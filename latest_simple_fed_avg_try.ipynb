{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 806 ms, sys: 63.9 ms, total: 870 ms\n",
      "Wall time: 889 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/Desktop/Projects/CodeSwitching/hparam.py:11: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from librosa.core import stft, magphase\n",
    "from torch.autograd import Variable\n",
    "from data_load import CodeSwitchDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeSwitchDataset(Dataset):\n",
    "    def __init__(self, lang, client, mode = \"train\", shuffle=True):\n",
    "        self.mode = mode\n",
    "        # data path\n",
    "        self.lang = lang\n",
    "        if self.lang == \"Gujarati\":\n",
    "            self.max_len = 0\n",
    "        elif self.lang == \"Telugu\":\n",
    "            self.max_len = 529862\n",
    "        elif self.lang == 'Tamil':\n",
    "            self.max_len = 0\n",
    "        else:\n",
    "            raise Exception(\"Check Language\")\n",
    "        if self.mode == \"train\":\n",
    "            self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        elif self.mode == \"test\":\n",
    "            self.path = self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        else:\n",
    "            raise Exception(\"Incorrect mode\")\n",
    "        self.file_list = os.listdir(os.path.join(self.path, 'Audio'))\n",
    "        self.shuffle=shuffle\n",
    "        self.csv_file = pd.read_csv(self.path + 'samples_450_{}.tsv'.format(client), header=None, sep='\\t')\n",
    "        self.input_length = []\n",
    "        self.label_length = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def pad(self, wav, trans, max_len):\n",
    "        orig_len = len(wav)\n",
    "        while len(wav) < max_len:\n",
    "            diff = max_len - len(wav)\n",
    "            ext = wav[:diff]\n",
    "            wav = np.append(wav, wav[:diff])\n",
    "            ratio = int(len(trans)*diff/len(wav))\n",
    "            trans +=trans[:ratio]\n",
    "        return wav, trans\n",
    "\n",
    "    def preprocess(self, wav, sr, trans):\n",
    "\n",
    "        out = stft(wav, win_length=int(sr*0.02), hop_length=int(sr*0.01))\n",
    "        text_transform = TextTransform()\n",
    "        trans = torch.Tensor(text_transform.text_to_int(trans.lower()))\n",
    "\n",
    "        out = magphase(out)[0]\n",
    "        out = [np.log(1 + x) for x in out]\n",
    "        return np.array(out), trans\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.csv_file[0][idx]\n",
    "        trans = self.csv_file[1][idx]\n",
    "        wav, sr = librosa.load(glob(self.path + 'Audio/*'+ str(file_name) + '.wav')[0])\n",
    "\n",
    "        if len(set(trans)) > 2:\n",
    "            label = 1\n",
    "        elif len(set(trans)) == 1 or len(set(trans)) == 2:\n",
    "            label = 0\n",
    "        else:\n",
    "            raise Exception(\"Check transcript\")\n",
    "        if self.mode ==\"train\":\n",
    "            return wav, sr, trans, self.lang\n",
    "        elif self.mode == \"test\":\n",
    "            return wav\n",
    "        else:\n",
    "            raise Exception(\"Incorrect Mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        s 1\n",
    "        e 2\n",
    "        t 3\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "            torchaudio.transforms.MelSpectrogram(n_mels=128, sample_rate = 22050, n_fft = 512, win_length=int(22050*0.02), hop_length=int(22050*0.01)),\n",
    "            torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "            torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    "        )\n",
    "\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _) in data:\n",
    "        waveform=torch.Tensor(waveform)\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, padding_value = 1, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "def wer(r, h):\n",
    "    \"\"\"\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "\n",
    "    Works only for iterables up to 254 elements (uint8).\n",
    "    O(nm) time ans space complexity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : list\n",
    "    h : list\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
    "    1\n",
    "    >>> wer(\"who is there\".split(), \"\".split())\n",
    "    3\n",
    "    >>> wer(\"\".split(), \"who is there\".split())\n",
    "    3\n",
    "    \"\"\"\n",
    "    # initialisation\n",
    "\n",
    "    d = np.zeros((len(r) + 1) * (len(h) + 1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r) + 1, len(h) + 1))\n",
    "    for i in range(len(r) + 1):\n",
    "        for j in range(len(h) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    for i in range(1, len(r) + 1):\n",
    "        for j in range(1, len(h) + 1):\n",
    "            if r[i - 1] == h[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=0, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \"\"\"Speech Recognition Model Inspired by DeepSpeech 2\"\"\"\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 64, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "\n",
    "            ResidualCNN(64, 64, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*64, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, _data, criterion, epoch, writer, client_no):\n",
    "    model.eval()\n",
    "    training_loss, train_acc = 0, 0\n",
    "    eer, total_eer = 0, 0\n",
    "    test_loss=0\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        inputs, labels, input_lengths, label_lengths = _data \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # output = model(inputs, input_lengths)  # (batch, time, n_class)\n",
    "        output=model(inputs)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        test_loss += loss.item() / len(test_loader)\n",
    "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "        decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "        for j in range(len(decoded_preds)):\n",
    "            s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "            acc.append(s.ratio())\n",
    "\n",
    "        avg_acc = sum(acc)/len(acc)\n",
    "        writer.add_scalar(\"{}/test_accuracy\".format(client_no), avg_acc, epoch)\n",
    "        writer.add_scalar(\"{}/WER\".format(client_no), wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "        writer.add_scalar('{}/test_loss'.format(client_no), test_loss, epoch)\n",
    "        print(\"Test Accuracy: {}, Test loss: {}\".format(avg_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename='checkpoint.pth.tar'):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 1\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "\n",
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\": 4,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 4,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 4,\n",
    "        \"epochs\": 60\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.frameworks.torch.fl.utils import federated_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_client1 = CodeSwitchDataset(lang='Telugu', client = 'a', mode=\"train\")\n",
    "train_dataset_client2 = CodeSwitchDataset(lang='Telugu', client = 'b', mode=\"train\")\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "client1_train_loader = DataLoader(train_dataset_client1,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = train_sampler,\n",
    "                          collate_fn = lambda x: data_processing(x, 'train'))\n",
    "\n",
    "\n",
    "client2_train_loader = DataLoader(train_dataset_client2,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = train_sampler,\n",
    "                          collate_fn = lambda x: data_processing(x, 'train'))\n",
    "\n",
    "\n",
    "\n",
    "test_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers=6,\n",
    "                          sampler=valid_sampler,\n",
    "                          collate_fn=lambda x: data_processing(x, 'valid'))\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "client1_optimizer = optim.Adam(client1_model.parameters(), hparams['learning_rate'])\n",
    "\n",
    "client2_model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "client2_optimizer = optim.Adam(client2_model.parameters(), hparams['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss(blank=0, reduction='mean').to(device)\n",
    "epochs = 60\n",
    "epoch_num = 1\n",
    "optimizer = optim.Adam(model.parameters(), hparams['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "    max_lr=hparams['learning_rate'],\n",
    "    steps_per_epoch=int(len(train_loader)),\n",
    "    epochs=hparams['epochs'],\n",
    "    anneal_strategy='linear')\n",
    "\n",
    "\n",
    "#model, optimizer, epoch_num = load_checkpoint(model, optimizer, \"checkpoints/ckpt_epoch_30_batch_id_1645.pth\")\n",
    "\n",
    "print(epoch_num)\n",
    "writer = SummaryWriter('train_logs_450_a_avg/')\n",
    "iter_meter = IterMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, _data, criterion, optimizer, epoch, iter_meter, writer, scheduler, client_no):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    total_loss=0\n",
    "    LR = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    avg_acc = 0\n",
    "    acc = []\n",
    "    wers = []\n",
    "    #bi, wav, label = batch_idx, wav, label\n",
    "    for g in optimizer.param_groups:\n",
    "        LR=g['lr']\n",
    "    wav, labels, input_lengths, label_lengths = _data\n",
    "    wav, labels = wav.to(device), labels.to(device)\n",
    "    # input_lengths, label_lengths = torch.IntTensor(input_lengths), torch.IntTensor(label_lengths)\n",
    "    wav = wav.to(device)\n",
    "    # wav = wav.float()\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    # output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\n",
    "    output = model(wav)\n",
    "\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0,1)\n",
    "\n",
    "    # print(labels, label_lengths)\n",
    "    loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    #print(loss)\n",
    "    total_loss+=loss\n",
    "\n",
    "    iter_meter.step()\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "    decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "    print(decoded_preds, decoded_targets)\n",
    "    print(\"preds: \", \"\".join(decoded_preds))\n",
    "    for j in range(len(decoded_preds)):\n",
    "        s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "        wers.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "        acc.append(s.ratio())\n",
    "\n",
    "    avg_acc = sum(acc)/len(acc)\n",
    "    writer.add_scalar(\"{}/accuracy/train_accuracy\".format(client_no), avg_acc, epoch)\n",
    "    writer.add_scalar('{}/accuracy/train_loss'.format(client_no), loss.item(), iter_meter.get())\n",
    "    writer.add_scalar('{}/CTCLoss'.format(client_no), loss, epoch*len(train_loader)+1)\n",
    "    writer.add_scalar('{}/TLoss'.format(client_no), total_loss, epoch*len(train_loader)+1)\n",
    "    writer.add_scalar(\"{}/Learning Rate\".format(client_no), LR, epoch)\n",
    "\n",
    "    writer.add_scalar(\"WER\", wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "    \"\"\"if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(wav), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        print(\"Train Accuracy: {}, Train loss: {}\".format(avg_acc, train_loss))\n",
    "    \"\"\"\n",
    "\n",
    "    #print(decoded_preds[0])\n",
    "    if (epoch+1)%2 == 0:\n",
    "        model.eval().cpu()\n",
    "        ckpt_model_filename = \"{}_ckpt_epoch_\".format(client_no) + str(epoch+1) + \"_450a.pth\"\n",
    "        ckpt_model_path = os.path.join(\"checkpoints_avg/\", ckpt_model_filename)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, ckpt_model_path)\n",
    "        model.to(device).train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(model, device, train_loader, criterion, optimizer, epoch, iter_meter, writer, scheduler)\n",
    "    test(model, device, test_loader, criterion, epoch, writer)\n",
    "\n",
    "model.eval().cpu()\n",
    "save_model_filename = \"final_epoch_client1\" + str(epoch + 1)  + \".model\"\n",
    "save_model_path = os.path.join(\"checkpoints\", save_model_filename)\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, save_model_path)\n",
    "\n",
    "print(\"\\nDone, trained model saved at\", save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eeteeteeeteeetteteteeteteeeetteetteeteeeeeteeetetetetetetetetteteteteteteetetetetetteeeeeteeetetetetetetettetettetetetetteteeteteteteteteteteteeseetteteeteeteteteeetetetetstete', 'eeteeteteeeeeeeteeteteteteteeeteteteteteeeteteseeteeeteeteteteteteteteteeteteteteteeteteteteteteteetetetetetetetetetetetetetteettetetetteeeetettetetetettetetetetetetettetetete', 'eteteteteeeeteteteeteteteteteeeeteeeteeeteteteeteteeteteeteteeeteeteteteteeteteteteteeteteeteteteteteteteteteteetetetetettetetetetetetetetetetetee', 'eteteteteteteeeeteeeteteeteteeeteteeteteteeseseteteteeteteteteeteteetteseteetetetetetetetetetetetsetetetetetetetetetseteteteteteteteteteetette'] ['sssttttteeteeeetttttss', 'sssssstttttttsssssssssssesettttstttttttttss', 'ssstttttttttttteettttttttttttss', 'ssttttttttttteeeeettteeetttttttttttttttttts']\n",
      "preds:  eeteeteeeteeetteteteeteteeeetteetteeteeeeeteeetetetetetetetetteteteteteteetetetetetteeeeeteeetetetetetetettetettetetetetteteeteteteteteteteteteeseetteteeteeteteteeetetetetsteteeeteeteteeeeeeeteeteteteteteeeteteteteteeeteteseeteeeteeteteteteteteteteeteteteteteeteteteteteteteetetetetetetetetetetetetetteettetetetteeeetettetetetettetetetetetetetteteteteeteteteteeeeteteteeteteteteteeeeteeeteeeteteteeteteeteteeteteeeteeteteteteeteteteteteeteteeteteteteteteteteteteetetetetetteteteteteteteteteteteteeeteteteteteteeeeteeeteteeteteeeteteeteteteeseseteteteeteteteteeteteetteseteetetetetetetetetetetetsetetetetetetetetetseteteteteteteteteteetette\n",
      "Test Accuracy: 0.0, Test loss: 0.18484176288951526\n",
      "['eeeeseeeeeeeseeeeeeeeseeeeeeeeeeseeeseeeeeeeeeeeeeeeseeeeseeeeeeseeeseeeseeeeseeeeeeeeeeeeseseeeeeeeseeeeeeeeeeeeeeeeeseeeeeeeeeeeeeeeeeeeeeeee', 'eseseseeeseeesessseeeeeeeeeeeeeeeeeeeeeeseseseseeeeeseseeeeeseseeseeseeeeeeseseseseeeeeeeeeeeeseeeseeeeeseseeseeeseeeeeseeseeeeeseeeeeeseeeeeeeeeeeeeeeeeeee', 'eseeeseeseseeseeeseseseeseeeeeeeeeseseeeeseseeeseseseseeseeseeeeseseeesseseeeeeeeeeseeeeeesesseseeeeeeeeeeeeeeeeseeeseeeeeeseeseeeeseeseeeeseseseseeeeseeeeeeseseseeeeeese', 'eseeeeseseseeeeseseseseeeeeeeeeeseeesesseeeseeeeeseetseseeeeeeeseeseeeeeeeeeeeeeeeeeeeeeeeeseeeeeeeeeeeeeseeeeeeeeeeeeeeeeeeeeseeeseee'] ['sstttteetttssttttttttttttttss', 'ssttttttttttseettttteeesseetttttttttttttttttttsetttss', 'ssttttttttttssssssssssssttttttttttttttttesseeseeeeetttttttss', 'sssttttttttttttttttttttttteetttss']\n",
      "preds:  eeeeseeeeeeeseeeeeeeeseeeeeeeeeeseeeseeeeeeeeeeeeeeeseeeeseeeeeeseeeseeeseeeeseeeeeeeeeeeeseseeeeeeeseeeeeeeeeeeeeeeeeseeeeeeeeeeeeeeeeeeeeeeeeeseseseeeseeesessseeeeeeeeeeeeeeeeeeeeeeseseseseeeeeseseeeeeseseeseeseeeeeeseseseseeeeeeeeeeeeseeeseeeeeseseeseeeseeeeeseeseeeeeseeeeeeseeeeeeeeeeeeeeeeeeeeeseeeseeseseeseeeseseseeseeeeeeeeeseseeeeseseeeseseseseeseeseeeeseseeesseseeeeeeeeeseeeeeesesseseeeeeeeeeeeeeeeeseeeseeeeeeseeseeeeseeseeeeseseseseeeeseeeeeeseseseeeeeeseeseeeeseseseeeeseseseseeeeeeeeeeseeesesseeeseeeeeseetseseeeeeeeseeseeeeeeeeeeeeeeeeeeeeeeeeseeeeeeeeeeeeeseeeeeeeeeeeeeeeeeeeeseeeseee\n",
      "Test Accuracy: 0.0, Test loss: 0.1454817598516291\n",
      "Test Accuracy: 0.0, Test loss: 0.40263384038751776\n",
      "['', '', '', ''] ['ssssttttttttttttttttttttttttttttttttseeettttttttttttttsss', 'ssssstttttsssttttttsstttttttssstttteetttttttss', 'sstttttsssssttttttttettss', 'ssstttttssssssssttttttttetttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.22064434398304333\n",
      "['', '', '', ''] ['ssstttttteeeeettttttss', 'ssttttttttteeetttteetttttttsttttttttttttttttss', 'ssseettttssstttttstttttttttttttsttttttttttstttsssssss', 'sstttttttteeteeetttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.05048062584616921\n",
      "Test Accuracy: 0.0, Test loss: 0.1412860480221835\n",
      "['', '', '', ''] ['sstteetttttttssttttttttss', 'ssseeeteeetttttttttttttttttttttttssttttttts', 'ssttttttssttttttttttsttttttttttttttttsssttttssssssssseeeeesstttss', 'sseeetttttttttssstttssssssssstttssttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.05178811875256625\n",
      "['', '', '', ''] ['ssseeeeeeetttttteeeeseettttsttteeetttttttss', 'ssseeeeessssseeeessseeesssssssseeeeetteeess', 'sssttttttttttttttteeeeeeesseeeeesseeseeetttstttttss', 'sstttttttttttteettttttttttteeesttttttssttttttttttttttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.06891448931260542\n",
      "Test Accuracy: 0.0, Test loss: 0.05048860744996504\n",
      "['', '', '', ''] ['ssttttetttetttttttttttttsttttttttttss', 'ssttttttttettttttss', 'sseeettttttttteetttss', 'sstttttttttttttestttttttttttttttttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.07280988043004816\n",
      "['', '', '', ''] ['sstttttttttttttttttttttssssseeettsssstttttttttssss', 'sssstttttttssttttteeeeetttttsssstttttsss', 'sstttttttsttttttettttss', 'ssstttttttttttttttettttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.053417325019836426\n",
      "Test Accuracy: 0.0, Test loss: 0.06364106048237193\n",
      "['', '', '', ''] ['sseeetttttttttttssstttttttttttttttttsssttttssttttttttssttts', 'sstttttttettttss', 'sstttsseetttetteteetttttss', 'sstttttttsteetttttttseetttttttssss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.046025568788701836\n",
      "['', '', '', ''] ['ssstttttteeetttttttttttstttttttttts', 'sssttteeeeeeeeeesstttttssssseeeeeeeettttttttttttss', 'sseettttttttttttttttseeeetttttss', 'sstteetttttttttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.059566010128368034\n",
      "Test Accuracy: 0.0, Test loss: 0.04358028281818737\n",
      "['', '', '', ''] ['stttttsseeeeestttttttts', 'sstttteettseeettttttteetttttttts', 'sseetttttttttttttttttettttttttttts', 'sstttttteeeeesssssttttttttsttstttetttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.0439460196278312\n",
      "['', '', '', ''] ['ssseeetttttttttttttttttt', 'sssttttttttstttttttteeetteetttttss', 'ssstttttttttttttteetttttttttttss', 'ssssteeeeeetttttttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.04597373442216353\n",
      "Test Accuracy: 0.0, Test loss: 0.04507818547162143\n",
      "['', '', '', ''] ['sseeetttttttsstttttsssssttttsttttttsttttsttttttttt', 'sseeettttttttteetttss', 'ssstttttttseetttts', 'ssttttttteeeeeeettttttsttttttttttttss']\n",
      "preds:  \n",
      "Test Accuracy: 0.0, Test loss: 0.04731918465007435\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-e91f45ec7427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0m_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"client_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [client1_model, client2_model]\n",
    "optimizers = [client1_optimizer, client2_optimizer]\n",
    "train_loaders = [client1_train_loader, client2_train_loader]\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    _test_data = next(iter(test_loader))\n",
    "    for i in range(len(models)):\n",
    "        _train_data = next(iter(train_loaders[i]))\n",
    "        models[i].to(device)\n",
    "        models[i] = train(models[i], device, _train_data, criterion, optimizers[i], epoch, iter_meter, writer, scheduler, \"client_{}\".format(i))\n",
    "        test(models[i], device, _test_data, criterion, epoch, writer, \"client_{}\".format(i))\n",
    "    fed_model = federated_avg({'client1': models[0],\n",
    "                              'client2': models[1]})\n",
    "    test(fed_model, device, _test_data, criterion, epoch, writer, \"client_{}\".format(i))\n",
    "fed_model.eval().cpu()\n",
    "save_model_filename = \"final_epoch_client1\" + str(epoch + 1)  + \".model\"\n",
    "save_model_path = os.path.join(\"fed_checkpoints\", save_model_filename)\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': fed_model.state_dict(),\n",
    "            }, save_model_path)\n",
    "\n",
    "print(\"\\nDone, trained model saved at\", save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128, 1177])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128, 897])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.9348e-03, 6.9216e-03, 3.4567e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.6095e-02, 1.8771e-02, 9.3745e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [3.9755e-07, 1.5729e-15, 2.3203e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.9780e-07, 1.3513e-15, 1.4307e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.0308e-07, 1.2944e-15, 1.2784e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.6575e-02, 3.2842e-02, 1.2850e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [7.2070e-02, 8.9065e-02, 3.4849e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [3.5998e-06, 7.3058e-15, 3.3232e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.6035e-06, 6.3003e-15, 3.8330e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.6522e-06, 5.7338e-15, 1.7321e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.0525e-04, 1.3889e-03, 4.6921e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.5663e-04, 3.7667e-03, 1.2725e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [2.2641e-08, 3.2746e-16, 3.1243e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.2781e-08, 2.9219e-16, 1.4813e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.3159e-08, 2.5383e-16, 9.8389e-17,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.1914e-06, 1.0250e-06, 7.1830e-08,  ..., 3.6329e-07,\n",
       "            1.3712e-06, 2.8189e-06],\n",
       "           [1.4079e-05, 2.7797e-06, 1.9480e-07,  ..., 9.8524e-07,\n",
       "            3.7187e-06, 7.6447e-06],\n",
       "           ...,\n",
       "           [2.3139e-07, 3.7314e-16, 4.7132e-16,  ..., 5.9783e-16,\n",
       "            3.6230e-16, 1.8816e-07],\n",
       "           [2.3074e-07, 3.1931e-16, 4.4585e-16,  ..., 4.8613e-16,\n",
       "            3.0082e-16, 1.8690e-07],\n",
       "           [2.3333e-07, 2.8152e-16, 4.1711e-16,  ..., 4.3068e-16,\n",
       "            2.4560e-16, 1.8854e-07]]]]),\n",
       " tensor([[1., 1., 1., 3., 3., 3., 3., 1., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 2., 2., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 2., 2., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 3., 1.]]),\n",
       " [318, 328, 363, 441],\n",
       " [32, 33, 37, 44])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
