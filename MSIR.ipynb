{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTfYifImtoSJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/Desktop/MSR challenge/hparam.py:11: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import csv\n",
    "from data_load import TextTransform\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from decoder import GreedyDecoder\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "from librosa.core import stft, magphase\n",
    "from glob import glob\n",
    "from torch import autograd\n",
    "import csv\n",
    "from data_load import CodeSwitchDataset\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pad(wav, trans, lang):\n",
    "    if lang == \"Gujarati\":\n",
    "        max_len = 0\n",
    "    elif lang == \"Telugu\":\n",
    "        max_len = 529862\n",
    "    elif lang == 'Tamil':\n",
    "        max_len = 0\n",
    "    else:\n",
    "        raise Exception(\"Check Language\")\n",
    "\n",
    "    while len(wav) < max_len:\n",
    "        diff = max_len - len(wav)\n",
    "        ext = wav[:diff]\n",
    "        wav = np.append(wav, wav[:diff])\n",
    "        ratio = int(len(trans)*diff/len(wav))\n",
    "        trans +=trans[:ratio]\n",
    "    return wav, trans\n",
    "\n",
    "def preprocess(data):\n",
    "    #print(data)\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    \n",
    "    for (wav, sr, trans, lang) in data:\n",
    "        wav, trans  = pad(wav, trans, lang)\n",
    "        out = stft(wav, win_length=int(sr*0.02), hop_length=int(sr*0.01))\n",
    "        out = np.transpose(out, axes=(1, 0))\n",
    "\n",
    "        text_transform = TextTransform()\n",
    "        trans = torch.Tensor(text_transform.text_to_int(trans.lower()))\n",
    "\n",
    "        out = magphase(out)[0]\n",
    "        out = torch.from_numpy(np.array([np.log(1 + x) for x in out]))\n",
    "        #print(out.shape)\n",
    "        inputs.append(out)\n",
    "        labels.append(trans)\n",
    "        input_lengths.append(out.shape[0])\n",
    "        label_lengths.append(len(trans))\n",
    "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    #spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    return inputs, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=False):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CodeSwitchDataset(lang = 'Telugu', mode = \"train\")\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = train_sampler,\n",
    "                         collate_fn = lambda x: preprocess(x))\n",
    "test_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = valid_sampler,\n",
    "                         collate_fn = lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim = 29, num_layers = 4):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "        #self.drop = nn.Dropout(0.25)\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(type(self.lstm))\n",
    "        #print(x.shape)\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        #lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.linear(lstm_out)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data_len = len(train_loader.dataset)\n",
    "pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "for batch_idx, (_data) in pbar:\n",
    "    #bi, wav, label = batch_idx, wav, label\n",
    "    wav, labels, input_lengths, label_lengths = _data\n",
    "    print(wav.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, writer):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (_data) in pbar:\n",
    "        #bi, wav, label = batch_idx, wav, label\n",
    "        wav, labels, input_lengths, label_lengths = _data\n",
    "        wav = wav.to(device)\n",
    "        wav = wav.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "        output, _ = model(wav)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        output = output.transpose(0,1)\n",
    "        #print(output.shape)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        \n",
    "        writer.add_scalar('Loss', loss, epoch*len(train_loader)+1)\n",
    "        #writer.add_scalar('TLoss', total_loss, epoch*len(train_loader)+1)\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(wav), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    if (epoch+1)%2 == 0:\n",
    "        model.eval().cpu()\n",
    "        ckpt_model_filename = \"ckpt_epoch_\" + str(epoch+1) + \"_batch_id_\" + str(batch_idx+1) + \".pth\"\n",
    "        ckpt_model_path = os.path.join(\"checkpoints/\", ckpt_model_filename)\n",
    "        torch.save(model.state_dict(), ckpt_model_path)\n",
    "        model.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
    "    model.eval()\n",
    "    training_loss, train_acc = 0, 0\n",
    "    eer, total_eer = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, _data in enumerate(test_loader):\n",
    "            frr_far, eer = 0, 0\n",
    "            inputs, labels, input_lengths, label_lengths = _data \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, _ = model(inputs)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=1)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                if len(set(decoded_preds[j])) != len(set(decoded_targets[j])):\n",
    "                    frr_far+=1\n",
    "            eer = frr_far/len(decoded_preds)\n",
    "            total_eer+=eer\n",
    "            print(\"EER: \",eer)\n",
    "            print(\"Total EER: \", total_eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=1025,\n",
    "              hidden_dim=512,\n",
    "              batch_size=8,\n",
    "              output_dim=29,\n",
    "              num_layers=4)\n",
    "#model.half()\n",
    "model = model.to(device)\n",
    "criterion = nn.CTCLoss().to(device)\n",
    "epochs = 40\n",
    "optimizer = optim.Adam(model.parameters(), 5e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-4, \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=40,\n",
    "                                            anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1699 [00:03<1:50:06,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/16991 (0%)]\tLoss: 68.128494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 101/1699 [00:59<11:39,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [800/16991 (6%)]\tLoss: 71.089249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 108/1699 [01:03<10:50,  2.45it/s]"
     ]
    }
   ],
   "source": [
    "for layer in model.modules():\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        layer.float()\n",
    "writer = SummaryWriter('train_logs/')\n",
    "iter_meter = IterMeter()\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, writer)\n",
    "    test(model, device, test_loader, criterion, epoch, writer)\n",
    "    \n",
    "    \n",
    "model.eval().cpu()\n",
    "save_model_filename = \"final_epoch_\" + str(epoch + 1) + \"_batch_id_\" + str(batch_idx + 1) + \".model\"\n",
    "save_model_path = os.path.join(\"checkpoints\", save_model_filename)\n",
    "torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "print(\"\\nDone, trained model saved at\", save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label\n",
    "x_train = wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = len(x_train)\n",
    "nb_features = len(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_len = np.asarray([len(x_train[i]) for i in range(nb_train)])\n",
    "print(x_train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 189\n",
    "n_class = 80\n",
    "y = torch.tensor([[55, 43, 40, 62, 41, 44, 53, 40, 62, 41, 50, 53, 62, 58, 36, 54, 43, 44, 49, 42]])\n",
    "output_length = torch.tensor(y.shape[1])\n",
    "\n",
    "pred_model_idx = 79*torch.ones(T, dtype=torch.long)\n",
    "pred_perf_idx = torch.cat([y[0], (n_class-1) * torch.ones(T-y.shape[1], dtype=torch.long)]) # the first idx are perfect with y, then padded with blanks\n",
    "pred_model = torch.eye(n_class)[pred_model_idx].unsqueeze(1) # one-hot encoding\n",
    "pred_perf = torch.eye(n_class)[pred_perf_idx].unsqueeze(1) # one-hot encoding\n",
    "\n",
    "for input_length in [torch.tensor(y.shape[1]), torch.tensor(T)]:\n",
    "    print(\"=============\\ninput length:\", input_length)\n",
    "    print(\"perfect loss:\", F.ctc_loss(F.log_softmax(pred_perf, dim=2), y, input_length, output_length, n_class-1, 'none', True))\n",
    "    print(\"all_blank loss:\", F.ctc_loss(F.log_softmax(pred_model, dim=2), y, input_length, output_length, n_class-1, 'none', True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = librosa.load('Data/PartA_Telugu/Train/Audio/000010010.wav')\n",
    "df = pd.read_csv('Data/PartA_Gujarati/Train/Transcription_LT_Sequence.tsv', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = torch.rand((2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear(2, 29)(qw).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MSIR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
