{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z42K6l1dFWlN",
    "outputId": "321173a9-e01b-4d89-f478-692218c94909"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.4.0\n",
    "#!pip install torchaudio==0.4.0\n",
    "#!pip install syft==0.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5PghMt9XFWse"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnPHbct-z2md"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmgQ0ep7FO0b",
    "outputId": "767314b5-f0e1-4723-bc6b-481f94f0c744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 160 ms, total: 2.14 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from librosa.core import stft, magphase\n",
    "from torch.autograd import Variable\n",
    "## from data_load import CodeSwitchDataset\n",
    "\n",
    "from syft.frameworks.torch.fl.utils import federated_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ghu8CAFYrRP1",
    "outputId": "0e60ea1c-2566-4c3a-9003-f58718d09d59"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMKyFdxzKcTQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "62OEVVwGFUVE"
   },
   "outputs": [],
   "source": [
    "class CodeSwitchDataset(Dataset):\n",
    "    def __init__(self, lang, client, mode = \"train\", shuffle=True):\n",
    "        self.mode = mode\n",
    "        # data path\n",
    "        self.lang = lang\n",
    "        if self.lang == \"Gujarati\":\n",
    "            self.max_len = 0\n",
    "        elif self.lang == \"Telugu\":\n",
    "            self.max_len = 529862\n",
    "        elif self.lang == 'Tamil':\n",
    "            self.max_len = 0\n",
    "        else:\n",
    "            raise Exception(\"Check Language\")\n",
    "        if self.mode == \"train\":\n",
    "            self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        elif self.mode == \"test\":\n",
    "            self.path = self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        else:\n",
    "            raise Exception(\"Incorrect mode\")\n",
    "        self.file_list = os.listdir(os.path.join(self.path, 'Audio'))\n",
    "        self.shuffle=shuffle\n",
    "        self.csv_file = pd.read_csv(self.path + 'samples_450_{}.tsv'.format(client), header=None, sep='\\t')\n",
    "        self.input_length = []\n",
    "        self.label_length = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def pad(self, wav, trans, max_len):\n",
    "        orig_len = len(wav)\n",
    "        while len(wav) < max_len:\n",
    "            diff = max_len - len(wav)\n",
    "            ext = wav[:diff]\n",
    "            wav = np.append(wav, wav[:diff])\n",
    "            ratio = int(len(trans)*diff/len(wav))\n",
    "            trans +=trans[:ratio]\n",
    "        return wav, trans\n",
    "\n",
    "    def preprocess(self, wav, sr, trans):\n",
    "\n",
    "        out = stft(wav, win_length=int(sr*0.02), hop_length=int(sr*0.01))\n",
    "        text_transform = TextTransform()\n",
    "        trans = torch.Tensor(text_transform.text_to_int(trans.lower()))\n",
    "\n",
    "        out = magphase(out)[0]\n",
    "        out = [np.log(1 + x) for x in out]\n",
    "        return np.array(out), trans\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.csv_file[0][idx]\n",
    "        trans = self.csv_file[1][idx]\n",
    "        wav, sr = librosa.load(glob(self.path + 'Audio/*'+ str(file_name) + '.wav')[0])\n",
    "        length_wav, length_trans = len(wav), len(trans)\n",
    "        if len(set(trans)) > 2:\n",
    "            label = 1\n",
    "        elif len(set(trans)) == 1 or len(set(trans)) == 2:\n",
    "            label = 0\n",
    "        else:\n",
    "            raise Exception(\"Check transcript\")\n",
    "            \n",
    "        if self.mode ==\"train\":\n",
    "            return wav, sr, trans, self.lang\n",
    "        elif self.mode == \"test\":\n",
    "            return wav\n",
    "        else:\n",
    "            raise Exception(\"Incorrect Mode\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeSwitchDataset(Dataset):\n",
    "    def __init__(self, lang, mode = \"train\", shuffle=True):\n",
    "        self.mode = mode\n",
    "        # data path\n",
    "        self.lang = lang\n",
    "        if self.lang == \"Gujarati\":\n",
    "            self.max_len = 0\n",
    "        elif self.lang == \"Telugu\":\n",
    "            self.max_len = 529862\n",
    "        elif self.lang == 'Tamil':\n",
    "            self.max_len = 0\n",
    "        else:\n",
    "            raise Exception(\"Check Language\")\n",
    "        if self.mode == \"train\":\n",
    "            self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        elif self.mode == \"test\":\n",
    "            self.path = self.path = 'Data/PartB_{}/Dev/'.format(self.lang)\n",
    "        else:\n",
    "            raise Exception(\"Incorrect mode\")\n",
    "        self.file_list = os.listdir(os.path.join(self.path, 'Audio'))\n",
    "        self.shuffle=shuffle\n",
    "        self.csv_file = pd.read_csv(self.path + 'samples_450_b.tsv', header=None, sep='\\t')\n",
    "        self.input_length = []\n",
    "        self.label_length = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def pad(self, wav, trans, max_len):\n",
    "        orig_len = len(wav)\n",
    "        while len(wav) < max_len:\n",
    "            diff = max_len - len(wav)\n",
    "            ext = wav[:diff]\n",
    "            wav = np.append(wav, wav[:diff])\n",
    "            ratio = int(len(trans)*diff/len(wav))\n",
    "            trans +=trans[:ratio]\n",
    "        return wav, trans\n",
    "\n",
    "    def preprocess(self, wav, sr, trans):\n",
    "\n",
    "        out = stft(wav, win_length=int(sr*0.02), hop_length=int(sr*0.01))\n",
    "        text_transform = TextTransform()\n",
    "        trans = torch.Tensor(text_transform.text_to_int(trans.lower()))\n",
    "\n",
    "        out = magphase(out)[0]\n",
    "        out = [np.log(1 + x) for x in out]\n",
    "        return np.array(out), trans\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.csv_file[0][idx]\n",
    "        trans = self.csv_file[1][idx]\n",
    "        wav, sr = librosa.load(glob(self.path + 'Audio/*'+ str(file_name) + '.wav')[0])\n",
    "\n",
    "        if len(set(trans)) > 2:\n",
    "            label = 1\n",
    "        elif len(set(trans)) == 1 or len(set(trans)) == 2:\n",
    "            label = 0\n",
    "        else:\n",
    "            raise Exception(\"Check transcript\")\n",
    "        if self.mode ==\"train\":\n",
    "            return wav, sr, trans, self.lang\n",
    "        elif self.mode == \"test\":\n",
    "            return wav\n",
    "        else:\n",
    "            raise Exception(\"Incorrect Mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X_Hzcy_uI5GM"
   },
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        s 1\n",
    "        e 2\n",
    "        t 3\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "03YASWhEI6d7"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "            torchaudio.transforms.MelSpectrogram(n_mels=128, sample_rate = 22050, n_fft = 512, win_length=int(22050*0.02), hop_length=int(22050*0.01)),\n",
    "            torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "            torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    "        )\n",
    "\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _) in data:\n",
    "        waveform=torch.Tensor(waveform)\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, padding_value = 1, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "def wer(r, h):\n",
    "    \"\"\"\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "\n",
    "    Works only for iterables up to 254 elements (uint8).\n",
    "    O(nm) time ans space complexity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : list\n",
    "    h : list\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
    "    1\n",
    "    >>> wer(\"who is there\".split(), \"\".split())\n",
    "    3\n",
    "    >>> wer(\"\".split(), \"who is there\".split())\n",
    "    3\n",
    "    \"\"\"\n",
    "    # initialisation\n",
    "\n",
    "    d = np.zeros((len(r) + 1) * (len(h) + 1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r) + 1, len(h) + 1))\n",
    "    for i in range(len(r) + 1):\n",
    "        for j in range(len(h) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    for i in range(1, len(r) + 1):\n",
    "        for j in range(1, len(h) + 1):\n",
    "            if r[i - 1] == h[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=0, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7T7ZVbXI7tB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9ayRUTURI9qf"
   },
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \"\"\"Speech Recognition Model Inspired by DeepSpeech 2\"\"\"\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 64, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "\n",
    "            ResidualCNN(64, 64, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*64, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yJUSI1iIHhxD"
   },
   "outputs": [],
   "source": [
    "def train(model, device, _data, criterion, optimizer, epoch, iter_meter, writer, scheduler, client_no):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    LR = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    avg_acc = 0\n",
    "    acc = []\n",
    "    wers = []\n",
    "    #bi, wav, label = batch_idx, wav, label\n",
    "    for g in optimizer.param_groups:\n",
    "        LR=g['lr']\n",
    "    wav, labels, input_lengths, label_lengths = _data\n",
    "    wav, labels = wav.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "    # input_lengths, label_lengths = torch.IntTensor(input_lengths), torch.IntTensor(label_lengths)\n",
    "    \n",
    "    # wav = wav.float()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\n",
    "    output = model(wav)\n",
    "\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0,1)\n",
    "\n",
    "    # print(labels, label_lengths)\n",
    "    loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    #print(loss)\n",
    "    total_loss+=loss\n",
    "\n",
    "    iter_meter.step()\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "    decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "    print(decoded_preds, decoded_targets)\n",
    "    #print(\"preds: \", \"\".join(decoded_preds))\n",
    "    for j in range(len(decoded_preds)):\n",
    "        s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "        wers.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "        acc.append(s.ratio())\n",
    "\n",
    "    avg_acc = sum(acc)/len(acc)\n",
    "    writer.add_scalar(\"{}/accuracy/train_accuracy\".format(client_no), avg_acc, epoch)\n",
    "    writer.add_scalar('{}/accuracy/train_loss'.format(client_no), loss.item(), iter_meter.get())\n",
    "    writer.add_scalar('{}/CTCLoss'.format(client_no), loss, iter_meter.get())\n",
    "    writer.add_scalar('{}/TLoss'.format(client_no), total_loss, iter_meter.get())\n",
    "    writer.add_scalar(\"{}/Learning Rate\".format(client_no), LR, epoch)\n",
    "\n",
    "    writer.add_scalar(\"WER\", wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "    \"\"\"if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(wav), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        print(\"Train Accuracy: {}, Train loss: {}\".format(avg_acc, train_loss))\n",
    "    \"\"\"\n",
    "\n",
    "    #print(decoded_preds[0])\n",
    "    \"\"\"\n",
    "    if (epoch+1)%2 == 0:\n",
    "        model.eval().cpu()\n",
    "        ckpt_model_filename = \"{}_ckpt_epoch_\".format(client_no) + str(epoch+1) + \"_450a.pth\"\n",
    "        ckpt_model_path = os.path.join(\"Audio/MyDrive/checkpoints_avg/\", ckpt_model_filename)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, ckpt_model_path)\n",
    "        model.to(device).train()\n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ik8ElvGiI-AY"
   },
   "outputs": [],
   "source": [
    "def test(model, device, _data, criterion, epoch, writer, client_no, iter_meter):\n",
    "    model.eval()\n",
    "    training_loss, train_acc = 0, 0\n",
    "    eer, total_eer = 0, 0\n",
    "    test_loss=0\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        inputs, labels, input_lengths, label_lengths = _data \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # output = model(inputs, input_lengths)  # (batch, time, n_class)\n",
    "        output=model(inputs)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        test_loss += loss.item() / len(test_loader)\n",
    "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "        decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "        for j in range(len(decoded_preds)):\n",
    "            s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "            acc.append(s.ratio())\n",
    "\n",
    "        avg_acc = sum(acc)/len(acc)\n",
    "        writer.add_scalar(\"{}/test_accuracy\".format(client_no), avg_acc, epoch)\n",
    "        writer.add_scalar(\"{}/WER\".format(client_no), wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "        writer.add_scalar('{}/test_loss'.format(client_no), test_loss, epoch)\n",
    "        print(\"Test Accuracy: {}, Test loss: {}\".format(avg_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G_OSoOpyI_by"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename='checkpoint.pth.tar'):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 1\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename, map_location = torch.device('cpu'))\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "\n",
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ontTSp-pJAgK"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\": 4,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 4,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 4,\n",
    "        \"epochs\": 60\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WnWwgR2SJD3z"
   },
   "outputs": [],
   "source": [
    "LANGUAGE = \"Telugu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "uAfkxa2TJEcD"
   },
   "outputs": [],
   "source": [
    "train_dataset_client1 = CodeSwitchDataset(lang=LANGUAGE, client = 'a', mode=\"train\")\n",
    "train_dataset_client2 = CodeSwitchDataset(lang=LANGUAGE, client = 'b', mode=\"train\")\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "\n",
    "dataset_size_1 = len(train_dataset_client1)\n",
    "dataset_size_2 = len(train_dataset_client2)\n",
    "indices_1 = list(range(dataset_size_1))\n",
    "indices_2 = list(range(dataset_size_2))\n",
    "\n",
    "split_1 = int(np.floor(validation_split * dataset_size_1))\n",
    "split_2 = int(np.floor(validation_split * dataset_size_2))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices_1)\n",
    "    np.random.shuffle(indices_2)\n",
    "    \n",
    "train_indices_1, val_indices_1 = indices_1[split_1:], indices_1[:split_1]\n",
    "train_indices_2, val_indices_2 = indices_2[split_2:], indices_2[:split_2]\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler_1 = SubsetRandomSampler(train_indices_1)\n",
    "valid_sampler_1 = SubsetRandomSampler(val_indices_1)\n",
    "\n",
    "\n",
    "train_sampler_2 = SubsetRandomSampler(train_indices_2)\n",
    "valid_sampler_2 = SubsetRandomSampler(val_indices_2)\n",
    "\n",
    "\n",
    "\n",
    "client1_train_loader = DataLoader(train_dataset_client1,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 0,\n",
    "                          sampler = train_sampler_1,\n",
    "                          collate_fn = lambda x: data_processing(x, 'train'))\n",
    "\n",
    "\n",
    "client2_train_loader = DataLoader(train_dataset_client2,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 0,\n",
    "                          sampler = train_sampler_2,\n",
    "                          collate_fn = lambda x: data_processing(x, 'train'))\n",
    "\n",
    "\n",
    "\n",
    "client1_test_loader = DataLoader(train_dataset_client1,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers=0,\n",
    "                          sampler=valid_sampler_1,\n",
    "                          collate_fn=lambda x: data_processing(x, 'valid'))\n",
    "\n",
    "\n",
    "client2_test_loader = DataLoader(train_dataset_client2,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True,\n",
    "                          num_workers=0,\n",
    "                          sampler=valid_sampler_2,\n",
    "                          collate_fn=lambda x: data_processing(x, 'valid'))\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIRfb_ylJIFM",
    "outputId": "af9358e2-c940-4617-8a76-8e4f82cf460e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth'\n",
      "=> loaded checkpoint 'Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth' (epoch 35)\n",
      "=> loading checkpoint 'Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth'\n",
      "=> loaded checkpoint 'Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth' (epoch 35)\n"
     ]
    }
   ],
   "source": [
    "client1_model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "client1_optimizer = optim.Adam(client1_model.parameters(), hparams['learning_rate'])\n",
    "\n",
    "client2_model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "client2_optimizer = optim.Adam(client2_model.parameters(), hparams['learning_rate'])\n",
    "\n",
    "\n",
    "#client1_model, _, epoch_num = load_checkpoint(client1_model, client1_optimizer, \"/content/Audio/MyDrive/PartB_{}/ckpt_epoch_36_batch_id_1645.pth\".format(LANGUAGE))\n",
    "#client2_model, _, epoch_num = load_checkpoint(client2_model, client2_optimizer, \"/content/Audio/MyDrive/PartB_{}/ckpt_epoch_36_batch_id_1645.pth\".format(LANGUAGE))\n",
    "\n",
    "client1_model, _, epoch_num = load_checkpoint(client1_model, client1_optimizer, \"Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth\".format(LANGUAGE))\n",
    "client2_model, _, epoch_num = load_checkpoint(client2_model, client2_optimizer, \"Telugu_Checkpoints/ckpt_epoch_36_batch_id_1645.pth\".format(LANGUAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1wyTzU4JKEV",
    "outputId": "ee77c4ee-be5c-4b50-fc83-3dcf946bd10e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss(blank=0, reduction='mean').to(device)\n",
    "epochs = 60\n",
    "epoch_num = 1\n",
    "client1_scheduler = optim.lr_scheduler.OneCycleLR(client1_optimizer,\n",
    "    max_lr=hparams['learning_rate'],\n",
    "    steps_per_epoch=int(len(client1_train_loader)),\n",
    "    epochs=hparams['epochs'],\n",
    "    anneal_strategy='linear')\n",
    "\n",
    "client2_scheduler = optim.lr_scheduler.OneCycleLR(client2_optimizer,\n",
    "    max_lr=hparams['learning_rate'],\n",
    "    steps_per_epoch=int(len(client2_train_loader)),\n",
    "    epochs=hparams['epochs'],\n",
    "    anneal_strategy='linear')\n",
    "\n",
    "\n",
    "#model, optimizer, epoch_num = load_checkpoint(model, optimizer, \"checkpoints/ckpt_epoch_30_batch_id_1645.pth\")\n",
    "\n",
    "print(epoch_num)\n",
    "writer = SummaryWriter('train_logs_450/')\n",
    "iter_meter_client1 = IterMeter()\n",
    "iter_meter_client2 = IterMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "YdJpu-XQS5Hp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodels = [client1_model, client2_model]\\noptimizers = [client1_optimizer, client2_optimizer]\\ntrain_loaders = [client1_train_loader, client2_train_loader]\\nschedulers = [client1_scheduler, client2_scheduler]\\niter_meter = [iter_meter_client1, iter_meter_client2]\\nfor epoch in range(1, epochs+1):\\n    print(\"----------Epoch: \", epoch, \"----------------\")\\n    _test_data = next(iter(test_loader))\\n    for i in range(len(models)):\\n        _train_data = next(iter(train_loaders[i]))\\n        #models[i].to(device)\\n        print(\"training: \", i)\\n        \\n        print(\"Train data :----------------------------\", len(_train_data), _train_data[0].shape, _train_data)\\n        print(\"Test data :----------------------------\", len(_test_data), _test_data[0].shape, _test_data)\\n        \\n        #models[i] = train(models[i], device, _train_data, criterion, optimizers[i], epoch, iter_meter[i], writer, schedulers[i], \"client_{}\".format(i))\\n        #test(models[i], device, _test_data, criterion, epoch, writer, \"client_{}\".format(i))\\n    #fed_model = federated_avg({\\'client1\\': models[0],\\n    #                          \\'client2\\': models[1]})\\n    #test(fed_model, device, _test_data, criterion, epoch, writer, \"client_{}\".format(i), iter_meter[i])\\n#fed_model.eval().cpu()\\n#save_model_filename = \"final_epoch_client1\" + str(epoch + 1)  + \".model\"\\n#save_model_path = os.path.join(\"fed_checkpoints\", save_model_filename)\\n#torch.save({\\n#            \\'epoch\\': epoch,\\n#            \\'model_state_dict\\': fed_model.state_dict(),\\n#            }, save_model_path)\\n#\\n#print(\"\\nDone, trained model saved at\", save_model_path)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "models = [client1_model, client2_model]\n",
    "optimizers = [client1_optimizer, client2_optimizer]\n",
    "train_loaders = [client1_train_loader, client2_train_loader]\n",
    "schedulers = [client1_scheduler, client2_scheduler]\n",
    "iter_meter = [iter_meter_client1, iter_meter_client2]\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"----------Epoch: \", epoch, \"----------------\")\n",
    "    _test_data = next(iter(test_loader))\n",
    "    for i in range(len(models)):\n",
    "        _train_data = next(iter(train_loaders[i]))\n",
    "        #models[i].to(device)\n",
    "        print(\"training: \", i)\n",
    "        \n",
    "        print(\"Train data :----------------------------\", len(_train_data), _train_data[0].shape, _train_data)\n",
    "        print(\"Test data :----------------------------\", len(_test_data), _test_data[0].shape, _test_data)\n",
    "        \n",
    "        #models[i] = train(models[i], device, _train_data, criterion, optimizers[i], epoch, iter_meter[i], writer, schedulers[i], \"client_{}\".format(i))\n",
    "        #test(models[i], device, _test_data, criterion, epoch, writer, \"client_{}\".format(i))\n",
    "    #fed_model = federated_avg({'client1': models[0],\n",
    "    #                          'client2': models[1]})\n",
    "    #test(fed_model, device, _test_data, criterion, epoch, writer, \"client_{}\".format(i), iter_meter[i])\n",
    "#fed_model.eval().cpu()\n",
    "#save_model_filename = \"final_epoch_client1\" + str(epoch + 1)  + \".model\"\n",
    "#save_model_path = os.path.join(\"fed_checkpoints\", save_model_filename)\n",
    "#torch.save({\n",
    "#            'epoch': epoch,\n",
    "#            'model_state_dict': fed_model.state_dict(),\n",
    "#            }, save_model_path)\n",
    "#\n",
    "#print(\"\\nDone, trained model saved at\", save_model_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client1_model.classifier.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch, iter_meter, writer, scheduler, ckpt_save_dir):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    total_loss=0\n",
    "    LR = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    avg_acc = 0\n",
    "    acc = []\n",
    "    wers = []\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (_data) in enumerate(train_loader):\n",
    "        print(\"------------------ITER------------------\")\n",
    "        #bi, wav, label = batch_idx, wav, label\n",
    "        for g in optimizer.param_groups:\n",
    "            LR=g['lr']\n",
    "        wav, labels, input_lengths, label_lengths = _data\n",
    "        # input_lengths, label_lengths = torch.IntTensor(input_lengths), torch.IntTensor(label_lengths)\n",
    "        wav = wav.to(device)\n",
    "        # wav = wav.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\n",
    "        output = model(wav)\n",
    "\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "\n",
    "\n",
    "        output = output.transpose(0,1)\n",
    "        \n",
    "        # print(labels, label_lengths)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        #print(loss)\n",
    "        total_loss+=loss\n",
    "\n",
    "        iter_meter.step()\n",
    "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "        decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "        print(decoded_preds, decoded_targets)\n",
    "        print(\"preds: \", \"\".join(decoded_preds))\n",
    "        for j in range(len(decoded_preds)):\n",
    "            s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "            wers.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "            acc.append(s.ratio())\n",
    "\n",
    "        avg_acc = sum(acc)/len(acc)\n",
    "        writer.add_scalar(\"accuracy/train_accuracy\", avg_acc, epoch)\n",
    "        writer.add_scalar('accuracy/train_loss', loss.item(), iter_meter.get())\n",
    "        writer.add_scalar('CTCLoss', loss, epoch*len(train_loader)+1)\n",
    "        writer.add_scalar('TLoss', total_loss, epoch*len(train_loader)+1)\n",
    "        writer.add_scalar(\"Learning Rate\", LR, epoch)\n",
    "\n",
    "        writer.add_scalar(\"WER\", wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(wav), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "            print(\"Train Accuracy: {}, Train loss: {}\".format(avg_acc, train_loss))\n",
    "        model.to(device).train()\n",
    "    #return model, optimizer\n",
    "    # for g in optimizer.param_groups:\n",
    "    #   g['lr'] = g['lr']/LEARNING_ANNEAL\n",
    "    \"\"\"\n",
    "    #print(decoded_preds[0])\n",
    "    if (epoch+1)%2 == 0:\n",
    "        model.eval().cpu()\n",
    "        ckpt_model_filename = \"ckpt_epoch_\" + str(epoch+1) + \"_batch_id_\" + str(batch_idx+1) + \".pth\"\n",
    "        ckpt_model_path = os.path.join(ckpt_save_dir, ckpt_model_filename)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, ckpt_model_path)\n",
    "        model.to(device).train()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    training_loss, train_acc = 0, 0\n",
    "    eer, total_eer = 0, 0\n",
    "    test_loss=0\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, _data in enumerate(test_loader):\n",
    "            inputs, labels, input_lengths, label_lengths = _data \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # output = model(inputs, input_lengths)  # (batch, time, n_class)\n",
    "            output=model(inputs)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            \n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "            for j in range(len(decoded_preds)):\n",
    "                s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "                acc.append(s.ratio())\n",
    "\n",
    "            avg_acc = sum(acc)/len(acc)\n",
    "            writer.add_scalar(\"test_accuracy\", avg_acc, epoch)\n",
    "            writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            print(\"Test Accuracy: {}, Test loss: {}\".format(avg_acc, test_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.weight torch.Size([64, 1, 3, 3])\n",
      "tensor([[[[ 2.0512e-01,  7.2427e-02,  6.2728e-02],\n",
      "          [ 4.3884e-02, -8.3980e-02, -3.0685e-02],\n",
      "          [ 1.2385e-01, -2.1300e-01, -8.8035e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5716e-01,  6.3218e-02,  2.3704e-01],\n",
      "          [-3.9578e-01,  1.0188e-01,  9.4281e-02],\n",
      "          [-3.2622e-02,  5.7981e-02, -4.4567e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3063e-01,  3.5707e-01,  2.2267e-01],\n",
      "          [ 7.7468e-01,  7.0123e-01, -7.3938e-02],\n",
      "          [ 9.9112e-02,  5.4483e-01,  2.7855e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7231e-02,  4.1032e-01,  1.7382e-01],\n",
      "          [-3.0798e-01,  3.0852e-01,  5.9512e-01],\n",
      "          [-4.6495e-01, -2.5291e-01, -2.0049e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7359e-02,  1.5889e-02,  4.0100e-01],\n",
      "          [-3.4750e-02, -3.7033e-01, -5.0606e-02],\n",
      "          [-4.3513e-01,  9.8779e-02,  1.2856e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6491e-01,  2.4393e-01, -1.3148e-01],\n",
      "          [ 3.3702e-02,  1.6991e-01,  1.7112e-01],\n",
      "          [-1.0562e-01,  3.6429e-01,  9.3047e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8632e-01, -4.4191e-02,  2.1685e-01],\n",
      "          [-6.1189e-01,  2.5995e-01, -7.6619e-02],\n",
      "          [-3.6401e-01,  1.8571e-01,  2.0563e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9576e-02,  3.4190e-01,  1.9423e-01],\n",
      "          [ 5.5845e-02, -3.4611e-02,  1.4050e-01],\n",
      "          [ 8.4495e-02, -4.1085e-01, -2.7587e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2866e-02,  2.1226e-01, -3.7865e-01],\n",
      "          [ 3.2890e-01, -1.1556e-01, -2.1615e-01],\n",
      "          [ 2.3487e-01, -2.0715e-01, -3.1950e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6609e-02,  2.3843e-01, -4.1663e-01],\n",
      "          [ 3.9164e-03,  6.6919e-02, -5.3988e-01],\n",
      "          [ 2.5830e-02,  2.7802e-01, -1.5905e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0432e-02, -1.0953e-01, -3.2634e-01],\n",
      "          [-1.6749e-01,  3.8009e-01,  1.8482e-01],\n",
      "          [ 1.7208e-01,  1.3377e-01, -3.2430e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4321e-02,  3.8338e-02, -5.1225e-02],\n",
      "          [ 2.5178e-01,  3.6946e-01, -1.2137e-01],\n",
      "          [ 1.7027e-01, -3.7538e-01,  1.0882e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.0214e-02, -1.2996e-01,  5.9239e-02],\n",
      "          [ 3.2555e-01, -2.2716e-01, -1.4349e-01],\n",
      "          [ 2.0054e-01, -2.0264e-01, -1.7088e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0353e-02, -1.3450e-01,  2.0045e-01],\n",
      "          [-4.0906e-02, -1.9845e-01,  3.3184e-01],\n",
      "          [-1.4721e-01,  8.3992e-02, -7.1550e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0877e-01, -1.9479e-01,  1.1034e-01],\n",
      "          [-5.4187e-01, -4.1254e-01,  1.4150e-01],\n",
      "          [-2.6493e-02, -1.5005e-01,  6.5489e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2113e-01,  2.3204e-01,  1.1229e-01],\n",
      "          [-2.2828e-01, -2.3247e-01,  3.3800e-01],\n",
      "          [-1.9255e-02, -8.4034e-03, -1.3443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1286e-01, -1.0947e-01, -2.2480e-01],\n",
      "          [ 3.3215e-01,  4.1668e-01,  3.8114e-01],\n",
      "          [-1.7602e-01, -8.2998e-02,  9.3387e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5750e-01, -2.9881e-02,  1.2013e-02],\n",
      "          [-8.0545e-02,  4.3307e-01, -2.7006e-01],\n",
      "          [ 1.7804e-01,  1.1021e-01, -1.0363e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4793e-01, -1.5796e-01,  2.7605e-02],\n",
      "          [-3.6901e-01, -4.6455e-01, -4.8060e-01],\n",
      "          [-6.4778e-02,  1.6247e-01,  4.7167e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0949e-01, -5.7672e-01, -4.0504e-01],\n",
      "          [-5.7268e-01, -8.0913e-01, -6.8358e-01],\n",
      "          [-3.6963e-01, -4.3455e-01,  2.6092e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2246e-01, -1.2401e-01,  2.4608e-01],\n",
      "          [ 1.1601e-01, -2.6906e-01,  1.4711e-01],\n",
      "          [-2.5997e-01, -1.8794e-01,  1.2391e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1523e-02, -2.8032e-01,  4.0595e-02],\n",
      "          [ 1.2131e-01, -4.1730e-01, -3.7581e-02],\n",
      "          [-2.9420e-01, -6.0943e-01, -2.3782e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8312e-01,  1.5621e-01,  1.7102e-01],\n",
      "          [-7.7850e-02,  7.3653e-02, -5.3415e-01],\n",
      "          [ 1.5323e-01, -2.4034e-03, -1.5392e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0978e-01, -1.5395e-01, -1.4074e-01],\n",
      "          [ 3.0007e-01, -1.0926e-01, -5.4637e-01],\n",
      "          [ 9.6532e-02,  7.1957e-04, -1.2860e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4349e-01,  8.7756e-02, -1.5372e-01],\n",
      "          [-2.1590e-01,  9.3804e-03,  2.1909e-01],\n",
      "          [-1.4147e-01,  4.9924e-02, -2.8043e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4255e-01, -2.3873e-01,  2.2607e-01],\n",
      "          [-2.7629e-01, -3.0641e-01, -5.2863e-01],\n",
      "          [ 2.3675e-01,  1.2518e-01, -1.2426e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0004e-01, -1.3666e-01, -1.8062e-01],\n",
      "          [ 2.8599e-01,  1.1977e-01, -4.1543e-01],\n",
      "          [-8.6936e-02,  1.4780e-01,  5.0473e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9241e-01,  2.6347e-01,  1.7469e-01],\n",
      "          [-5.5341e-01, -5.9302e-02, -8.2684e-02],\n",
      "          [ 6.8472e-02, -1.2035e-01,  3.5937e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9032e-02, -7.1209e-02,  8.2477e-02],\n",
      "          [ 3.4487e-02, -5.6817e-01, -4.0353e-02],\n",
      "          [-2.6834e-02, -2.0197e-01,  1.1693e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7459e-01,  6.6145e-01,  5.1448e-01],\n",
      "          [ 2.6176e-01, -4.1014e-01, -5.6548e-02],\n",
      "          [-1.6786e-01, -1.9360e-01, -1.0960e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3294e-01,  1.9249e-02, -9.7180e-02],\n",
      "          [-3.1217e-01, -1.7266e-01, -5.1317e-01],\n",
      "          [-1.9872e-02,  1.1049e-01, -1.8751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6602e-01, -4.9492e-01,  1.7568e-01],\n",
      "          [-6.6954e-01, -7.0129e-01, -1.0405e-01],\n",
      "          [-5.4887e-01, -6.1016e-01, -2.6281e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3084e-02, -8.5176e-02,  6.3080e-02],\n",
      "          [-2.5007e-01,  2.6009e-01,  7.4208e-03],\n",
      "          [ 3.5640e-02, -6.1683e-02, -4.7792e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2245e-01, -2.4639e-01,  4.3206e-02],\n",
      "          [ 3.2914e-01,  4.4397e-01,  6.8472e-02],\n",
      "          [ 2.3416e-01,  6.0785e-02, -1.9080e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5229e-01, -1.2929e-02,  3.4038e-02],\n",
      "          [-7.8232e-02,  2.6472e-01,  3.8942e-02],\n",
      "          [-3.1282e-01, -3.6924e-02,  2.4772e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5063e-02, -1.4980e-01, -3.1161e-01],\n",
      "          [ 2.5599e-01, -1.7372e-01,  3.3645e-01],\n",
      "          [-2.1569e-01,  1.7921e-01,  3.3194e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8563e-01,  8.7876e-01,  7.1941e-01],\n",
      "          [-1.2609e-01,  4.5157e-01,  4.6827e-01],\n",
      "          [-2.7254e-01,  2.5400e-01,  3.0850e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3214e-02, -2.1278e-01,  1.6217e-01],\n",
      "          [-5.4556e-02, -3.0917e-01,  1.0176e-01],\n",
      "          [ 2.7379e-04, -2.4704e-01,  2.1067e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3133e-01, -3.8522e-01, -4.0380e-01],\n",
      "          [ 1.1696e-01, -4.8310e-01,  2.4974e-01],\n",
      "          [ 3.2253e-01,  8.6284e-02,  9.2386e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0018e-01, -2.0093e-01,  9.1038e-02],\n",
      "          [ 1.4965e-01, -4.1749e-01,  1.7867e-01],\n",
      "          [ 1.0837e-01,  3.0541e-01,  4.5510e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8297e-02, -1.6623e-02, -5.3597e-01],\n",
      "          [ 2.9539e-01,  1.9934e-01, -2.3657e-01],\n",
      "          [ 2.0357e-01,  1.1881e-01,  1.1671e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6156e-01, -3.0482e-01,  2.0807e-02],\n",
      "          [ 2.0365e-01,  4.0113e-02, -2.9743e-01],\n",
      "          [ 5.0340e-02, -2.8039e-01,  1.0344e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9782e-02,  2.9783e-01,  1.2264e-02],\n",
      "          [-6.6044e-01,  5.7855e-02, -9.6592e-02],\n",
      "          [-3.2578e-01,  3.9868e-03,  3.4449e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2074e-02,  2.8242e-02, -1.8875e-02],\n",
      "          [-1.8753e-01,  3.5192e-01, -1.1002e-01],\n",
      "          [-1.2983e-02,  1.4464e-01, -1.3922e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8282e-01, -1.2147e-01,  5.1399e-02],\n",
      "          [-5.1631e-01, -5.2500e-01,  2.2894e-01],\n",
      "          [ 2.3097e-01, -9.9258e-03,  1.2903e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8800e-01,  3.7943e-01,  6.5280e-01],\n",
      "          [ 3.1783e-01, -1.5063e-01, -1.3963e-01],\n",
      "          [ 9.3543e-02,  1.8863e-01,  2.5276e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7258e-02, -3.7089e-02,  5.0268e-02],\n",
      "          [-2.2194e-01,  1.1021e-01,  7.6248e-02],\n",
      "          [-3.7257e-01,  1.4452e-01, -5.2315e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9949e-01, -8.6319e-02, -2.9700e-01],\n",
      "          [-3.6073e-01,  3.2191e-02,  3.1405e-01],\n",
      "          [ 1.0964e-01, -1.0481e-02,  1.8944e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3581e-01, -2.1880e-01,  1.0742e-01],\n",
      "          [-4.9595e-01, -3.9525e-01, -7.8257e-02],\n",
      "          [-9.8359e-02, -2.3347e-01,  2.4186e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0138e-01, -8.8291e-02,  5.8339e-02],\n",
      "          [-2.7250e-01, -2.9311e-01,  2.8238e-01],\n",
      "          [ 1.9396e-03, -1.1608e-01, -1.7983e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0155e-01,  2.7445e-03, -1.1999e-01],\n",
      "          [-2.0494e-01, -5.9138e-01, -3.1624e-01],\n",
      "          [ 8.2260e-02, -1.2084e-01, -7.5361e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2990e-01,  1.9767e-01,  3.5542e-01],\n",
      "          [-6.3356e-01, -1.8365e-01, -3.0196e-01],\n",
      "          [ 7.8334e-02, -1.5947e-01,  1.9367e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8549e-02, -3.6854e-01,  5.8679e-02],\n",
      "          [ 4.8353e-01,  3.4983e-01,  4.4450e-01],\n",
      "          [-1.7270e-03, -3.6553e-01,  9.5151e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0264e-01, -2.1830e-01, -1.1311e-01],\n",
      "          [ 2.0409e-01, -2.8495e-01,  6.0994e-02],\n",
      "          [ 1.6120e-01,  1.5576e-01, -1.4591e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0357e-01, -2.7002e-01,  2.5564e-01],\n",
      "          [-4.2593e-01,  3.0944e-01,  2.2503e-01],\n",
      "          [-2.7746e-01, -1.3165e-01,  2.1032e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0692e-01,  1.0331e-01, -2.8482e-01],\n",
      "          [-8.4799e-02,  1.0237e-01, -2.5629e-01],\n",
      "          [ 2.0744e-01,  1.8704e-01, -3.6797e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6225e-01, -6.6835e-02, -2.5346e-01],\n",
      "          [ 2.3883e-01, -1.5725e-01,  3.8760e-02],\n",
      "          [-2.2974e-01,  4.7838e-02,  1.9911e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0324e-01, -2.9615e-01,  4.8117e-02],\n",
      "          [ 5.5595e-02,  3.0441e-01, -3.7790e-02],\n",
      "          [-3.2683e-01, -4.7054e-02,  3.8993e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9705e-02, -3.4611e-02, -2.3606e-01],\n",
      "          [ 3.9786e-01,  4.3021e-01,  6.0649e-03],\n",
      "          [ 2.9467e-01, -1.0929e-01, -9.0561e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0033e-01,  2.0945e-02, -1.8067e-01],\n",
      "          [-3.0200e-01, -1.3686e-01,  3.2977e-01],\n",
      "          [-1.5876e-01, -1.7782e-01,  1.2271e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6824e-01,  1.0307e-01, -3.7893e-02],\n",
      "          [-2.7402e-01,  2.4794e-01,  8.9942e-02],\n",
      "          [-2.7369e-01,  2.8411e-02, -7.9168e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.5255e-02,  1.2479e-01, -1.3098e-02],\n",
      "          [-1.7057e-01,  2.5699e-01,  2.9000e-03],\n",
      "          [-6.4616e-02,  9.9051e-02,  9.3525e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5183e-02, -6.4697e-02, -2.0714e-01],\n",
      "          [ 7.2530e-02,  3.3588e-01,  6.0231e-01],\n",
      "          [-2.3746e-01, -1.0280e-01,  5.7296e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5748e-01,  2.7084e-01, -1.2917e-01],\n",
      "          [-4.5814e-01,  1.1190e-01,  2.3448e-03],\n",
      "          [-3.2149e-01,  1.5419e-01,  4.4123e-02]]]])\n",
      "cnn.bias torch.Size([64])\n",
      "tensor([-0.2349,  0.2491, -0.1681,  0.3627,  0.1046, -0.0633, -0.2693, -0.1597,\n",
      "         0.1694,  0.2238,  0.2917, -0.2622, -0.2930, -0.0591, -0.1677, -0.2492,\n",
      "         0.2570, -0.0773,  0.0644,  0.2140, -0.1997,  0.1447,  0.1133,  0.1486,\n",
      "         0.3318, -0.1719, -0.0824,  0.2153, -0.1530,  0.3396, -0.1010, -0.2149,\n",
      "         0.2553, -0.1794, -0.0218,  0.0545, -0.1405,  0.0708, -0.2486,  0.0344,\n",
      "        -0.0408,  0.2783,  0.0192,  0.2424, -0.1290, -0.1767,  0.0871, -0.1507,\n",
      "         0.0900, -0.3183, -0.0587, -0.1074,  0.1103, -0.0763, -0.1154, -0.3621,\n",
      "         0.2006,  0.0686, -0.0460, -0.3269,  0.2922, -0.2638, -0.0293,  0.2495])\n",
      "rescnn_layers.0.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-0.2141, -0.1755, -0.1142],\n",
      "          [ 0.0282,  0.1589,  0.1762],\n",
      "          [ 0.0305,  0.0628,  0.0718]],\n",
      "\n",
      "         [[ 0.0746,  0.0256, -0.1330],\n",
      "          [ 0.0939,  0.0757, -0.0381],\n",
      "          [ 0.0210, -0.0994, -0.2604]],\n",
      "\n",
      "         [[-0.1318, -0.0546, -0.0459],\n",
      "          [-0.0269, -0.0234, -0.0774],\n",
      "          [-0.0995, -0.0478, -0.1239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0008, -0.0620,  0.0255],\n",
      "          [ 0.0312, -0.0057,  0.0707],\n",
      "          [ 0.0369,  0.0177, -0.0453]],\n",
      "\n",
      "         [[-0.0955, -0.0813, -0.0799],\n",
      "          [-0.0202,  0.0400,  0.0373],\n",
      "          [ 0.0118,  0.0683,  0.0446]],\n",
      "\n",
      "         [[ 0.1022,  0.0467, -0.1982],\n",
      "          [ 0.0607, -0.0195, -0.1846],\n",
      "          [ 0.0695,  0.0022, -0.1423]]],\n",
      "\n",
      "\n",
      "        [[[-0.0248, -0.0803, -0.0272],\n",
      "          [ 0.0954,  0.1515,  0.0686],\n",
      "          [ 0.1141,  0.1426,  0.0497]],\n",
      "\n",
      "         [[ 0.0224, -0.1296, -0.1380],\n",
      "          [-0.0332, -0.2041, -0.2246],\n",
      "          [-0.0214, -0.2423, -0.2103]],\n",
      "\n",
      "         [[ 0.0304, -0.0479, -0.0676],\n",
      "          [ 0.1269,  0.0464, -0.0746],\n",
      "          [ 0.0394, -0.0598, -0.0679]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0464, -0.0446, -0.0151],\n",
      "          [ 0.0445, -0.0650,  0.0222],\n",
      "          [-0.0319, -0.0778, -0.0679]],\n",
      "\n",
      "         [[-0.1108, -0.1119, -0.0870],\n",
      "          [ 0.1022,  0.0348, -0.0102],\n",
      "          [ 0.0318,  0.0434,  0.0600]],\n",
      "\n",
      "         [[ 0.0340, -0.1761, -0.0515],\n",
      "          [ 0.0310, -0.1968, -0.1161],\n",
      "          [ 0.0477, -0.1904, -0.1315]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0199,  0.1120,  0.0489],\n",
      "          [ 0.0873, -0.0266,  0.0655],\n",
      "          [-0.0303, -0.0029,  0.0663]],\n",
      "\n",
      "         [[ 0.0348, -0.1031, -0.0022],\n",
      "          [-0.0393,  0.0260,  0.0253],\n",
      "          [-0.0029,  0.0404,  0.0299]],\n",
      "\n",
      "         [[-0.0494, -0.0958, -0.1547],\n",
      "          [-0.1175, -0.1922, -0.0928],\n",
      "          [-0.1993, -0.1757, -0.1106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0723, -0.0071, -0.0038],\n",
      "          [-0.0118, -0.0889,  0.0723],\n",
      "          [-0.0594, -0.0207, -0.0320]],\n",
      "\n",
      "         [[-0.0463, -0.0083, -0.0379],\n",
      "          [-0.0490, -0.1570, -0.0031],\n",
      "          [-0.1785, -0.2494, -0.0830]],\n",
      "\n",
      "         [[-0.0038, -0.0518, -0.0905],\n",
      "          [ 0.0423, -0.0429, -0.0382],\n",
      "          [ 0.0043,  0.0758, -0.0340]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0220,  0.0042],\n",
      "          [ 0.0686, -0.0052,  0.0604],\n",
      "          [-0.0146,  0.0117, -0.0014]],\n",
      "\n",
      "         [[-0.0548,  0.0105,  0.0935],\n",
      "          [-0.1295, -0.0325,  0.0912],\n",
      "          [-0.0351, -0.1065, -0.0701]],\n",
      "\n",
      "         [[-0.0476, -0.1570, -0.1241],\n",
      "          [-0.1238, -0.0840, -0.1288],\n",
      "          [-0.0670, -0.0265, -0.1562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714, -0.0952, -0.0513],\n",
      "          [ 0.0785, -0.0346, -0.0693],\n",
      "          [ 0.1114, -0.0270, -0.0569]],\n",
      "\n",
      "         [[-0.0082, -0.1878, -0.1386],\n",
      "          [-0.0521, -0.2119, -0.2024],\n",
      "          [ 0.0829,  0.0083, -0.1015]],\n",
      "\n",
      "         [[-0.0704,  0.0114, -0.0353],\n",
      "          [-0.0185,  0.0364, -0.0150],\n",
      "          [ 0.0611, -0.0373, -0.0578]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208, -0.1421, -0.0708],\n",
      "          [ 0.1189, -0.1747, -0.1772],\n",
      "          [ 0.1158, -0.1927, -0.2298]],\n",
      "\n",
      "         [[-0.0123,  0.1583,  0.0897],\n",
      "          [ 0.0236,  0.1609,  0.0830],\n",
      "          [ 0.0434,  0.0150,  0.0365]],\n",
      "\n",
      "         [[-0.0255, -0.0828, -0.0647],\n",
      "          [-0.0410, -0.0543, -0.1736],\n",
      "          [ 0.0459, -0.0817, -0.1931]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0644, -0.0098,  0.0472],\n",
      "          [-0.0597,  0.0486,  0.1453],\n",
      "          [-0.0446, -0.0845,  0.0923]],\n",
      "\n",
      "         [[-0.0110,  0.0598,  0.0832],\n",
      "          [-0.0710,  0.0892,  0.0536],\n",
      "          [-0.0884, -0.0432, -0.0138]],\n",
      "\n",
      "         [[-0.0465,  0.1468,  0.0851],\n",
      "          [-0.0781,  0.1972,  0.0817],\n",
      "          [-0.0452,  0.0608, -0.0015]]],\n",
      "\n",
      "\n",
      "        [[[-0.0774, -0.0302,  0.0644],\n",
      "          [ 0.1069,  0.1132,  0.1358],\n",
      "          [ 0.1527,  0.0649,  0.0943]],\n",
      "\n",
      "         [[-0.0747, -0.0250,  0.0065],\n",
      "          [-0.1648, -0.1073, -0.0730],\n",
      "          [-0.2819, -0.2129, -0.0313]],\n",
      "\n",
      "         [[-0.0826, -0.0718, -0.0511],\n",
      "          [ 0.0424, -0.0039,  0.0036],\n",
      "          [-0.0182, -0.0847, -0.1591]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473,  0.0559,  0.0349],\n",
      "          [ 0.1272, -0.0742, -0.0216],\n",
      "          [-0.0214, -0.0555, -0.1111]],\n",
      "\n",
      "         [[-0.1752, -0.1544, -0.0503],\n",
      "          [ 0.0926,  0.0490,  0.0460],\n",
      "          [-0.0950, -0.0420,  0.0203]],\n",
      "\n",
      "         [[-0.0196, -0.0176, -0.0317],\n",
      "          [-0.0421, -0.1692, -0.1179],\n",
      "          [ 0.0041, -0.0410, -0.0674]]]])\n",
      "rescnn_layers.0.cnn1.bias torch.Size([64])\n",
      "tensor([ 0.0670, -0.0926, -0.0270, -0.0124, -0.0323, -0.0277,  0.0577, -0.0231,\n",
      "        -0.0204, -0.0289, -0.0509, -0.0267, -0.0274, -0.0318,  0.0601,  0.0318,\n",
      "         0.0161, -0.0066, -0.0066,  0.0186, -0.0006, -0.0156, -0.0048, -0.0095,\n",
      "         0.0024,  0.0155, -0.0074, -0.0052, -0.0179,  0.0583, -0.0056,  0.0012,\n",
      "         0.0385, -0.0107,  0.0002,  0.0188,  0.0001,  0.0561, -0.0024, -0.0454,\n",
      "         0.0371,  0.0117, -0.0131,  0.0120,  0.0051, -0.0225, -0.0095,  0.0089,\n",
      "         0.0136,  0.0699,  0.0441, -0.0633,  0.0439, -0.0029,  0.0067, -0.0063,\n",
      "        -0.0251,  0.0049,  0.0275, -0.0859, -0.0346,  0.0271, -0.0181, -0.0360])\n",
      "rescnn_layers.0.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 2.0576e-02, -2.1785e-02,  3.7911e-02],\n",
      "          [-5.9223e-02, -1.9010e-02,  2.5934e-02],\n",
      "          [ 8.7968e-02,  1.0768e-01,  5.6846e-03]],\n",
      "\n",
      "         [[ 5.0613e-02, -6.4800e-02, -1.1734e-01],\n",
      "          [-5.0253e-02, -5.8591e-02, -3.1467e-02],\n",
      "          [-1.8586e-02, -2.3813e-02,  2.6392e-02]],\n",
      "\n",
      "         [[ 1.3258e-01, -8.1380e-02, -1.0097e-01],\n",
      "          [ 1.0595e-01, -2.2372e-01, -2.3417e-01],\n",
      "          [ 1.9317e-02, -1.6356e-01, -1.1986e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8677e-02, -3.8096e-02, -6.9178e-02],\n",
      "          [-1.2011e-01, -2.3454e-01, -7.9760e-02],\n",
      "          [-6.2556e-02, -1.2174e-01, -7.0874e-02]],\n",
      "\n",
      "         [[-1.6591e-02, -3.9644e-02, -2.5731e-01],\n",
      "          [ 1.1230e-03, -3.3642e-02, -3.3945e-01],\n",
      "          [-1.1867e-01,  4.1947e-02, -9.0289e-02]],\n",
      "\n",
      "         [[ 1.4092e-01,  2.4097e-02, -1.5459e-01],\n",
      "          [ 3.6032e-02, -4.5555e-02, -1.6221e-01],\n",
      "          [ 2.5228e-02,  7.5996e-02, -9.1947e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.8549e-02,  5.5993e-03,  1.3311e-01],\n",
      "          [-7.0754e-02,  7.5233e-02,  1.4334e-01],\n",
      "          [-2.2690e-02,  7.3089e-02,  9.0624e-02]],\n",
      "\n",
      "         [[-2.0387e-01, -1.4446e-01,  2.9523e-02],\n",
      "          [-2.2184e-01, -7.5039e-02,  6.4789e-02],\n",
      "          [-1.5565e-01, -1.7616e-01, -8.5754e-02]],\n",
      "\n",
      "         [[ 7.1056e-02,  7.9873e-02,  1.1334e-01],\n",
      "          [ 3.3217e-02,  4.3242e-02,  1.0993e-01],\n",
      "          [ 2.2704e-01,  1.3097e-01,  8.6777e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8262e-02, -1.8809e-02,  5.8511e-02],\n",
      "          [-1.1009e-01, -4.8411e-02,  2.3054e-02],\n",
      "          [-4.6436e-02,  1.5078e-02,  1.6691e-02]],\n",
      "\n",
      "         [[-9.5735e-03, -5.4519e-02, -7.2333e-02],\n",
      "          [ 2.8960e-02,  4.7751e-03, -1.2229e-01],\n",
      "          [ 7.2956e-03,  2.0021e-02, -5.5161e-02]],\n",
      "\n",
      "         [[-3.0649e-02,  1.7853e-02, -3.9024e-03],\n",
      "          [-5.4525e-02,  5.1862e-03, -5.2568e-02],\n",
      "          [-5.6302e-02, -8.0028e-02, -3.7417e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0648e-01,  3.3192e-02,  1.4074e-02],\n",
      "          [-1.8545e-02, -3.5787e-02,  3.1618e-02],\n",
      "          [ 8.0261e-02,  3.9688e-02,  4.8226e-03]],\n",
      "\n",
      "         [[-8.5619e-02, -3.9870e-02,  1.3044e-02],\n",
      "          [-2.7332e-02,  3.9608e-02,  6.3507e-02],\n",
      "          [-4.2133e-02,  4.7058e-05,  4.2087e-03]],\n",
      "\n",
      "         [[-6.0749e-02, -2.6404e-02, -7.1081e-03],\n",
      "          [ 1.0739e-02,  3.2984e-04,  5.0143e-02],\n",
      "          [ 5.6721e-02,  5.6294e-02,  5.8720e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.8488e-02,  2.4494e-02, -3.0422e-02],\n",
      "          [-3.7239e-02, -2.6117e-02, -5.2497e-02],\n",
      "          [ 4.4846e-02,  9.0881e-02, -1.8369e-02]],\n",
      "\n",
      "         [[ 5.5143e-02, -3.7287e-02, -2.8532e-02],\n",
      "          [ 4.8586e-02, -6.3212e-02, -3.4962e-02],\n",
      "          [ 9.6235e-03, -2.9359e-02, -6.3037e-03]],\n",
      "\n",
      "         [[-5.8460e-02, -5.1727e-02, -2.6186e-02],\n",
      "          [ 4.9847e-02,  1.0395e-01, -4.0421e-02],\n",
      "          [-1.4112e-02, -2.3065e-02, -4.4274e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7887e-01,  2.2280e-01,  1.4673e-01],\n",
      "          [ 5.9862e-02,  5.4842e-02, -1.0159e-02],\n",
      "          [ 1.3650e-01,  4.7117e-02,  5.5462e-05]],\n",
      "\n",
      "         [[-7.1415e-02,  3.6543e-02,  9.9435e-02],\n",
      "          [-7.1756e-02, -1.5302e-01, -5.7663e-02],\n",
      "          [ 3.9471e-02, -4.5030e-02,  3.6482e-02]],\n",
      "\n",
      "         [[ 1.3518e-02,  7.2749e-02,  1.1017e-01],\n",
      "          [ 8.0320e-02,  6.5010e-02,  7.5201e-02],\n",
      "          [ 1.6732e-02, -2.4623e-02,  5.4454e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2358e-01,  8.0975e-03, -1.2958e-01],\n",
      "          [-9.1446e-03,  3.7356e-02, -3.3085e-02],\n",
      "          [ 7.2339e-03,  1.5716e-01, -8.2406e-02]],\n",
      "\n",
      "         [[-3.4905e-03, -1.9275e-02, -1.1512e-02],\n",
      "          [ 1.2422e-01,  1.8310e-02,  3.3854e-02],\n",
      "          [ 8.9592e-03,  5.9347e-02, -3.0246e-02]],\n",
      "\n",
      "         [[ 3.3616e-02,  9.2579e-02, -3.0461e-04],\n",
      "          [-1.0281e-01, -5.4000e-02, -1.0368e-01],\n",
      "          [-1.0847e-03,  4.3425e-02, -3.4350e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3602e-02, -9.1330e-03,  1.1507e-01],\n",
      "          [-1.7717e-03, -2.2444e-02,  1.8815e-01],\n",
      "          [-2.7639e-01, -2.3101e-01, -7.9659e-03]],\n",
      "\n",
      "         [[ 1.1576e-02, -1.5344e-02,  4.2318e-02],\n",
      "          [ 3.4610e-02, -9.8214e-02,  1.6902e-02],\n",
      "          [-8.0119e-02, -1.8502e-01, -8.5222e-02]],\n",
      "\n",
      "         [[-5.2829e-02, -5.5972e-02,  8.9319e-02],\n",
      "          [-1.2300e-02,  4.9558e-02,  7.2477e-02],\n",
      "          [-3.9540e-02, -7.3514e-02,  1.7363e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1342e-01,  9.7290e-02,  4.2318e-02],\n",
      "          [ 1.5314e-01,  1.5081e-02,  3.1425e-03],\n",
      "          [ 1.4258e-01, -5.2406e-02,  5.2957e-02]],\n",
      "\n",
      "         [[ 8.4500e-02, -2.9767e-02,  1.0408e-01],\n",
      "          [ 9.1393e-02, -5.6133e-02,  1.0158e-01],\n",
      "          [ 1.1410e-02,  4.5759e-02,  7.6145e-02]],\n",
      "\n",
      "         [[ 8.5474e-02,  3.4304e-02,  6.5937e-02],\n",
      "          [ 1.7229e-01, -2.2551e-02,  1.0224e-01],\n",
      "          [-4.1144e-02, -2.2531e-01, -1.2221e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.6460e-02, -5.8418e-02, -5.6188e-02],\n",
      "          [-1.1274e-01, -3.1090e-02, -9.4618e-02],\n",
      "          [-2.4541e-02,  3.2424e-02,  2.5589e-02]],\n",
      "\n",
      "         [[-2.7813e-02, -1.5174e-03, -2.2712e-02],\n",
      "          [-6.5988e-02, -4.4334e-02, -4.4825e-02],\n",
      "          [-3.0733e-02,  3.8974e-02,  7.0953e-02]],\n",
      "\n",
      "         [[ 1.1879e-01,  7.8404e-02,  1.8984e-01],\n",
      "          [ 1.7664e-03,  4.6735e-02,  7.0281e-02],\n",
      "          [ 5.6823e-02,  8.2740e-02,  6.1675e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3490e-02,  1.8776e-02,  6.0932e-03],\n",
      "          [ 3.1324e-03,  8.5048e-02,  1.1355e-01],\n",
      "          [ 1.2602e-01,  3.8650e-02,  1.3158e-01]],\n",
      "\n",
      "         [[-9.5320e-03,  8.7120e-03,  7.8121e-02],\n",
      "          [-8.7206e-02, -1.0572e-02,  6.7282e-02],\n",
      "          [-7.8292e-03,  7.6017e-02,  1.2100e-01]],\n",
      "\n",
      "         [[ 7.5505e-02,  1.9892e-02,  4.3423e-02],\n",
      "          [ 2.2583e-02, -7.4437e-03,  6.3248e-02],\n",
      "          [ 4.3937e-02,  6.8176e-02,  1.7424e-01]]]])\n",
      "rescnn_layers.0.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0501,  0.0495, -0.0760,  0.0492,  0.0428,  0.0514,  0.0400,  0.0575,\n",
      "         0.0266, -0.1046,  0.1123, -0.1123, -0.0720,  0.0400,  0.0425,  0.0032,\n",
      "         0.0901, -0.0403, -0.0325,  0.0742, -0.0061,  0.0056,  0.0735, -0.0067,\n",
      "         0.0303, -0.0771,  0.0106,  0.0492,  0.0370,  0.1004,  0.0594, -0.0365,\n",
      "        -0.0166,  0.0291,  0.0221, -0.0320, -0.0856,  0.0685,  0.0589,  0.0878,\n",
      "        -0.0766,  0.0182, -0.0404,  0.0905, -0.0421, -0.0430, -0.0971, -0.0767,\n",
      "         0.0763, -0.1260,  0.0641,  0.1260, -0.0206, -0.0028, -0.0107, -0.1141,\n",
      "         0.0459, -0.0475, -0.0081, -0.0695,  0.0350, -0.0870, -0.0041, -0.0021])\n",
      "rescnn_layers.0.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.1641, 1.0815, 0.9759, 0.8925, 0.8272, 0.6713, 0.7322, 0.6275, 0.6731,\n",
      "        0.8523, 0.8983, 0.7246, 0.7887, 0.8934, 1.0591, 0.9162, 1.0240, 0.9815,\n",
      "        0.9972, 1.0348, 1.0230, 1.0546, 1.0259, 1.0440, 1.0254, 1.0227, 1.0449,\n",
      "        1.0403, 1.0577, 1.0449, 1.0083, 1.0229, 1.0344, 1.0241, 0.9841, 0.9936,\n",
      "        0.9943, 1.0218, 1.0264, 1.0908, 1.0613, 1.0514, 1.0174, 1.0617, 1.0062,\n",
      "        0.9954, 1.0105, 1.0116, 1.0114, 0.9902, 0.9876, 1.0253, 1.0026, 1.0197,\n",
      "        0.9798, 0.9720, 0.9726, 0.9829, 0.9866, 1.0017, 1.0287, 1.0345, 1.0183,\n",
      "        1.1058])\n",
      "rescnn_layers.0.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0323, -0.0050, -0.0086, -0.0083,  0.0013, -0.0322,  0.0119, -0.0261,\n",
      "        -0.0085,  0.0062,  0.0172,  0.0124, -0.0094, -0.0035, -0.0151, -0.0135,\n",
      "         0.0097,  0.0131,  0.0059,  0.0259, -0.0108, -0.0061,  0.0020, -0.0043,\n",
      "        -0.0146,  0.0270, -0.0191, -0.0074, -0.0067, -0.0270,  0.0141, -0.0059,\n",
      "         0.0031,  0.0007,  0.0003,  0.0447,  0.0344,  0.0345, -0.0250, -0.0233,\n",
      "        -0.0335,  0.0077, -0.0041, -0.0281,  0.0071,  0.0018,  0.0088,  0.0132,\n",
      "         0.0056,  0.0100,  0.0235, -0.0102, -0.0092, -0.0075, -0.0102, -0.0074,\n",
      "         0.0014,  0.0012,  0.0072, -0.0009,  0.0045, -0.0023, -0.0044, -0.0016])\n",
      "rescnn_layers.0.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0429, 0.8819, 0.9408, 1.0345, 0.7583, 0.8342, 0.7799, 0.8674, 0.9994,\n",
      "        1.0302, 0.9035, 0.8074, 0.8812, 1.0015, 1.0810, 0.9876, 1.0997, 1.0486,\n",
      "        1.0472, 1.0396, 1.0516, 1.0585, 1.0288, 1.0754, 1.0476, 1.0445, 1.0033,\n",
      "        1.0308, 1.0296, 1.0668, 1.0297, 1.0088, 1.0645, 1.0887, 1.0263, 1.0059,\n",
      "        0.9990, 0.9927, 1.0365, 1.0534, 1.0416, 1.0129, 1.0118, 0.9968, 1.0289,\n",
      "        1.0139, 1.0793, 0.9746, 0.9913, 1.0258, 0.9785, 0.9664, 1.0171, 0.9623,\n",
      "        0.9660, 0.9685, 0.9617, 0.9871, 0.9749, 0.9376, 0.9258, 0.9800, 0.9868,\n",
      "        0.9478])\n",
      "rescnn_layers.0.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0608, -0.0293,  0.0134,  0.0423,  0.0436,  0.0178,  0.0216,  0.0061,\n",
      "         0.0080,  0.0472,  0.0311,  0.0124, -0.0008, -0.0063, -0.0048, -0.0012,\n",
      "        -0.0179, -0.0113,  0.0068,  0.0084, -0.0039, -0.0152,  0.0002, -0.0189,\n",
      "         0.0022, -0.0002, -0.0142, -0.0234, -0.0358, -0.0034, -0.0114, -0.0256,\n",
      "        -0.0212, -0.0103, -0.0046, -0.0107, -0.0252, -0.0368, -0.0114, -0.0059,\n",
      "        -0.0075, -0.0068, -0.0039, -0.0126, -0.0156, -0.0236, -0.0078, -0.0029,\n",
      "         0.0022,  0.0056, -0.0183, -0.0056, -0.0047, -0.0104, -0.0101,  0.0008,\n",
      "         0.0036, -0.0051, -0.0147, -0.0154, -0.0120, -0.0055, -0.0096, -0.0283])\n",
      "rescnn_layers.1.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-8.0460e-02,  2.6712e-02,  5.3580e-02],\n",
      "          [-5.2312e-03,  3.1687e-02,  7.2675e-02],\n",
      "          [-6.1359e-02, -6.5073e-02,  1.3241e-02]],\n",
      "\n",
      "         [[ 3.3060e-02,  2.5672e-02,  1.4951e-01],\n",
      "          [-4.1389e-02, -3.4545e-02,  1.1119e-01],\n",
      "          [-1.0491e-01, -1.4236e-01,  2.7737e-02]],\n",
      "\n",
      "         [[-4.0922e-02,  3.1610e-02,  1.6839e-01],\n",
      "          [-1.1863e-01, -1.5810e-01, -3.4358e-02],\n",
      "          [-8.0108e-02, -2.2599e-01, -1.7670e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7737e-02,  3.7471e-02,  6.9589e-02],\n",
      "          [-1.4482e-01, -6.5917e-02,  1.0690e-01],\n",
      "          [-1.2402e-01, -1.3422e-01,  1.1338e-01]],\n",
      "\n",
      "         [[-5.9005e-02,  1.1353e-02,  3.7000e-02],\n",
      "          [-2.0436e-02,  1.7345e-01,  1.8564e-01],\n",
      "          [ 5.3624e-02,  1.2995e-01,  1.0567e-01]],\n",
      "\n",
      "         [[-3.6062e-02, -7.7854e-02, -1.7789e-02],\n",
      "          [ 6.1844e-03, -6.8946e-02, -4.9895e-03],\n",
      "          [ 4.0278e-03, -3.2861e-02, -6.9068e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9711e-02,  5.0515e-02, -4.6614e-03],\n",
      "          [ 1.3345e-01,  2.9549e-02, -4.6067e-02],\n",
      "          [ 1.5513e-02,  1.2636e-02, -3.5073e-02]],\n",
      "\n",
      "         [[-5.5780e-02,  1.0948e-01, -1.0968e-02],\n",
      "          [-1.2212e-01,  1.5351e-01,  9.2362e-03],\n",
      "          [-1.2885e-02,  1.2261e-01,  9.3786e-02]],\n",
      "\n",
      "         [[-4.6946e-02, -6.9868e-02,  4.3961e-02],\n",
      "          [-8.8357e-02, -2.4405e-02,  8.3489e-02],\n",
      "          [-4.4652e-02, -1.1129e-02,  3.1186e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1213e-03,  1.5698e-01,  8.8067e-02],\n",
      "          [-1.2146e-02,  1.6695e-01,  6.8060e-02],\n",
      "          [ 5.3142e-03,  1.0266e-01,  1.1384e-01]],\n",
      "\n",
      "         [[-5.7364e-02, -1.9911e-02,  7.7978e-02],\n",
      "          [ 2.8826e-02,  3.6489e-02,  5.9194e-02],\n",
      "          [ 3.3459e-02, -4.9736e-02,  9.0338e-02]],\n",
      "\n",
      "         [[-1.3478e-01, -5.5428e-02, -2.8080e-02],\n",
      "          [-4.3336e-03,  1.1392e-02, -2.8974e-02],\n",
      "          [ 7.5650e-02,  4.9885e-02, -5.4214e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6504e-02, -4.6791e-02, -8.6921e-02],\n",
      "          [ 3.5315e-02, -7.3972e-02, -8.3147e-02],\n",
      "          [ 6.6245e-03, -1.0019e-01, -1.2049e-01]],\n",
      "\n",
      "         [[ 1.6967e-02, -1.1867e-01,  1.0285e-01],\n",
      "          [ 5.0784e-02, -1.1540e-01,  1.5692e-01],\n",
      "          [-2.1355e-02, -6.1353e-02,  7.1209e-02]],\n",
      "\n",
      "         [[-5.9827e-02, -1.6571e-01, -5.2584e-02],\n",
      "          [-1.6147e-01, -1.2196e-01, -5.6559e-02],\n",
      "          [-2.3511e-01, -1.3637e-01, -5.5545e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.8161e-03,  5.3999e-03,  2.9604e-02],\n",
      "          [-2.4087e-04, -5.0260e-02,  8.9658e-02],\n",
      "          [-4.8303e-02, -3.6899e-02,  1.3987e-02]],\n",
      "\n",
      "         [[-1.3074e-02, -2.8221e-02,  9.5708e-02],\n",
      "          [-1.5903e-03,  1.2784e-02,  9.0106e-02],\n",
      "          [-3.4575e-02, -4.9874e-02, -1.2591e-02]],\n",
      "\n",
      "         [[ 1.1905e-01,  1.2348e-01,  1.6692e-01],\n",
      "          [ 1.1351e-02,  8.0947e-02,  1.4698e-01],\n",
      "          [-5.2076e-03,  4.4724e-02,  1.5151e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.6627e-03,  4.4909e-02, -1.8274e-02],\n",
      "          [ 4.5190e-02,  5.6581e-02, -1.0860e-02],\n",
      "          [ 2.4967e-02,  1.2148e-02, -8.1816e-03]],\n",
      "\n",
      "         [[ 7.8431e-02,  1.1523e-01, -2.8977e-02],\n",
      "          [ 8.0284e-02,  1.3109e-01,  4.1100e-02],\n",
      "          [-8.0638e-03,  2.2019e-02, -8.6583e-03]],\n",
      "\n",
      "         [[ 9.3663e-02,  4.8778e-02,  7.2342e-02],\n",
      "          [ 7.7813e-03, -1.5737e-03, -3.3255e-02],\n",
      "          [ 6.6718e-03, -6.6718e-02, -2.6285e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9911e-02, -9.9675e-02, -1.0442e-03],\n",
      "          [ 3.8685e-02, -2.5320e-02, -6.1283e-02],\n",
      "          [ 5.9057e-02,  4.9649e-02, -1.3586e-02]],\n",
      "\n",
      "         [[ 3.9972e-02,  3.6024e-02,  1.2523e-01],\n",
      "          [-1.2781e-03,  4.8158e-02,  8.8909e-02],\n",
      "          [ 1.8040e-02, -8.9311e-02,  3.7851e-03]],\n",
      "\n",
      "         [[-3.3122e-02, -3.5571e-02, -3.5716e-03],\n",
      "          [ 4.9320e-02,  1.1461e-02, -3.4023e-02],\n",
      "          [ 5.5862e-02, -7.1630e-03,  1.3577e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9002e-02, -1.0428e-01, -1.2537e-01],\n",
      "          [-2.5536e-02, -1.5328e-02, -5.7772e-02],\n",
      "          [-7.3616e-03, -3.4536e-02, -5.1775e-02]],\n",
      "\n",
      "         [[ 2.5917e-02,  2.3932e-02,  8.6528e-02],\n",
      "          [-2.8233e-03, -3.0395e-02,  3.8214e-02],\n",
      "          [-1.1279e-03, -2.2615e-02, -7.7240e-02]],\n",
      "\n",
      "         [[-5.2656e-03, -9.8655e-02, -8.7501e-02],\n",
      "          [-4.1923e-02, -2.3179e-02, -4.3922e-02],\n",
      "          [-1.1412e-01, -6.6167e-02,  2.8247e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1253e-01, -9.6192e-02, -1.8888e-01],\n",
      "          [ 5.3819e-03, -9.5201e-02, -1.5596e-01],\n",
      "          [-4.1566e-02, -9.7623e-02, -2.3142e-01]],\n",
      "\n",
      "         [[ 3.3529e-02, -6.0362e-02, -1.0054e-01],\n",
      "          [-4.6571e-02, -1.1550e-01, -1.4898e-01],\n",
      "          [-8.6990e-02, -1.6290e-01, -1.2979e-01]],\n",
      "\n",
      "         [[-1.1023e-02, -3.5644e-02,  7.0606e-02],\n",
      "          [-3.0199e-02, -7.7858e-03,  2.1030e-02],\n",
      "          [ 4.3620e-04, -1.2168e-02,  1.0160e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8130e-03, -6.6883e-02, -2.9503e-01],\n",
      "          [-5.1896e-02, -7.2360e-03, -2.8954e-01],\n",
      "          [-5.0364e-02, -3.2188e-03, -1.8965e-01]],\n",
      "\n",
      "         [[-1.9354e-01,  1.0794e-01, -2.1304e-02],\n",
      "          [-1.8006e-01,  1.0397e-01,  6.0154e-02],\n",
      "          [-9.9376e-02,  2.9864e-02,  3.0681e-02]],\n",
      "\n",
      "         [[ 4.9466e-02, -5.6756e-02, -1.2047e-01],\n",
      "          [ 4.4018e-02,  2.9156e-02,  4.0572e-02],\n",
      "          [-3.3636e-02, -6.9007e-02, -3.5480e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3943e-02,  3.7026e-02, -3.1583e-03],\n",
      "          [-1.0895e-01, -1.4635e-01, -1.5149e-01],\n",
      "          [-5.8374e-02, -9.5990e-02, -4.7105e-02]],\n",
      "\n",
      "         [[ 5.6968e-02, -6.0881e-02, -7.7261e-02],\n",
      "          [ 6.5705e-02,  2.3583e-02, -2.4534e-03],\n",
      "          [ 1.2632e-01, -2.5378e-02,  1.5506e-02]],\n",
      "\n",
      "         [[-1.8224e-01, -2.6856e-02, -4.9183e-03],\n",
      "          [-1.3390e-01,  4.3054e-02,  4.1348e-02],\n",
      "          [-4.7544e-02,  1.5984e-02,  4.3903e-02]]]])\n",
      "rescnn_layers.1.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0327, -0.0333,  0.0154,  0.0232, -0.0311,  0.0218, -0.0103,  0.0263,\n",
      "         0.0139, -0.0177,  0.0112,  0.0367, -0.0361,  0.0427, -0.0308, -0.0317,\n",
      "         0.0128,  0.0249,  0.0385,  0.0319,  0.0040, -0.0038, -0.0291,  0.0020,\n",
      "         0.0263, -0.0381,  0.0371, -0.0227,  0.0259,  0.0039, -0.0250,  0.0046,\n",
      "        -0.0043,  0.0316, -0.0293, -0.0146,  0.0284, -0.0416,  0.0105,  0.0248,\n",
      "         0.0342,  0.0376, -0.0175, -0.0100, -0.0356, -0.0188, -0.0054,  0.0189,\n",
      "         0.0004,  0.0179,  0.0254,  0.0149,  0.0061, -0.0414, -0.0139, -0.0089,\n",
      "         0.0095, -0.0385,  0.0409, -0.0033, -0.0389, -0.0264, -0.0129,  0.0117])\n",
      "rescnn_layers.1.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 0.0185, -0.0009, -0.0792],\n",
      "          [-0.0282, -0.0212, -0.2501],\n",
      "          [ 0.0604,  0.0983, -0.1515]],\n",
      "\n",
      "         [[-0.0517,  0.0367, -0.0036],\n",
      "          [-0.1060,  0.0248, -0.0033],\n",
      "          [-0.0723,  0.0111,  0.0405]],\n",
      "\n",
      "         [[ 0.0575, -0.0406,  0.0177],\n",
      "          [ 0.0423, -0.1491, -0.1032],\n",
      "          [-0.0341, -0.1651, -0.1502]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0480,  0.0550,  0.0311],\n",
      "          [ 0.0562,  0.1052,  0.1252],\n",
      "          [ 0.0476,  0.0801,  0.1263]],\n",
      "\n",
      "         [[-0.0116,  0.0496,  0.0300],\n",
      "          [ 0.0584,  0.0802, -0.0052],\n",
      "          [ 0.0452,  0.0150, -0.0060]],\n",
      "\n",
      "         [[-0.0560, -0.0443, -0.1017],\n",
      "          [-0.0694,  0.0226, -0.0382],\n",
      "          [-0.1770,  0.0346, -0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0055, -0.0405, -0.0066],\n",
      "          [ 0.0860, -0.0108, -0.0589],\n",
      "          [-0.0418,  0.0150, -0.0142]],\n",
      "\n",
      "         [[ 0.0987,  0.0430, -0.0545],\n",
      "          [ 0.0751,  0.1202, -0.0601],\n",
      "          [ 0.0942,  0.0923,  0.0657]],\n",
      "\n",
      "         [[ 0.0138, -0.1463, -0.2441],\n",
      "          [ 0.0295, -0.1478, -0.2368],\n",
      "          [ 0.0589,  0.0090, -0.0454]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0551,  0.0160, -0.1533],\n",
      "          [ 0.1023,  0.0429,  0.0173],\n",
      "          [ 0.0850,  0.0422,  0.0267]],\n",
      "\n",
      "         [[-0.0542, -0.0910, -0.1680],\n",
      "          [-0.0459, -0.1546, -0.2041],\n",
      "          [ 0.0730, -0.0649, -0.1177]],\n",
      "\n",
      "         [[ 0.0216,  0.0210,  0.0649],\n",
      "          [-0.0062,  0.1027,  0.0963],\n",
      "          [ 0.0781,  0.1217,  0.1648]]],\n",
      "\n",
      "\n",
      "        [[[-0.0840, -0.0603, -0.1048],\n",
      "          [ 0.0049, -0.0269, -0.0597],\n",
      "          [ 0.0542, -0.0162,  0.0747]],\n",
      "\n",
      "         [[ 0.0714, -0.0949, -0.0633],\n",
      "          [ 0.0028, -0.0647, -0.0687],\n",
      "          [ 0.0378, -0.0508, -0.0295]],\n",
      "\n",
      "         [[-0.1622, -0.0559,  0.0084],\n",
      "          [-0.1019, -0.0702,  0.0209],\n",
      "          [-0.0760,  0.0060, -0.0343]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0835, -0.0557, -0.0365],\n",
      "          [-0.0244,  0.0304,  0.0267],\n",
      "          [ 0.0078,  0.0967,  0.1665]],\n",
      "\n",
      "         [[-0.0195, -0.0309,  0.0407],\n",
      "          [-0.0621, -0.0535, -0.0118],\n",
      "          [ 0.0258,  0.0354, -0.0311]],\n",
      "\n",
      "         [[ 0.0145,  0.0111, -0.0916],\n",
      "          [ 0.0662,  0.0586,  0.0409],\n",
      "          [ 0.0841,  0.0361,  0.0395]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0403, -0.0422, -0.0465],\n",
      "          [-0.0241, -0.1455, -0.1617],\n",
      "          [-0.0679, -0.1491, -0.2013]],\n",
      "\n",
      "         [[ 0.0982,  0.0121, -0.1197],\n",
      "          [ 0.1059,  0.0716, -0.0809],\n",
      "          [ 0.0575,  0.0421, -0.0875]],\n",
      "\n",
      "         [[ 0.0824,  0.0636,  0.0259],\n",
      "          [ 0.1021,  0.0765,  0.0218],\n",
      "          [ 0.0250,  0.0167,  0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0314,  0.0242,  0.0482],\n",
      "          [-0.0588,  0.0097, -0.0499],\n",
      "          [-0.1616, -0.1402, -0.1753]],\n",
      "\n",
      "         [[ 0.0720,  0.0792,  0.0091],\n",
      "          [ 0.1452,  0.1472,  0.0532],\n",
      "          [ 0.0983,  0.0614,  0.1012]],\n",
      "\n",
      "         [[ 0.0500,  0.0622,  0.0510],\n",
      "          [-0.0531,  0.0012,  0.0112],\n",
      "          [ 0.1567,  0.1367, -0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0751, -0.0806, -0.1158],\n",
      "          [ 0.1142,  0.1145, -0.1092],\n",
      "          [ 0.1301,  0.0936, -0.0344]],\n",
      "\n",
      "         [[ 0.0190,  0.0193,  0.0189],\n",
      "          [-0.1078,  0.0234,  0.0243],\n",
      "          [-0.1590, -0.0393, -0.0830]],\n",
      "\n",
      "         [[ 0.0021, -0.0071, -0.0724],\n",
      "          [-0.0015,  0.0408, -0.1242],\n",
      "          [-0.0008, -0.0578, -0.1626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1442, -0.1199, -0.0122],\n",
      "          [-0.0914, -0.1198, -0.0634],\n",
      "          [-0.0146, -0.1145, -0.0687]],\n",
      "\n",
      "         [[-0.2062, -0.0947, -0.0237],\n",
      "          [-0.2023, -0.0859,  0.0704],\n",
      "          [-0.1217, -0.0032,  0.0543]],\n",
      "\n",
      "         [[-0.0136, -0.0321,  0.0573],\n",
      "          [-0.0285,  0.0314,  0.0714],\n",
      "          [-0.0661, -0.0489,  0.0610]]],\n",
      "\n",
      "\n",
      "        [[[-0.0190, -0.0957, -0.1116],\n",
      "          [ 0.0370, -0.0480, -0.1165],\n",
      "          [-0.0197, -0.0674, -0.0397]],\n",
      "\n",
      "         [[ 0.0533,  0.1001,  0.0303],\n",
      "          [ 0.0491,  0.1305,  0.0768],\n",
      "          [ 0.0806,  0.0742, -0.0209]],\n",
      "\n",
      "         [[ 0.0366,  0.1046,  0.0401],\n",
      "          [-0.0242,  0.0444,  0.0605],\n",
      "          [-0.0381,  0.0562,  0.0124]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0380,  0.0395, -0.0011],\n",
      "          [ 0.0088, -0.0615, -0.0406],\n",
      "          [-0.0901, -0.0994, -0.1523]],\n",
      "\n",
      "         [[ 0.0722, -0.0025,  0.0089],\n",
      "          [ 0.1353,  0.0853,  0.0725],\n",
      "          [ 0.1138,  0.1047, -0.0218]],\n",
      "\n",
      "         [[ 0.1967,  0.1236, -0.0192],\n",
      "          [ 0.2194,  0.0926, -0.0308],\n",
      "          [ 0.0511, -0.0930, -0.0590]]]])\n",
      "rescnn_layers.1.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0602,  0.0663, -0.1395,  0.1279,  0.0384,  0.0668,  0.0087,  0.0541,\n",
      "         0.0607, -0.0817,  0.1493, -0.1313, -0.0568,  0.0251,  0.0517, -0.0061,\n",
      "         0.1270,  0.0295, -0.0220,  0.0316, -0.0065,  0.0295,  0.0518,  0.0518,\n",
      "        -0.0217, -0.0937,  0.0239,  0.0957,  0.0355,  0.0911,  0.1344, -0.1174,\n",
      "         0.0241, -0.0229,  0.0954,  0.0426, -0.1063,  0.0458,  0.0779,  0.0216,\n",
      "        -0.0845,  0.0426,  0.0028,  0.0830, -0.0545, -0.0291, -0.0974, -0.1034,\n",
      "        -0.0013, -0.1148,  0.0271,  0.1400, -0.0623, -0.0043,  0.0048, -0.1202,\n",
      "         0.0550, -0.0321, -0.0527, -0.1123,  0.0430, -0.0415, -0.0064, -0.0447])\n",
      "rescnn_layers.1.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([0.9428, 1.0035, 0.9800, 0.8155, 0.9468, 0.7985, 0.9213, 0.7959, 0.6956,\n",
      "        0.7594, 0.8574, 0.8468, 0.9112, 0.8569, 0.9105, 0.8766, 0.9937, 0.9815,\n",
      "        1.0060, 1.0530, 1.0945, 1.0436, 1.0575, 1.0939, 1.0800, 1.0778, 1.0730,\n",
      "        1.0254, 1.0888, 1.0353, 1.0477, 1.0432, 1.0686, 1.0566, 1.0177, 1.0642,\n",
      "        1.0354, 1.0374, 0.9866, 1.0042, 1.0174, 1.0308, 1.0767, 1.0874, 1.0137,\n",
      "        1.0695, 1.0327, 0.9776, 1.0413, 1.0719, 1.0668, 1.0380, 1.0319, 1.0154,\n",
      "        0.9590, 1.0216, 0.9768, 0.9537, 1.0499, 1.0696, 1.0768, 1.0211, 1.0387,\n",
      "        1.0687])\n",
      "rescnn_layers.1.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([-4.2127e-02,  4.2451e-03, -9.9484e-03, -2.0308e-03,  4.8507e-02,\n",
      "        -1.9510e-02, -4.8154e-02, -3.6426e-02, -2.7755e-02, -1.9886e-03,\n",
      "         1.2564e-02, -1.8472e-03,  1.0562e-02, -3.7604e-03, -1.7623e-02,\n",
      "        -2.2279e-02,  4.2160e-03,  7.3782e-03, -1.4405e-02,  4.2041e-03,\n",
      "        -2.2128e-02, -2.5962e-02, -1.3612e-02, -2.4563e-02,  3.9089e-03,\n",
      "         1.9618e-02,  2.0055e-02,  1.3722e-02,  4.8201e-03, -1.2305e-03,\n",
      "        -1.7169e-03, -5.2451e-04, -3.0501e-02, -4.4860e-02, -3.0613e-02,\n",
      "        -1.3232e-02, -5.0858e-02, -3.6451e-02, -2.6557e-02, -1.2234e-02,\n",
      "         6.7850e-03, -6.6167e-03,  3.7317e-03,  3.3032e-02, -9.6445e-03,\n",
      "        -2.2326e-02, -1.8221e-02, -1.2206e-02,  1.1272e-02, -2.6461e-03,\n",
      "        -2.2714e-02,  9.3375e-03,  3.1867e-04, -7.8920e-03, -8.1622e-03,\n",
      "         7.4233e-03, -1.2262e-02, -3.1634e-02,  6.9086e-06, -4.2605e-04,\n",
      "         1.2696e-03, -1.3586e-02, -4.7309e-02, -2.3058e-02])\n",
      "rescnn_layers.1.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([0.9588, 0.8650, 0.8236, 0.7691, 0.8149, 0.8482, 0.7843, 0.8242, 0.7746,\n",
      "        0.8494, 0.8725, 0.8458, 0.7955, 0.9042, 0.9212, 0.9361, 0.9477, 1.0103,\n",
      "        1.0386, 1.0649, 1.0022, 1.0372, 1.0417, 1.0574, 1.0759, 1.1042, 1.1039,\n",
      "        1.0601, 1.0782, 1.1657, 1.1198, 1.0875, 1.0663, 1.1569, 1.0369, 1.0458,\n",
      "        1.0508, 1.0110, 0.9915, 1.0841, 1.0607, 1.1292, 1.1316, 1.0563, 1.0207,\n",
      "        1.1223, 1.0523, 1.0788, 0.9919, 1.1183, 1.1008, 1.0825, 1.1075, 1.0648,\n",
      "        0.9984, 0.9967, 1.0394, 1.0386, 1.1175, 1.1596, 1.0475, 1.0388, 1.1060,\n",
      "        1.1157])\n",
      "rescnn_layers.1.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([ 3.2475e-02, -1.6168e-02, -6.7970e-02, -1.4571e-01, -1.3608e-01,\n",
      "        -1.3968e-01, -1.2346e-01, -1.2595e-01, -1.2793e-01, -7.3478e-02,\n",
      "        -6.3545e-02, -7.1977e-02, -1.5530e-01, -7.9418e-02, -9.6280e-02,\n",
      "        -2.9450e-02, -1.3989e-05, -3.3547e-03, -7.2506e-02, -4.7784e-02,\n",
      "        -1.7263e-02, -8.1034e-03, -3.2624e-02, -4.7886e-02,  8.8429e-03,\n",
      "        -1.4420e-02, -3.0520e-02, -1.9405e-02, -5.8984e-02, -9.5965e-03,\n",
      "        -3.5989e-02, -3.7312e-02, -7.0367e-02, -3.9249e-03, -2.9125e-02,\n",
      "        -7.9140e-03, -1.2262e-02,  8.0261e-03, -2.3732e-02, -3.1278e-02,\n",
      "        -1.5501e-02, -1.1930e-02, -2.5739e-02, -5.2736e-02, -6.3737e-02,\n",
      "        -1.9169e-02, -1.8803e-03, -3.3219e-02, -5.5384e-02, -7.7996e-02,\n",
      "        -7.2467e-02, -4.7464e-02, -6.3155e-02, -5.7837e-02, -6.0199e-02,\n",
      "        -7.3057e-02, -4.0425e-02, -1.4640e-02,  6.7243e-02,  9.2525e-02,\n",
      "         4.4901e-02,  5.5304e-04, -1.4210e-02, -9.8971e-03])\n",
      "rescnn_layers.2.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 2.9518e-02, -5.9953e-02,  7.1525e-02],\n",
      "          [ 1.2534e-01, -3.9216e-03,  1.5983e-02],\n",
      "          [ 1.3987e-01,  3.6259e-02, -2.6200e-03]],\n",
      "\n",
      "         [[ 9.1705e-02, -5.3828e-02, -1.2536e-01],\n",
      "          [-1.1059e-02, -9.6548e-02, -2.5219e-01],\n",
      "          [-3.7644e-02, -1.8630e-02, -8.7547e-02]],\n",
      "\n",
      "         [[-4.6080e-02, -2.0119e-02,  6.2515e-02],\n",
      "          [-1.3635e-01, -5.3841e-02, -8.4248e-03],\n",
      "          [ 1.0661e-02,  3.0975e-02,  4.8312e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3476e-02,  2.3646e-02, -5.1143e-02],\n",
      "          [ 1.4225e-02, -2.6778e-02, -1.5735e-01],\n",
      "          [-3.7286e-02, -1.1978e-01, -9.5741e-02]],\n",
      "\n",
      "         [[-1.1289e-02, -1.7987e-02, -8.5261e-02],\n",
      "          [ 3.2481e-02, -3.7706e-02, -5.3760e-02],\n",
      "          [-7.1891e-03, -6.2408e-02, -1.2746e-01]],\n",
      "\n",
      "         [[-3.4120e-02,  1.7181e-01,  1.0605e-01],\n",
      "          [-1.4085e-01,  5.0792e-02,  3.4367e-02],\n",
      "          [-1.1283e-01,  3.0455e-02,  9.2119e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0839e-01,  1.5492e-01, -2.6088e-03],\n",
      "          [ 3.9060e-02,  6.3260e-02,  1.2140e-02],\n",
      "          [-3.3484e-02, -4.2094e-02, -5.1339e-03]],\n",
      "\n",
      "         [[-4.1622e-02, -7.0450e-02, -1.4086e-01],\n",
      "          [ 8.8128e-02,  1.1424e-01,  5.9611e-02],\n",
      "          [-2.7792e-02,  4.7915e-02,  7.1826e-02]],\n",
      "\n",
      "         [[-7.5935e-02,  4.1071e-02, -5.2967e-03],\n",
      "          [-1.6161e-01, -6.4546e-02, -2.7638e-02],\n",
      "          [ 2.6808e-02,  9.9754e-02, -2.3084e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1548e-02,  1.2729e-02,  1.6559e-02],\n",
      "          [ 6.6099e-03,  9.1922e-02,  1.6230e-01],\n",
      "          [-9.6947e-02, -5.9210e-02,  4.3012e-04]],\n",
      "\n",
      "         [[ 2.6801e-03,  9.4296e-02,  4.0405e-02],\n",
      "          [-1.8097e-02,  1.0125e-01,  4.8561e-02],\n",
      "          [ 1.5568e-01,  2.0183e-01,  1.9306e-01]],\n",
      "\n",
      "         [[-2.5232e-02, -2.5137e-02, -2.1379e-02],\n",
      "          [-8.0868e-02, -1.8072e-02,  3.0404e-02],\n",
      "          [ 3.5851e-02, -3.3391e-02,  3.9733e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3110e-02, -1.2279e-03, -6.0796e-02],\n",
      "          [ 7.7224e-02, -9.5637e-02, -9.5599e-02],\n",
      "          [ 2.9969e-02, -1.3124e-01, -8.8177e-02]],\n",
      "\n",
      "         [[ 2.4382e-01,  2.2847e-01,  1.9944e-01],\n",
      "          [ 8.8561e-02,  8.9011e-02,  7.3058e-02],\n",
      "          [ 1.8108e-02, -1.9191e-02, -1.1963e-01]],\n",
      "\n",
      "         [[ 1.2689e-02,  7.2635e-03, -1.3506e-01],\n",
      "          [ 8.9435e-02,  8.8989e-02, -9.8641e-02],\n",
      "          [ 6.1622e-02,  3.1646e-02, -1.9529e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0903e-01,  4.6334e-02, -9.8327e-04],\n",
      "          [ 3.7143e-02, -7.6751e-02, -9.4153e-02],\n",
      "          [ 1.2937e-01,  8.5147e-03, -5.0563e-02]],\n",
      "\n",
      "         [[-1.3075e-01, -8.2891e-02, -1.5718e-02],\n",
      "          [-1.7234e-02, -5.4178e-02, -5.8323e-02],\n",
      "          [-6.4464e-02, -5.5650e-02, -5.4719e-02]],\n",
      "\n",
      "         [[-9.3646e-03,  1.1677e-01, -7.3744e-02],\n",
      "          [ 3.1233e-02,  6.7813e-02, -3.4143e-02],\n",
      "          [ 8.7040e-02,  4.6394e-02,  2.9070e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4974e-03,  4.9909e-02,  9.4813e-02],\n",
      "          [ 2.2196e-02, -7.6496e-02, -1.9205e-02],\n",
      "          [ 1.0914e-02, -7.8764e-02, -4.7894e-02]],\n",
      "\n",
      "         [[ 3.1198e-02, -2.1556e-03, -2.9433e-02],\n",
      "          [ 1.2165e-01,  6.1352e-02,  5.3983e-02],\n",
      "          [ 8.3814e-02,  7.7935e-02,  5.2642e-02]],\n",
      "\n",
      "         [[-1.1095e-01,  5.7790e-02,  1.5657e-01],\n",
      "          [-1.5594e-01, -1.2750e-01,  4.8515e-02],\n",
      "          [-1.9972e-01, -1.5112e-01, -1.5338e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2548e-02, -6.0990e-02, -5.5162e-02],\n",
      "          [-2.1619e-02, -6.7766e-02,  6.6713e-03],\n",
      "          [ 4.2950e-03, -3.6026e-02, -1.3791e-02]],\n",
      "\n",
      "         [[ 3.2714e-02,  9.1990e-02,  1.3037e-01],\n",
      "          [ 7.8003e-03, -3.4621e-03,  2.0003e-01],\n",
      "          [ 2.2610e-02, -1.0009e-01, -6.4815e-02]],\n",
      "\n",
      "         [[-2.5885e-02, -5.3037e-02, -7.2515e-02],\n",
      "          [-3.8393e-02, -2.8117e-02, -9.5483e-02],\n",
      "          [-7.9305e-03, -2.0679e-02, -7.6517e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5439e-02, -6.2473e-02,  1.0582e-02],\n",
      "          [-2.8654e-03, -1.2849e-01, -1.3133e-02],\n",
      "          [ 2.8130e-02, -4.0449e-02,  4.8174e-02]],\n",
      "\n",
      "         [[-4.1942e-02, -4.4854e-02,  6.4244e-02],\n",
      "          [ 7.6986e-02, -1.4813e-02,  2.7746e-02],\n",
      "          [-4.2620e-03,  1.3093e-01,  9.5010e-02]],\n",
      "\n",
      "         [[ 1.0015e-01,  4.4721e-02, -3.5549e-02],\n",
      "          [ 5.2803e-02,  4.1891e-02, -2.2957e-02],\n",
      "          [-8.3025e-02, -1.0357e-01, -1.9416e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4810e-02,  2.0315e-02, -6.2784e-02],\n",
      "          [ 3.4364e-02, -1.7503e-02, -8.8829e-02],\n",
      "          [ 5.4861e-02,  7.2131e-02, -3.7621e-02]],\n",
      "\n",
      "         [[-2.6617e-02, -1.0645e-01, -6.3875e-02],\n",
      "          [-4.9432e-03, -7.0716e-02, -2.2629e-02],\n",
      "          [-9.6836e-02, -1.4390e-01, -1.4194e-02]],\n",
      "\n",
      "         [[ 6.7951e-03,  1.1307e-01,  2.3851e-02],\n",
      "          [-4.5510e-02,  3.3035e-02, -4.6689e-03],\n",
      "          [-5.9041e-02, -9.6005e-04, -5.0160e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4241e-01, -9.8251e-02,  8.2521e-03],\n",
      "          [-1.3175e-01, -1.7007e-01,  9.4896e-03],\n",
      "          [-9.7499e-02, -1.1727e-01, -7.9212e-02]],\n",
      "\n",
      "         [[-2.4086e-01, -4.1505e-02,  9.9159e-02],\n",
      "          [-2.8611e-01, -6.0810e-02,  2.1227e-01],\n",
      "          [-1.8498e-01, -1.2921e-01,  4.0854e-02]],\n",
      "\n",
      "         [[ 1.3002e-02, -1.0750e-01,  5.6929e-02],\n",
      "          [ 1.9967e-01, -3.8082e-02, -3.7066e-02],\n",
      "          [ 1.1607e-02, -4.6272e-02, -6.2623e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7764e-04, -1.0277e-01,  6.5533e-02],\n",
      "          [-1.0019e-01, -1.0174e-01,  4.4567e-02],\n",
      "          [ 9.5614e-02,  2.2051e-02,  7.6231e-02]],\n",
      "\n",
      "         [[-6.6137e-02, -1.8790e-02,  6.3869e-02],\n",
      "          [ 6.5596e-02,  7.7115e-05, -1.1619e-02],\n",
      "          [ 4.5618e-02,  1.1148e-04, -1.9375e-03]],\n",
      "\n",
      "         [[-1.6989e-01, -1.7494e-01, -1.6376e-01],\n",
      "          [-1.7783e-01, -1.1602e-01, -1.1000e-01],\n",
      "          [-1.1875e-01, -5.1222e-02, -3.0972e-02]]]])\n",
      "rescnn_layers.2.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0072,  0.0148,  0.0341,  0.0193,  0.0344,  0.0266,  0.0187, -0.0038,\n",
      "        -0.0045,  0.0323, -0.0069, -0.0069,  0.0123, -0.0397,  0.0010,  0.0265,\n",
      "        -0.0202, -0.0207,  0.0072,  0.0090, -0.0238,  0.0173, -0.0180, -0.0234,\n",
      "        -0.0140, -0.0050,  0.0263, -0.0085, -0.0346,  0.0168, -0.0208,  0.0051,\n",
      "        -0.0017, -0.0165, -0.0214, -0.0022, -0.0222, -0.0231,  0.0061,  0.0372,\n",
      "         0.0100, -0.0354, -0.0110,  0.0335, -0.0111,  0.0257,  0.0172, -0.0131,\n",
      "         0.0114,  0.0297,  0.0318,  0.0271,  0.0400, -0.0296, -0.0242, -0.0271,\n",
      "        -0.0273, -0.0410,  0.0189, -0.0166, -0.0281,  0.0315,  0.0212, -0.0424])\n",
      "rescnn_layers.2.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-0.0366, -0.0254,  0.0926],\n",
      "          [-0.0801, -0.0600,  0.0598],\n",
      "          [-0.0203, -0.0682,  0.0583]],\n",
      "\n",
      "         [[ 0.0537,  0.0784,  0.0146],\n",
      "          [-0.0636, -0.0336, -0.0847],\n",
      "          [-0.0396,  0.0058,  0.0246]],\n",
      "\n",
      "         [[ 0.0101,  0.1024,  0.1988],\n",
      "          [ 0.0368,  0.0468,  0.1713],\n",
      "          [-0.0599, -0.0568,  0.0217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0289,  0.0063,  0.0586],\n",
      "          [-0.0429, -0.0201, -0.0766],\n",
      "          [ 0.0313, -0.0050, -0.0755]],\n",
      "\n",
      "         [[-0.0444, -0.0812,  0.0862],\n",
      "          [-0.0865, -0.1336,  0.0858],\n",
      "          [-0.0676, -0.0183,  0.1398]],\n",
      "\n",
      "         [[ 0.1051,  0.1574,  0.0470],\n",
      "          [ 0.1267,  0.0995, -0.0287],\n",
      "          [ 0.0978,  0.0510, -0.1054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0722, -0.0828, -0.0862],\n",
      "          [ 0.0303,  0.0506, -0.0348],\n",
      "          [ 0.0140,  0.0053,  0.0275]],\n",
      "\n",
      "         [[ 0.0055, -0.0048,  0.0160],\n",
      "          [ 0.0780,  0.0739,  0.0287],\n",
      "          [ 0.0497,  0.0078,  0.0212]],\n",
      "\n",
      "         [[-0.0272, -0.0049, -0.0382],\n",
      "          [ 0.0424, -0.0398, -0.0023],\n",
      "          [ 0.0500,  0.0676,  0.0401]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0326,  0.0295, -0.0370],\n",
      "          [ 0.1522,  0.0311,  0.0637],\n",
      "          [ 0.0517,  0.0352,  0.0683]],\n",
      "\n",
      "         [[ 0.1359,  0.0922,  0.0535],\n",
      "          [-0.0133, -0.0417,  0.0882],\n",
      "          [-0.1265, -0.1300, -0.0494]],\n",
      "\n",
      "         [[-0.0682,  0.0962,  0.0031],\n",
      "          [-0.0361,  0.0123, -0.0246],\n",
      "          [ 0.0470,  0.0899,  0.0609]]],\n",
      "\n",
      "\n",
      "        [[[-0.0732, -0.0618, -0.0479],\n",
      "          [-0.0034, -0.0529, -0.0916],\n",
      "          [ 0.1018, -0.0465, -0.1055]],\n",
      "\n",
      "         [[-0.0057, -0.0713, -0.0277],\n",
      "          [-0.0709, -0.1713, -0.0774],\n",
      "          [ 0.0407, -0.0690,  0.0305]],\n",
      "\n",
      "         [[-0.0134,  0.1119,  0.0137],\n",
      "          [ 0.0801,  0.0757,  0.0599],\n",
      "          [ 0.0562,  0.0932,  0.0406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0706, -0.0594, -0.1196],\n",
      "          [-0.0886, -0.0143, -0.0763],\n",
      "          [-0.0136,  0.0860,  0.0008]],\n",
      "\n",
      "         [[-0.1215,  0.0162, -0.1168],\n",
      "          [-0.0134, -0.0049, -0.0545],\n",
      "          [-0.0181,  0.0502,  0.0361]],\n",
      "\n",
      "         [[-0.0030, -0.0615, -0.0505],\n",
      "          [ 0.0183, -0.0192,  0.0350],\n",
      "          [-0.0406, -0.0216,  0.0562]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0062,  0.1112,  0.0977],\n",
      "          [ 0.0906,  0.1369,  0.1728],\n",
      "          [ 0.0124,  0.0841,  0.1430]],\n",
      "\n",
      "         [[-0.0064, -0.0274,  0.0557],\n",
      "          [ 0.1897,  0.1560,  0.1273],\n",
      "          [ 0.0621,  0.0459,  0.0437]],\n",
      "\n",
      "         [[-0.1170,  0.0159, -0.0186],\n",
      "          [-0.0989,  0.0752, -0.0419],\n",
      "          [-0.0353,  0.0457,  0.0118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0626,  0.0428,  0.0248],\n",
      "          [ 0.1042,  0.0982,  0.0265],\n",
      "          [ 0.0729, -0.0361, -0.0349]],\n",
      "\n",
      "         [[-0.0084,  0.0920,  0.0279],\n",
      "          [-0.0789,  0.0645,  0.0188],\n",
      "          [-0.1586, -0.0601, -0.0496]],\n",
      "\n",
      "         [[-0.0660,  0.0932,  0.1194],\n",
      "          [-0.1104, -0.1171, -0.0026],\n",
      "          [-0.0669, -0.1561, -0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1475,  0.0705,  0.0674],\n",
      "          [ 0.1283,  0.0182,  0.1162],\n",
      "          [ 0.0891,  0.0327,  0.0303]],\n",
      "\n",
      "         [[ 0.0735,  0.1417,  0.0192],\n",
      "          [ 0.0156,  0.0441,  0.0193],\n",
      "          [-0.0258,  0.0784, -0.0369]],\n",
      "\n",
      "         [[ 0.0334, -0.0132,  0.1133],\n",
      "          [ 0.0358, -0.0251,  0.1152],\n",
      "          [-0.0456, -0.1224, -0.0072]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0315,  0.0367, -0.0977],\n",
      "          [ 0.0555,  0.0529, -0.1506],\n",
      "          [ 0.0886,  0.0710, -0.1101]],\n",
      "\n",
      "         [[ 0.0878, -0.0373, -0.0873],\n",
      "          [ 0.1059, -0.0652, -0.0494],\n",
      "          [ 0.0298,  0.0280,  0.0814]],\n",
      "\n",
      "         [[ 0.1036, -0.0104, -0.0921],\n",
      "          [ 0.1782, -0.0505, -0.1824],\n",
      "          [ 0.0132, -0.0298, -0.1437]]],\n",
      "\n",
      "\n",
      "        [[[-0.1275, -0.0600, -0.0007],\n",
      "          [-0.0491, -0.0783,  0.0129],\n",
      "          [-0.0939,  0.0398,  0.0190]],\n",
      "\n",
      "         [[-0.0385,  0.0894,  0.0822],\n",
      "          [-0.1008, -0.0013,  0.1080],\n",
      "          [-0.1342, -0.0056,  0.0044]],\n",
      "\n",
      "         [[-0.0636, -0.0587,  0.0550],\n",
      "          [-0.1171, -0.0801,  0.0495],\n",
      "          [-0.1231,  0.0014,  0.0649]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0134,  0.0259, -0.0511],\n",
      "          [-0.0341, -0.0512, -0.1308],\n",
      "          [ 0.0264, -0.0927, -0.1747]],\n",
      "\n",
      "         [[ 0.0451, -0.0360,  0.0091],\n",
      "          [ 0.0694,  0.0125, -0.0252],\n",
      "          [ 0.1046,  0.0985,  0.0574]],\n",
      "\n",
      "         [[ 0.1396,  0.0407,  0.0117],\n",
      "          [ 0.1946,  0.0859, -0.0357],\n",
      "          [ 0.1064,  0.0115, -0.0523]]]])\n",
      "rescnn_layers.2.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0761,  0.0400, -0.1014,  0.0725, -0.0214,  0.0193, -0.0593,  0.1159,\n",
      "         0.0364, -0.0450,  0.1654, -0.1332, -0.0891,  0.0703,  0.0480, -0.0468,\n",
      "         0.1627,  0.0067, -0.0092,  0.0564, -0.0102,  0.0735,  0.0323,  0.0378,\n",
      "         0.0390, -0.0995, -0.0233,  0.0537,  0.0273,  0.0753,  0.0947, -0.0864,\n",
      "         0.0049, -0.0284,  0.0534,  0.0309, -0.0930,  0.0863,  0.0787,  0.0564,\n",
      "        -0.1150,  0.0976,  0.0019,  0.1040, -0.0091, -0.0595, -0.0956, -0.0637,\n",
      "         0.0057, -0.0906,  0.0456,  0.1354, -0.0202, -0.0208,  0.0042, -0.1821,\n",
      "         0.0671, -0.0542, -0.0168, -0.1202,  0.0544, -0.0470, -0.0541, -0.0807])\n",
      "rescnn_layers.2.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0193, 0.9680, 0.9874, 0.9660, 0.9341, 0.8509, 0.8651, 0.9053, 0.7754,\n",
      "        0.8115, 0.8566, 0.8562, 0.8603, 0.8322, 0.8383, 0.8623, 0.9231, 1.0082,\n",
      "        1.0267, 1.0439, 1.0185, 1.1196, 1.1403, 1.0674, 1.1101, 1.1130, 1.0103,\n",
      "        1.0756, 1.0562, 1.0491, 1.0595, 1.0523, 1.0600, 1.0721, 1.0341, 1.0677,\n",
      "        1.0607, 1.0639, 1.0262, 1.1027, 1.0941, 1.0819, 1.1014, 1.0192, 1.0201,\n",
      "        1.0943, 1.1287, 1.0270, 1.0042, 1.0854, 1.1192, 1.1111, 1.0973, 1.0475,\n",
      "        0.9914, 1.0200, 1.0493, 0.9307, 1.0106, 1.0458, 0.9742, 0.9897, 1.0688,\n",
      "        1.0576])\n",
      "rescnn_layers.2.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.0312, -0.0747, -0.0380, -0.0024,  0.0654,  0.0397,  0.0027,  0.0173,\n",
      "        -0.0433,  0.0397,  0.0090,  0.0415,  0.0273,  0.0603,  0.0065,  0.0514,\n",
      "         0.0593,  0.0316, -0.0531,  0.0226,  0.0375,  0.0321,  0.0118, -0.0429,\n",
      "         0.0070,  0.0109, -0.0087,  0.0233, -0.0027,  0.0276,  0.0295,  0.0248,\n",
      "        -0.0581, -0.0733, -0.0387,  0.0156, -0.0499, -0.0856, -0.0660,  0.0138,\n",
      "        -0.0074, -0.0414,  0.0210,  0.0182,  0.0197, -0.0294, -0.0256, -0.0348,\n",
      "        -0.0456, -0.0347, -0.0208, -0.0228,  0.0201,  0.0097,  0.0122,  0.0075,\n",
      "         0.0157, -0.0473, -0.0132, -0.0274, -0.0853, -0.1275, -0.0965, -0.0223])\n",
      "rescnn_layers.2.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0047, 0.9535, 0.9478, 0.9695, 0.9035, 0.9243, 0.9432, 0.9365, 0.9177,\n",
      "        0.9092, 0.9674, 0.8925, 0.8536, 0.8652, 0.9300, 0.9770, 1.0133, 0.9590,\n",
      "        1.0025, 1.0202, 1.0628, 1.0633, 1.0550, 1.0414, 1.0257, 1.0261, 1.0652,\n",
      "        1.0718, 1.0268, 1.0468, 1.0289, 1.0027, 0.9997, 1.0155, 1.0181, 1.0199,\n",
      "        1.0143, 0.9845, 0.9776, 1.0284, 1.0434, 1.0178, 1.0052, 0.9776, 0.9521,\n",
      "        0.9491, 1.0157, 0.9850, 1.0206, 1.0840, 1.0514, 1.0353, 1.0372, 1.0577,\n",
      "        0.9610, 0.9595, 0.9977, 0.9678, 0.9738, 0.9958, 1.0070, 1.0047, 1.0233,\n",
      "        1.0328])\n",
      "rescnn_layers.2.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0324, -0.0810, -0.0858, -0.1295, -0.1342, -0.1239, -0.0784, -0.1196,\n",
      "        -0.1035, -0.0946, -0.0934, -0.1495, -0.1840, -0.1831, -0.1749, -0.1015,\n",
      "        -0.0730, -0.1200, -0.1231, -0.1276, -0.1122, -0.0998, -0.1122, -0.1137,\n",
      "        -0.1011, -0.0906, -0.0549, -0.0871, -0.1267, -0.0985, -0.1111, -0.1007,\n",
      "        -0.1039, -0.0884, -0.0611, -0.0890, -0.0752, -0.0905, -0.0909, -0.0726,\n",
      "        -0.0305, -0.0692, -0.0857, -0.0989, -0.1096, -0.0865, -0.0486, -0.0508,\n",
      "        -0.0177, -0.0251, -0.0375, -0.0293, -0.0798, -0.0829, -0.1007, -0.1085,\n",
      "        -0.0602, -0.0002,  0.0529,  0.0928,  0.0483,  0.0253, -0.0280, -0.0482])\n",
      "rescnn_layers.3.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-1.8677e-01, -9.1966e-02,  2.6854e-02],\n",
      "          [-1.0120e-01, -6.8626e-02,  3.6974e-03],\n",
      "          [-1.6867e-01, -1.9178e-01, -8.7254e-02]],\n",
      "\n",
      "         [[-1.7048e-01, -6.5401e-02,  5.5312e-02],\n",
      "          [-1.2039e-01, -9.0431e-02, -4.7488e-02],\n",
      "          [-7.8955e-02, -1.2237e-01, -5.9603e-02]],\n",
      "\n",
      "         [[ 1.5775e-01, -7.4515e-02, -1.1382e-01],\n",
      "          [ 2.5648e-01,  4.6477e-02, -8.2785e-02],\n",
      "          [ 6.0169e-02, -2.6350e-02, -1.3647e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7717e-04, -3.9027e-02,  1.4745e-01],\n",
      "          [ 2.7990e-02,  7.5388e-02,  1.7817e-01],\n",
      "          [-1.2526e-02,  3.3298e-02,  3.7921e-02]],\n",
      "\n",
      "         [[-1.7357e-01, -7.0748e-02, -1.3038e-01],\n",
      "          [-1.1784e-02, -1.4293e-02, -2.8676e-02],\n",
      "          [ 4.0886e-02,  8.5738e-02,  2.1002e-02]],\n",
      "\n",
      "         [[-1.5238e-01, -4.5574e-02,  3.4458e-02],\n",
      "          [-1.2731e-01,  6.7157e-02,  1.1830e-01],\n",
      "          [-2.2465e-02,  5.7542e-02,  2.0003e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4996e-02, -3.3487e-02,  2.8736e-02],\n",
      "          [-8.0993e-02, -7.2598e-02,  1.5885e-02],\n",
      "          [-1.4856e-01, -9.6581e-02, -6.5347e-02]],\n",
      "\n",
      "         [[-7.9069e-02,  5.5271e-02, -4.6570e-02],\n",
      "          [-5.0601e-02,  2.5330e-02, -5.7308e-02],\n",
      "          [ 1.6026e-02,  6.8647e-02,  6.2829e-02]],\n",
      "\n",
      "         [[ 4.2587e-02, -2.6391e-02, -3.2388e-02],\n",
      "          [ 3.3226e-02,  6.5091e-03, -3.3188e-02],\n",
      "          [-1.5525e-02,  1.4588e-02, -2.1866e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1316e-01, -8.9143e-02,  1.9852e-02],\n",
      "          [-1.9609e-01, -7.9459e-02,  7.5893e-02],\n",
      "          [-1.3613e-01, -7.5364e-02,  1.2213e-02]],\n",
      "\n",
      "         [[ 6.0909e-02, -6.9761e-02, -4.0451e-02],\n",
      "          [ 4.0772e-02, -1.0409e-01, -8.1673e-02],\n",
      "          [ 5.1374e-02, -6.2676e-02, -1.3976e-01]],\n",
      "\n",
      "         [[ 9.4362e-02,  7.6626e-02,  4.0274e-02],\n",
      "          [ 9.1256e-02,  6.6368e-02,  5.1126e-02],\n",
      "          [ 1.1655e-01,  6.0209e-02,  1.2648e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9639e-03,  1.3760e-02, -5.3122e-03],\n",
      "          [ 4.9078e-02,  2.3820e-02, -1.4107e-02],\n",
      "          [-7.2646e-02, -5.3551e-02, -9.4368e-02]],\n",
      "\n",
      "         [[ 3.3134e-02, -1.6016e-02, -1.3548e-02],\n",
      "          [ 7.9715e-03,  9.1149e-02,  4.7430e-02],\n",
      "          [-6.7846e-03,  8.9862e-02,  1.1709e-01]],\n",
      "\n",
      "         [[-5.0445e-02, -2.5619e-02, -5.6621e-02],\n",
      "          [ 4.7396e-02, -2.6532e-02,  9.1857e-02],\n",
      "          [ 6.0864e-02,  6.8496e-02,  1.3906e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0745e-01, -1.4350e-01, -1.1636e-01],\n",
      "          [-1.4788e-01, -9.8506e-02, -1.2262e-02],\n",
      "          [-1.8413e-01, -4.4046e-02,  1.7415e-02]],\n",
      "\n",
      "         [[-5.3378e-02, -3.0946e-03, -6.6565e-02],\n",
      "          [-5.6423e-02, -6.0793e-02, -7.9004e-02],\n",
      "          [ 1.9819e-02,  3.8109e-02,  5.7436e-02]],\n",
      "\n",
      "         [[-2.5930e-02, -7.9844e-02, -1.1298e-01],\n",
      "          [-7.9872e-03, -5.1486e-02, -1.4065e-01],\n",
      "          [ 2.4789e-04, -2.7511e-02, -8.6401e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9590e-02,  6.0169e-02,  1.7802e-02],\n",
      "          [ 5.2515e-02,  8.6532e-02,  2.1259e-02],\n",
      "          [-4.3552e-03,  1.1842e-01,  4.2843e-02]],\n",
      "\n",
      "         [[ 5.7717e-02,  3.5825e-02,  5.0345e-02],\n",
      "          [ 7.6567e-02,  4.6897e-02,  8.0689e-02],\n",
      "          [-7.5076e-02, -5.1932e-02,  2.5346e-02]],\n",
      "\n",
      "         [[ 1.1159e-02, -5.5695e-02, -8.3004e-02],\n",
      "          [-2.3680e-02, -1.8177e-02,  3.5943e-02],\n",
      "          [-4.5123e-02, -1.5546e-03,  5.2347e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6493e-02, -2.7503e-02, -4.9043e-02],\n",
      "          [ 1.6327e-02,  1.9288e-02, -2.3181e-02],\n",
      "          [-4.8228e-02, -2.7733e-02,  3.3387e-02]],\n",
      "\n",
      "         [[ 1.3050e-02,  1.3330e-02, -4.8516e-02],\n",
      "          [-1.0681e-01, -2.0315e-02, -7.9664e-02],\n",
      "          [-1.0195e-01, -6.2255e-02, -1.2776e-01]],\n",
      "\n",
      "         [[-1.6774e-01, -9.4971e-02,  3.0279e-02],\n",
      "          [-1.5877e-01, -1.1096e-01, -1.8421e-02],\n",
      "          [ 9.6356e-05, -1.9688e-02,  2.3890e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1939e-02, -2.8849e-02, -5.2087e-02],\n",
      "          [ 1.1651e-01,  4.6758e-02, -6.3556e-02],\n",
      "          [ 1.0520e-01,  5.0267e-02,  4.3754e-02]],\n",
      "\n",
      "         [[-1.1539e-01, -9.9076e-02, -1.9244e-01],\n",
      "          [-4.1845e-02, -1.2556e-02, -1.2687e-01],\n",
      "          [-9.1180e-03,  4.8115e-04, -6.7702e-02]],\n",
      "\n",
      "         [[ 1.5871e-01,  3.3616e-02, -4.7256e-02],\n",
      "          [ 1.3411e-01,  3.7979e-02, -4.5809e-02],\n",
      "          [ 4.9830e-02,  3.6707e-02,  2.5452e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4675e-02,  4.2672e-02,  7.5376e-02],\n",
      "          [ 7.8987e-02,  1.6097e-01,  6.9175e-02],\n",
      "          [ 2.4365e-02,  5.5733e-02,  3.2191e-02]],\n",
      "\n",
      "         [[-9.8297e-02, -5.7810e-02, -4.1141e-02],\n",
      "          [-5.5398e-02, -3.2327e-02,  5.4209e-02],\n",
      "          [ 5.2696e-02,  3.6074e-02,  8.0173e-02]],\n",
      "\n",
      "         [[ 8.0153e-02,  8.7397e-02,  1.8515e-01],\n",
      "          [-6.6838e-03,  5.0960e-02,  1.7176e-01],\n",
      "          [-2.6337e-02, -3.6619e-02,  6.7503e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7673e-02, -5.7174e-02,  3.5550e-02],\n",
      "          [-4.1844e-02, -2.9976e-02,  7.9896e-02],\n",
      "          [-3.7909e-02, -2.0528e-03,  8.7579e-02]],\n",
      "\n",
      "         [[-6.9731e-02, -7.4091e-03,  2.4693e-02],\n",
      "          [-2.2985e-01, -7.7439e-02,  3.8471e-02],\n",
      "          [-2.7846e-01, -1.7483e-01,  7.4751e-02]],\n",
      "\n",
      "         [[-5.7653e-02, -2.1514e-01, -2.4796e-01],\n",
      "          [-4.9119e-02, -1.3212e-01, -1.1930e-01],\n",
      "          [-5.9574e-03,  1.4322e-02, -8.6495e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9824e-02,  7.6397e-02, -2.0529e-02],\n",
      "          [-1.5538e-01, -6.5000e-02, -1.1546e-01],\n",
      "          [-7.1728e-02, -9.4060e-02, -2.8238e-02]],\n",
      "\n",
      "         [[ 8.1657e-02,  7.2321e-02,  3.5042e-02],\n",
      "          [ 1.3455e-01,  1.0152e-01,  4.7324e-02],\n",
      "          [ 8.7720e-02,  1.9201e-02,  1.3375e-02]],\n",
      "\n",
      "         [[-6.4862e-02,  2.2706e-02,  9.6865e-02],\n",
      "          [-9.6162e-02,  1.3377e-02,  1.4455e-01],\n",
      "          [-6.2509e-03,  8.1816e-02,  1.4465e-01]]]])\n",
      "rescnn_layers.3.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0364, -0.0174, -0.0201, -0.0335, -0.0256,  0.0337, -0.0386, -0.0298,\n",
      "         0.0401,  0.0186,  0.0256,  0.0379, -0.0060,  0.0091,  0.0143, -0.0123,\n",
      "         0.0094,  0.0242,  0.0086,  0.0053,  0.0238, -0.0403, -0.0242, -0.0167,\n",
      "         0.0061, -0.0196,  0.0157, -0.0267,  0.0210, -0.0039, -0.0350, -0.0355,\n",
      "        -0.0418,  0.0171, -0.0140, -0.0174, -0.0117,  0.0326,  0.0052,  0.0141,\n",
      "         0.0083, -0.0386,  0.0219, -0.0074,  0.0186, -0.0142,  0.0422,  0.0362,\n",
      "         0.0254, -0.0174,  0.0053,  0.0341, -0.0133,  0.0182,  0.0247,  0.0064,\n",
      "         0.0169, -0.0027,  0.0188,  0.0223, -0.0286,  0.0196,  0.0388,  0.0078])\n",
      "rescnn_layers.3.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 1.7525e-02,  5.7290e-02,  8.6180e-02],\n",
      "          [ 7.1471e-02,  1.0399e-01,  7.5107e-02],\n",
      "          [ 1.2633e-01,  1.1972e-01,  5.5398e-02]],\n",
      "\n",
      "         [[-3.5002e-02, -2.7675e-02,  4.3471e-02],\n",
      "          [-7.6301e-02,  2.8232e-02,  9.8492e-02],\n",
      "          [ 5.5740e-02,  3.1604e-02,  1.2136e-01]],\n",
      "\n",
      "         [[-1.8597e-02,  4.3655e-02,  1.3578e-01],\n",
      "          [-8.6211e-02,  2.2630e-02,  8.5369e-02],\n",
      "          [-2.4673e-02, -2.4097e-02,  5.2349e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1167e-01,  9.1784e-02,  1.3895e-01],\n",
      "          [ 7.2727e-02,  3.2388e-02,  7.6101e-02],\n",
      "          [-6.8947e-02, -8.9885e-02, -2.7006e-02]],\n",
      "\n",
      "         [[ 1.5158e-02, -1.2609e-02, -7.9293e-03],\n",
      "          [-4.2623e-02, -3.1145e-02,  5.3836e-02],\n",
      "          [ 5.8885e-03,  1.4045e-02,  6.1675e-02]],\n",
      "\n",
      "         [[-4.2452e-02, -4.2737e-02,  1.4642e-02],\n",
      "          [ 9.0641e-03, -1.9599e-02,  6.2889e-02],\n",
      "          [ 5.7140e-02, -4.0154e-02,  6.7610e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3737e-02,  1.8934e-01,  1.3702e-01],\n",
      "          [ 5.2918e-04,  8.1950e-02,  8.1301e-02],\n",
      "          [ 3.1294e-03,  8.4227e-02,  1.5158e-03]],\n",
      "\n",
      "         [[-4.5264e-02, -1.5615e-02,  1.2203e-01],\n",
      "          [ 4.3433e-02, -5.1741e-03,  1.3100e-01],\n",
      "          [-5.9160e-03, -1.5253e-05,  4.5535e-02]],\n",
      "\n",
      "         [[-5.1904e-02, -4.6117e-02, -5.2471e-02],\n",
      "          [ 1.7861e-02, -1.3820e-02, -1.7764e-02],\n",
      "          [ 1.3828e-01,  8.5806e-02,  6.5927e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5977e-02, -3.7591e-02, -9.1683e-02],\n",
      "          [-4.8501e-02,  5.6392e-03,  4.5236e-02],\n",
      "          [-3.6203e-02, -5.9388e-03, -1.7820e-02]],\n",
      "\n",
      "         [[ 7.4704e-02,  7.7853e-02,  2.2400e-02],\n",
      "          [ 7.5430e-02,  5.7255e-02,  1.4464e-03],\n",
      "          [ 6.7076e-02, -6.4875e-03, -7.1353e-03]],\n",
      "\n",
      "         [[-1.9058e-02,  6.2344e-02,  1.5725e-01],\n",
      "          [-2.4131e-02,  7.3132e-02,  1.6659e-01],\n",
      "          [ 9.8446e-02,  1.0770e-01,  1.2365e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0199e-03,  2.1367e-02,  1.0338e-01],\n",
      "          [ 1.4616e-01,  7.8238e-02,  9.6217e-02],\n",
      "          [ 6.1507e-02,  1.7534e-02,  5.9575e-02]],\n",
      "\n",
      "         [[-2.9456e-02, -5.5655e-02, -1.2232e-02],\n",
      "          [-8.8208e-02, -3.3448e-02,  1.3517e-02],\n",
      "          [-4.4921e-03,  3.0963e-02,  9.0331e-02]],\n",
      "\n",
      "         [[-1.0878e-01, -1.3780e-01, -8.7375e-02],\n",
      "          [-4.7222e-02, -1.2670e-01, -1.6126e-01],\n",
      "          [ 4.1789e-02,  5.2537e-02,  2.0503e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0937e-02,  5.0863e-02,  7.2639e-02],\n",
      "          [ 4.7328e-02,  7.0762e-02,  7.0404e-02],\n",
      "          [ 2.8691e-02,  5.3531e-02,  4.1668e-02]],\n",
      "\n",
      "         [[-1.8003e-01, -4.1059e-02,  3.6611e-02],\n",
      "          [-1.2475e-01, -3.3067e-02,  4.4726e-02],\n",
      "          [-2.1936e-02, -6.2605e-02,  4.5731e-02]],\n",
      "\n",
      "         [[-1.3620e-03,  6.6632e-02,  5.3517e-02],\n",
      "          [ 3.7561e-02,  5.9309e-02,  9.8904e-02],\n",
      "          [-3.8815e-02,  1.7578e-01,  1.3192e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3286e-01, -1.0248e-01,  4.9731e-02],\n",
      "          [-1.4513e-01, -1.6123e-01, -4.7323e-02],\n",
      "          [-5.1309e-02, -5.3006e-02, -6.7094e-02]],\n",
      "\n",
      "         [[ 8.9449e-03,  5.7389e-02,  2.6439e-02],\n",
      "          [ 1.1294e-02,  4.2820e-02,  8.0315e-02],\n",
      "          [ 5.1886e-02,  8.6463e-02,  3.7126e-02]],\n",
      "\n",
      "         [[-5.7179e-02, -9.7115e-02, -1.2935e-01],\n",
      "          [ 6.1152e-02,  9.0644e-03,  3.2609e-02],\n",
      "          [-2.1869e-02,  5.7007e-02,  9.4230e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8362e-02, -4.9013e-02, -5.0996e-02],\n",
      "          [ 3.3825e-03, -4.2389e-02, -7.5406e-02],\n",
      "          [-5.4655e-02, -8.7773e-03, -3.7561e-02]],\n",
      "\n",
      "         [[ 2.1404e-02,  1.8287e-02,  7.8768e-02],\n",
      "          [ 5.4706e-02,  4.6537e-02,  7.1537e-02],\n",
      "          [ 4.5286e-02,  5.3389e-04,  5.4440e-03]],\n",
      "\n",
      "         [[ 4.9609e-02,  3.1822e-02,  3.1098e-02],\n",
      "          [ 8.3608e-02,  4.6577e-02,  5.0773e-02],\n",
      "          [ 6.9768e-02, -6.5995e-02, -3.4494e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0647e-03, -9.7720e-02, -1.3198e-01],\n",
      "          [ 1.1616e-01, -2.9307e-02, -4.9446e-02],\n",
      "          [ 1.5351e-01,  2.2501e-02,  1.4457e-02]],\n",
      "\n",
      "         [[-1.2101e-01, -6.3192e-02, -2.3481e-02],\n",
      "          [-4.3191e-02,  2.5220e-03,  1.9400e-02],\n",
      "          [-5.1650e-03,  3.4456e-02,  6.6885e-02]],\n",
      "\n",
      "         [[-3.8601e-02,  3.5369e-02,  8.6084e-02],\n",
      "          [ 4.6018e-03,  1.8050e-02,  9.3118e-02],\n",
      "          [ 2.6262e-02,  7.5584e-02,  1.1368e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1992e-02,  2.1739e-03,  1.2765e-01],\n",
      "          [ 9.3743e-02,  7.4901e-02,  6.1965e-02],\n",
      "          [ 1.0401e-01,  6.3849e-02,  5.9785e-02]],\n",
      "\n",
      "         [[-9.3523e-03, -7.9424e-02,  4.3694e-02],\n",
      "          [ 1.2562e-02, -4.0238e-02, -7.2405e-02],\n",
      "          [ 2.0988e-02, -7.7090e-02, -8.1423e-02]],\n",
      "\n",
      "         [[-9.7945e-02, -8.7961e-02, -4.2461e-02],\n",
      "          [-1.2534e-01, -7.3453e-02, -2.3039e-02],\n",
      "          [-1.0861e-01, -5.4136e-02,  1.8091e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3415e-02,  1.3830e-02, -4.7158e-02],\n",
      "          [-1.2669e-02, -3.7316e-02, -6.1055e-03],\n",
      "          [-6.0258e-02, -1.1116e-01, -3.2504e-02]],\n",
      "\n",
      "         [[-9.4088e-02, -1.0118e-01, -7.3122e-02],\n",
      "          [-1.2548e-01, -1.1421e-01, -1.0504e-01],\n",
      "          [-8.3825e-02, -6.7843e-02, -5.9872e-02]],\n",
      "\n",
      "         [[ 3.0733e-02,  1.9565e-02,  1.7167e-02],\n",
      "          [-8.4984e-02, -9.8041e-02,  1.2301e-02],\n",
      "          [-1.1164e-01, -1.4604e-01, -7.2879e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0207e-03,  7.0938e-02,  6.6336e-02],\n",
      "          [ 3.1944e-02,  1.0793e-01,  5.4423e-02],\n",
      "          [ 5.7280e-02,  9.4080e-02,  6.3190e-02]],\n",
      "\n",
      "         [[ 1.1126e-01, -5.8816e-03,  4.5941e-02],\n",
      "          [ 1.1827e-01,  2.5403e-02,  7.5639e-02],\n",
      "          [ 7.2811e-02,  7.6833e-02,  1.1168e-01]],\n",
      "\n",
      "         [[-1.0464e-01, -1.7216e-01, -1.2219e-01],\n",
      "          [-9.5770e-02, -1.4503e-01, -8.0476e-02],\n",
      "          [-1.0555e-01, -1.6523e-01, -1.4843e-01]]]])\n",
      "rescnn_layers.3.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0236,  0.0825, -0.1467,  0.1186, -0.0292,  0.0675, -0.0580,  0.1263,\n",
      "         0.0692, -0.1071,  0.1494, -0.0922, -0.1065,  0.0763,  0.0248, -0.0037,\n",
      "         0.1699,  0.0190, -0.0154,  0.0394, -0.0249,  0.0337,  0.0779, -0.0003,\n",
      "         0.0265, -0.0711,  0.0091,  0.0617,  0.0309,  0.1135,  0.1341, -0.0912,\n",
      "        -0.0030, -0.0308,  0.0162,  0.0376, -0.1247,  0.0603,  0.0636,  0.0466,\n",
      "        -0.0917,  0.0618,  0.0089,  0.0740, -0.0278, -0.0126, -0.1076, -0.0915,\n",
      "         0.0735, -0.1155,  0.0443,  0.1215, -0.0245, -0.0729,  0.0108, -0.1933,\n",
      "         0.0299, -0.0186, -0.0534, -0.1098,  0.0300, -0.0976,  0.0067, -0.0508])\n",
      "rescnn_layers.3.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.1420, 1.0835, 1.0125, 1.1018, 1.0586, 0.9852, 0.9996, 0.9448, 0.9856,\n",
      "        0.9187, 0.9588, 0.8860, 0.8716, 0.9499, 0.9280, 0.9355, 0.9384, 0.9358,\n",
      "        0.9398, 1.0164, 0.9917, 1.0643, 1.0515, 1.0140, 1.0522, 1.0543, 1.0498,\n",
      "        1.0858, 1.0508, 0.9924, 1.0018, 1.0205, 1.0132, 0.9845, 0.9977, 1.0307,\n",
      "        1.0190, 1.1128, 1.0507, 1.1051, 1.0915, 1.0272, 1.0543, 1.0032, 1.0208,\n",
      "        1.1269, 1.0687, 1.0423, 1.0960, 1.1537, 1.1690, 1.0348, 1.0767, 1.0529,\n",
      "        1.0501, 1.0704, 1.0930, 0.9801, 0.9994, 1.0188, 0.9941, 0.9454, 0.9810,\n",
      "        1.0911])\n",
      "rescnn_layers.3.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.1473,  0.0765, -0.0800, -0.0294,  0.0197,  0.0110, -0.0073,  0.0034,\n",
      "        -0.0015, -0.0083,  0.0348,  0.0159, -0.0699, -0.0163, -0.0297, -0.0161,\n",
      "        -0.0106, -0.0151, -0.0841, -0.0643, -0.0820, -0.0841, -0.0965, -0.1440,\n",
      "        -0.1034, -0.0630, -0.0492, -0.0216, -0.0855, -0.1002, -0.1185, -0.1133,\n",
      "        -0.0677, -0.0773, -0.0534, -0.0203, -0.0462,  0.0055, -0.0014,  0.0185,\n",
      "         0.0407, -0.0152, -0.0033, -0.0095,  0.0116,  0.0337, -0.0251,  0.0037,\n",
      "         0.0424,  0.0978,  0.0869, -0.0057,  0.0312,  0.0397,  0.0302,  0.0417,\n",
      "         0.0807,  0.0342,  0.0721,  0.0634,  0.0095, -0.0406, -0.0401,  0.0290])\n",
      "rescnn_layers.3.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0346, 1.0085, 0.9941, 1.0171, 0.9962, 0.9933, 1.0234, 1.0574, 1.0629,\n",
      "        1.0377, 1.0333, 1.0485, 1.0759, 1.0756, 1.0432, 1.0375, 1.0250, 0.9777,\n",
      "        0.9440, 0.9769, 0.9924, 1.0432, 0.9811, 0.9638, 0.9489, 0.9314, 0.9434,\n",
      "        1.0309, 1.0173, 0.9997, 1.0306, 1.0002, 0.9764, 0.9312, 0.9301, 0.9296,\n",
      "        0.9795, 1.0364, 1.0002, 1.0076, 0.9983, 0.9925, 0.9650, 0.9592, 0.9681,\n",
      "        0.9622, 0.9762, 0.9553, 0.9359, 0.9661, 0.9601, 0.9029, 0.9037, 0.9567,\n",
      "        0.8421, 0.8629, 0.8197, 0.8210, 0.8158, 0.8533, 0.8680, 0.8747, 0.9593,\n",
      "        1.0019])\n",
      "rescnn_layers.3.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.0350,  0.0301, -0.0189, -0.0587, -0.0321, -0.0820, -0.0495, -0.0512,\n",
      "        -0.0518, -0.0434, -0.0535, -0.0917, -0.0759, -0.0768, -0.0939, -0.1231,\n",
      "        -0.1229, -0.1108, -0.1625, -0.1802, -0.1971, -0.1702, -0.2281, -0.2572,\n",
      "        -0.2246, -0.2134, -0.1925, -0.1621, -0.2135, -0.1848, -0.2215, -0.1925,\n",
      "        -0.1634, -0.2134, -0.1678, -0.1686, -0.1721, -0.1358, -0.1481, -0.1568,\n",
      "        -0.1806, -0.1541, -0.1770, -0.2047, -0.2034, -0.2177, -0.2074, -0.2239,\n",
      "        -0.2535, -0.2448, -0.2072, -0.2143, -0.2274, -0.1792, -0.1655, -0.1315,\n",
      "        -0.1192, -0.1663, -0.1557, -0.1609, -0.1894, -0.2030, -0.1327, -0.1034])\n",
      "fully_connected.weight torch.Size([512, 4096])\n",
      "tensor([[ 0.0471, -0.0118, -0.0126,  ...,  0.0011, -0.0172,  0.0104],\n",
      "        [-0.1120, -0.0724, -0.0971,  ..., -0.1049, -0.1205, -0.1110],\n",
      "        [ 0.0586,  0.0571,  0.0568,  ..., -0.0976, -0.0970, -0.1276],\n",
      "        ...,\n",
      "        [ 0.0399,  0.0783,  0.0496,  ..., -0.0725, -0.0342, -0.0083],\n",
      "        [ 0.1459,  0.1097,  0.0203,  ...,  0.0229, -0.0100, -0.0861],\n",
      "        [-0.0516, -0.1062, -0.0900,  ...,  0.0136,  0.0438,  0.0873]])\n",
      "fully_connected.bias torch.Size([512])\n",
      "tensor([ 3.2304e-02,  5.4665e-02,  1.2608e-03, -2.9497e-02, -2.0997e-02,\n",
      "        -6.7459e-02, -7.8742e-02, -9.0818e-02,  7.6225e-04,  6.0301e-02,\n",
      "         1.0051e-02,  1.7874e-02,  3.0778e-02,  1.0067e-01,  7.7391e-02,\n",
      "        -1.6570e-02, -4.4007e-03,  2.2690e-02, -8.0359e-02,  2.9541e-02,\n",
      "         6.4463e-03,  8.6846e-02,  1.3607e-02,  9.1513e-02,  4.9792e-02,\n",
      "         3.3599e-02, -3.0996e-02,  6.6468e-02,  5.3728e-02, -4.0042e-02,\n",
      "        -1.1597e-03,  6.4490e-02,  4.1221e-03,  7.4062e-02,  1.0737e-02,\n",
      "         6.3598e-03,  5.0282e-02,  4.0597e-02,  2.5698e-03,  6.6105e-02,\n",
      "         6.6886e-02, -4.8142e-02, -9.5959e-02,  2.0466e-02,  2.0729e-02,\n",
      "         1.7818e-02, -5.3698e-05, -1.7133e-02, -5.6132e-02, -2.7625e-02,\n",
      "         7.0551e-02,  6.8492e-02, -5.9073e-03,  2.5825e-02, -1.7681e-03,\n",
      "        -1.9125e-03,  7.7465e-02,  5.7187e-02, -5.5045e-02,  5.3737e-02,\n",
      "         4.8103e-02,  8.7295e-02,  1.1564e-02, -5.9196e-02,  8.8626e-02,\n",
      "         6.1900e-02,  2.2162e-02, -7.5280e-02, -7.5373e-03, -2.7117e-02,\n",
      "         3.0306e-02,  3.7498e-02, -4.0191e-02, -5.6767e-03, -3.0050e-03,\n",
      "        -2.2539e-02,  2.7201e-02, -5.8044e-02, -2.4367e-02, -4.3713e-02,\n",
      "         3.3751e-02,  2.9424e-03,  4.1422e-02,  3.4855e-02,  2.8281e-02,\n",
      "         4.5928e-02,  3.3617e-02,  4.7441e-02,  1.1386e-02,  4.9137e-02,\n",
      "         1.1907e-02,  7.6206e-02, -5.9718e-02,  8.7308e-03, -2.3393e-04,\n",
      "        -2.3505e-02,  2.9431e-02, -2.5129e-03, -2.9027e-02,  5.5855e-02,\n",
      "         1.3160e-02,  4.2366e-03, -5.6926e-02, -7.2408e-03, -5.7420e-02,\n",
      "         1.0145e-01,  7.0316e-02, -1.4585e-02, -5.8782e-02,  8.1709e-02,\n",
      "         2.2880e-03, -1.8722e-02, -2.7599e-03,  7.7070e-02,  3.5198e-02,\n",
      "         1.9583e-02,  6.7565e-02,  5.6571e-02,  2.6178e-02, -5.1627e-02,\n",
      "        -1.0890e-02, -4.3487e-02,  3.8296e-02,  7.2189e-03, -5.6529e-03,\n",
      "         3.5344e-02,  3.5909e-02,  8.2394e-02, -8.8472e-03,  3.6492e-02,\n",
      "         1.2180e-02,  6.8419e-02,  8.5818e-03,  8.9773e-02, -8.1041e-03,\n",
      "         7.7863e-02,  9.1910e-02, -5.8413e-03, -3.4281e-02,  1.0929e-01,\n",
      "         1.5548e-02, -2.0804e-02, -2.8541e-02,  4.4195e-02,  2.6914e-02,\n",
      "         7.0352e-02,  2.8042e-04, -6.3336e-02, -4.1625e-03, -5.0558e-02,\n",
      "        -3.5408e-02,  2.0728e-02,  3.2383e-02,  4.4609e-02, -4.2929e-02,\n",
      "        -2.8280e-03, -4.1410e-02,  5.1358e-02, -1.7998e-02, -1.0159e-03,\n",
      "        -1.7465e-02, -1.0004e-01,  9.7924e-02,  2.2335e-02, -5.6164e-03,\n",
      "         1.7176e-02, -2.9044e-02, -7.0674e-03, -2.5072e-02,  4.2242e-02,\n",
      "        -5.8683e-02, -6.9845e-02,  2.4527e-02,  9.3077e-02,  5.9306e-02,\n",
      "         9.6327e-03, -1.5029e-02,  4.1106e-02,  6.1091e-03, -8.0191e-02,\n",
      "        -1.2465e-02,  6.0794e-02, -2.3913e-02, -3.9982e-02,  1.4042e-01,\n",
      "         9.2886e-02, -1.0948e-02,  1.0034e-01,  2.1022e-02, -1.9993e-02,\n",
      "         5.2663e-02,  8.8202e-02,  7.1420e-02,  1.4048e-01, -6.3549e-02,\n",
      "         5.5586e-02,  3.8737e-02,  8.2162e-03,  1.7179e-02,  7.6013e-03,\n",
      "         1.0402e-01, -3.4335e-02,  1.8460e-02, -2.7853e-02, -1.9763e-02,\n",
      "        -5.6864e-02,  8.6219e-02,  1.1569e-01,  5.7077e-02, -1.1138e-02,\n",
      "        -7.1298e-02,  4.1478e-02,  4.7571e-02,  4.5016e-02,  1.9157e-02,\n",
      "         6.8977e-02, -2.9235e-02, -1.3553e-02,  4.8483e-02, -4.1169e-02,\n",
      "         6.8180e-02, -2.7596e-02, -7.9434e-02,  4.6960e-02, -6.1235e-02,\n",
      "         9.7430e-03,  7.5173e-02,  2.9068e-02,  3.1447e-02,  3.7885e-02,\n",
      "         3.9357e-02,  8.7753e-03, -6.0668e-02,  5.5883e-02,  2.8593e-02,\n",
      "         3.1737e-02, -6.3223e-02,  1.0518e-01, -3.6911e-02,  5.8102e-02,\n",
      "         5.0930e-02, -1.7204e-02, -6.5909e-02, -2.5410e-02, -1.0768e-02,\n",
      "        -3.9665e-03, -1.3140e-02,  5.6847e-02,  6.3823e-02,  2.1540e-02,\n",
      "        -3.4961e-02,  9.9249e-02, -3.4790e-02, -6.1379e-02,  5.1619e-02,\n",
      "         1.3698e-02, -3.8112e-02,  3.8512e-02,  4.5202e-02, -3.8768e-02,\n",
      "         5.6504e-02,  5.8116e-02,  3.1410e-02,  6.6082e-02, -1.1774e-01,\n",
      "         2.5845e-02,  1.6319e-02, -3.0154e-02, -2.2713e-02, -4.7099e-02,\n",
      "        -4.1015e-02,  2.6197e-02, -3.8271e-02,  7.5530e-02, -4.9052e-02,\n",
      "         1.9547e-02, -1.9921e-02,  2.1527e-02, -7.8333e-02,  1.4435e-01,\n",
      "         1.4295e-02,  7.9121e-03,  6.7607e-02,  5.2304e-02, -4.7304e-03,\n",
      "         8.1756e-02, -2.4592e-03,  1.5852e-02,  7.4673e-02,  8.0050e-03,\n",
      "         1.9276e-02,  2.6820e-02,  1.1267e-01, -1.8164e-02, -3.2122e-02,\n",
      "        -4.6634e-02,  7.1516e-02, -8.6051e-03, -1.9121e-03,  5.7953e-02,\n",
      "         5.7431e-02, -1.8112e-02,  8.7204e-02,  1.0533e-01,  1.6919e-02,\n",
      "         4.7928e-02,  6.9136e-02, -3.3555e-02,  2.0327e-02,  4.7626e-02,\n",
      "         2.2248e-02, -4.1457e-02,  5.8026e-02, -2.9746e-02, -1.9590e-02,\n",
      "        -3.9532e-02,  2.4722e-03,  4.1883e-02,  2.2858e-02,  2.5205e-02,\n",
      "         6.8030e-02, -5.9884e-02,  1.1259e-01,  7.3379e-02,  6.5900e-02,\n",
      "        -5.8285e-03,  1.0153e-01, -2.8644e-02, -4.3151e-02,  3.2042e-03,\n",
      "        -9.3059e-03, -9.1115e-02,  9.2011e-03, -4.2445e-02,  3.0688e-02,\n",
      "         3.5070e-02,  1.0295e-01,  1.0375e-02, -3.1566e-02, -3.3599e-02,\n",
      "        -7.0912e-02,  8.9128e-02,  1.2846e-02, -5.2301e-02, -4.6795e-02,\n",
      "         1.3773e-01, -5.4534e-02, -4.7570e-02,  5.2756e-03, -3.0118e-02,\n",
      "         1.1782e-02,  5.5594e-02,  4.7783e-02,  4.2581e-02, -1.6403e-02,\n",
      "        -2.5712e-02,  3.3054e-02, -8.8679e-03, -4.2881e-02, -6.9568e-03,\n",
      "         6.6137e-02,  6.3319e-02,  4.6552e-02,  1.3980e-03, -4.7112e-02,\n",
      "         4.2950e-02, -9.3004e-02,  6.9120e-02,  7.2755e-03, -4.4485e-02,\n",
      "        -9.6792e-02,  7.3155e-02, -1.0067e-01,  3.3935e-02,  6.8748e-02,\n",
      "         2.3607e-02, -1.3574e-02,  2.0381e-02,  1.2953e-01,  4.1444e-02,\n",
      "        -6.2216e-02,  4.1843e-02,  5.3250e-02,  3.0616e-02, -6.3860e-02,\n",
      "        -8.6820e-02,  3.3011e-03, -4.2924e-02, -9.3702e-03,  3.9646e-02,\n",
      "        -8.0573e-02, -3.7789e-02, -3.0245e-02, -7.6772e-02, -8.7197e-02,\n",
      "        -4.8845e-02,  4.4374e-02, -5.0886e-02, -1.8030e-02, -1.0362e-02,\n",
      "        -9.1824e-02,  5.5436e-02, -8.7408e-03, -7.6618e-03, -1.3210e-02,\n",
      "         1.0597e-01,  9.7956e-03,  4.9870e-02, -7.6542e-03,  5.1259e-02,\n",
      "         4.8535e-02,  5.0603e-02,  8.0428e-02,  2.1829e-02, -1.9259e-02,\n",
      "        -3.0687e-02, -2.9811e-02,  8.3242e-02, -4.4567e-02, -4.2996e-02,\n",
      "        -3.7371e-02,  5.7262e-02, -4.9531e-03, -6.4108e-02, -5.5299e-02,\n",
      "         2.3313e-02,  5.1542e-02,  8.3076e-03, -3.9964e-03, -6.7946e-03,\n",
      "        -8.2264e-02,  7.0567e-02, -1.9576e-02, -8.6403e-03, -2.6831e-02,\n",
      "         7.8006e-02, -2.9662e-02, -8.8590e-02,  2.2207e-02, -3.4875e-02,\n",
      "         1.0163e-01,  6.8304e-02, -1.2859e-02,  1.4596e-02, -9.1176e-03,\n",
      "         1.0596e-01,  7.6649e-02, -1.0053e-01,  8.4918e-02, -6.3177e-02,\n",
      "         1.7517e-02, -8.6137e-02,  9.9542e-03,  2.6514e-02, -2.7142e-02,\n",
      "        -8.8677e-03,  5.5724e-03,  4.0639e-02,  5.6236e-02, -6.8800e-02,\n",
      "         1.5568e-02, -3.3328e-02,  1.2462e-02, -4.1163e-02, -5.9665e-03,\n",
      "         9.0631e-03, -2.5923e-02,  2.8761e-02,  1.2600e-01, -1.0159e-02,\n",
      "         1.7401e-02,  2.8856e-05, -7.8742e-03,  1.6081e-02,  1.0044e-01,\n",
      "         2.5147e-02,  2.5829e-02, -1.2234e-02, -2.0863e-02, -7.1515e-02,\n",
      "         1.9864e-02, -9.4552e-02,  9.2601e-02, -4.3498e-02,  6.8062e-03,\n",
      "         3.4230e-03,  8.1541e-02,  3.6158e-02,  4.3373e-02,  1.1313e-01,\n",
      "         1.0259e-01,  5.1780e-02,  6.4286e-02,  2.0914e-02,  3.8117e-02,\n",
      "        -1.0648e-01,  1.0794e-01,  3.7472e-02, -8.9999e-02, -1.1250e-02,\n",
      "         3.2068e-02,  8.0376e-02,  2.7960e-02, -8.5348e-02,  8.8476e-02,\n",
      "        -1.3490e-02, -1.5340e-02,  7.3135e-02, -7.0716e-03, -5.0603e-02,\n",
      "         3.5969e-03, -4.7684e-02])\n",
      "birnn_layers.0.BiGRU.weight_ih_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0364, -0.0398,  0.0990,  ...,  0.0933,  0.0309,  0.0462],\n",
      "        [-0.0004, -0.0678, -0.0738,  ..., -0.0904, -0.1007,  0.0683],\n",
      "        [-0.0805,  0.1138,  0.0677,  ...,  0.0611, -0.0860, -0.1414],\n",
      "        ...,\n",
      "        [ 0.0652,  0.1942, -0.0245,  ..., -0.0591, -0.0079, -0.0507],\n",
      "        [ 0.0472, -0.1298, -0.1192,  ..., -0.0177,  0.0241, -0.0341],\n",
      "        [ 0.0154,  0.0036, -0.1699,  ..., -0.2150, -0.0404, -0.1017]])\n",
      "birnn_layers.0.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.1230,  0.0684, -0.0006,  ...,  0.0091, -0.0511, -0.1752],\n",
      "        [-0.0450, -0.1499,  0.1575,  ...,  0.0400,  0.0356,  0.0044],\n",
      "        [ 0.0458,  0.0577,  0.1026,  ...,  0.0686, -0.0176,  0.0927],\n",
      "        ...,\n",
      "        [-0.0310, -0.0538, -0.1595,  ..., -0.1423, -0.0835,  0.0529],\n",
      "        [-0.0242,  0.1419,  0.0142,  ...,  0.1107,  0.1386,  0.2034],\n",
      "        [-0.0643,  0.1054, -0.0113,  ..., -0.0358, -0.1076,  0.0164]])\n",
      "birnn_layers.0.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([ 0.1740, -0.0687,  0.0043,  ..., -0.0152, -0.0724,  0.0094])\n",
      "birnn_layers.0.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([ 0.1453, -0.1101, -0.0465,  ...,  0.0113, -0.1087,  0.0242])\n",
      "birnn_layers.0.BiGRU.weight_ih_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[-0.0032, -0.1211, -0.0112,  ...,  0.0337,  0.0542,  0.0109],\n",
      "        [ 0.0553, -0.0649, -0.1691,  ...,  0.0952,  0.0060,  0.1333],\n",
      "        [ 0.0211,  0.0698, -0.0778,  ..., -0.0135,  0.0287,  0.0170],\n",
      "        ...,\n",
      "        [ 0.0492,  0.0287,  0.0560,  ...,  0.0713,  0.2174, -0.0929],\n",
      "        [ 0.0217,  0.0313,  0.1209,  ..., -0.0026,  0.0809, -0.0259],\n",
      "        [-0.0335, -0.0633, -0.0643,  ...,  0.1446,  0.1536,  0.1802]])\n",
      "birnn_layers.0.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0209, -0.0498,  0.1651,  ..., -0.0362, -0.0122, -0.0188],\n",
      "        [-0.0182,  0.1768, -0.0778,  ...,  0.0324, -0.0686,  0.0647],\n",
      "        [ 0.0232, -0.0109,  0.0031,  ...,  0.0582,  0.0038,  0.0618],\n",
      "        ...,\n",
      "        [-0.0285, -0.1014,  0.0419,  ..., -0.0982,  0.0523,  0.0285],\n",
      "        [-0.1307, -0.0875, -0.0627,  ...,  0.1195,  0.0085,  0.0286],\n",
      "        [-0.0058,  0.0578,  0.0607,  ...,  0.0820,  0.0620, -0.1391]])\n",
      "birnn_layers.0.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0090, -0.0164,  0.0789,  ...,  0.0142, -0.0760,  0.0158])\n",
      "birnn_layers.0.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([ 0.0403,  0.0454,  0.0512,  ..., -0.0441, -0.0081, -0.0516])\n",
      "birnn_layers.0.layer_norm.weight torch.Size([512])\n",
      "tensor([0.8492, 1.1129, 1.0210, 1.0241, 1.0918, 1.1599, 0.9578, 0.8984, 1.0593,\n",
      "        0.9685, 1.0014, 0.9928, 0.9555, 1.0907, 0.9485, 0.9533, 0.9242, 1.0265,\n",
      "        0.9888, 0.9061, 0.8793, 0.8868, 1.0784, 0.8584, 1.0659, 0.8933, 0.8824,\n",
      "        0.9224, 0.9440, 1.0028, 0.8868, 0.9398, 0.9960, 0.9056, 1.0572, 1.0143,\n",
      "        0.9094, 0.9721, 0.9786, 0.8847, 0.8921, 1.1130, 1.1391, 0.8892, 0.8856,\n",
      "        0.9835, 0.9686, 0.9864, 0.9925, 0.9763, 0.9828, 0.9254, 1.1264, 0.9988,\n",
      "        1.0325, 0.8644, 0.9537, 0.9021, 1.0148, 0.9863, 1.0130, 0.8617, 0.9800,\n",
      "        0.9303, 0.8345, 0.8103, 0.8753, 1.1893, 1.0209, 0.9252, 0.9418, 1.1473,\n",
      "        1.1248, 1.1092, 0.9552, 1.0016, 0.9207, 1.1377, 0.9948, 0.9607, 0.9378,\n",
      "        0.9471, 0.9596, 0.8825, 0.9911, 0.9649, 0.9250, 1.1052, 0.9011, 1.0406,\n",
      "        0.9036, 0.8522, 1.1920, 1.0760, 0.9173, 1.1294, 1.0629, 0.9477, 0.9478,\n",
      "        0.9529, 1.0711, 0.9490, 1.1158, 0.9219, 0.9195, 0.8822, 0.9509, 1.0009,\n",
      "        1.1668, 1.0326, 0.9712, 0.9054, 1.0940, 0.9886, 0.9295, 0.8763, 0.9958,\n",
      "        0.9534, 0.9273, 1.0370, 0.9507, 1.1512, 0.9448, 1.0670, 1.0611, 1.0076,\n",
      "        1.0256, 0.9184, 1.0031, 1.0046, 0.9651, 0.8783, 1.1192, 0.9424, 0.9903,\n",
      "        0.8399, 0.8032, 0.9764, 0.9149, 0.7570, 1.1125, 0.9726, 0.8798, 1.1752,\n",
      "        0.9975, 0.8890, 1.0608, 1.0983, 1.0754, 1.0600, 1.0846, 0.8680, 0.9649,\n",
      "        0.8364, 0.9031, 1.0269, 0.9548, 1.0356, 1.0357, 0.9687, 1.1308, 0.9688,\n",
      "        0.8963, 1.1046, 1.0554, 0.9216, 0.9194, 1.0788, 1.0793, 0.9304, 1.0946,\n",
      "        0.9856, 0.9725, 0.9164, 0.9139, 0.9889, 1.0493, 1.0281, 1.0212, 1.1594,\n",
      "        0.8803, 0.9070, 0.9590, 1.1115, 0.8397, 0.8853, 0.9047, 0.9255, 0.9475,\n",
      "        1.2481, 0.9784, 0.7984, 0.8707, 0.8580, 1.0788, 0.9014, 0.9857, 1.0014,\n",
      "        1.0377, 0.9521, 0.8890, 0.9832, 0.8689, 0.9318, 1.0842, 1.1168, 0.9066,\n",
      "        0.8805, 0.9784, 1.0064, 1.1872, 0.9846, 0.9672, 0.9473, 0.9865, 0.9055,\n",
      "        0.8909, 1.0192, 0.9504, 1.1475, 1.0054, 0.9913, 1.1118, 1.0795, 1.1064,\n",
      "        0.9296, 0.9508, 1.0182, 0.9447, 0.9716, 0.9965, 0.9081, 1.0952, 0.7946,\n",
      "        0.9955, 1.0936, 0.9083, 0.9045, 0.9114, 1.0402, 1.0167, 1.0717, 0.8925,\n",
      "        0.9953, 1.0045, 1.0125, 1.0875, 0.9841, 0.8945, 1.0200, 0.9007, 0.9082,\n",
      "        1.0594, 1.0546, 0.8315, 1.0505, 1.0699, 0.9008, 0.8156, 1.1075, 0.8218,\n",
      "        1.1637, 1.0097, 1.0487, 1.0371, 0.9520, 1.1340, 0.8928, 1.0070, 0.9159,\n",
      "        0.9533, 0.8157, 0.8699, 0.8343, 0.9993, 1.0646, 0.9826, 0.9498, 1.1662,\n",
      "        0.6908, 1.0126, 1.0470, 0.9339, 1.0250, 1.0273, 0.8996, 1.0906, 0.8477,\n",
      "        1.0272, 1.0592, 0.9321, 1.0286, 0.8331, 1.0552, 1.1052, 1.0430, 0.9153,\n",
      "        0.9284, 0.9684, 0.9694, 0.9155, 1.0440, 0.9284, 0.9633, 1.1671, 1.0481,\n",
      "        0.9573, 1.0822, 0.9641, 1.0105, 0.9242, 1.0396, 0.9719, 1.0667, 1.0352,\n",
      "        1.0070, 1.0251, 0.9619, 0.9136, 0.9238, 0.8187, 0.9040, 0.8177, 0.8907,\n",
      "        0.8481, 0.9687, 0.9009, 1.0701, 0.9231, 1.1097, 1.0590, 0.8925, 1.0291,\n",
      "        1.0424, 1.2134, 0.9075, 0.8695, 0.9329, 0.9650, 0.9595, 1.0249, 0.9008,\n",
      "        0.9462, 1.0664, 1.1301, 0.8362, 1.0735, 0.9803, 1.0730, 1.0790, 0.9524,\n",
      "        0.9067, 0.9770, 1.0068, 0.8585, 1.0386, 1.0015, 1.0384, 1.0897, 1.0043,\n",
      "        0.9521, 0.9454, 0.9137, 0.9962, 1.1533, 1.0382, 1.0708, 0.9626, 1.0789,\n",
      "        1.0697, 0.9626, 0.9134, 1.1571, 0.9303, 0.7515, 1.0271, 0.9674, 0.9977,\n",
      "        0.9352, 0.9026, 1.1111, 1.0845, 1.0431, 1.0180, 0.9841, 0.9675, 1.0819,\n",
      "        0.8958, 1.0518, 0.9983, 1.2023, 1.0828, 1.0264, 0.8974, 1.0640, 0.9955,\n",
      "        0.7730, 0.9407, 1.0495, 1.0852, 1.1005, 0.7769, 0.9296, 0.9752, 1.1191,\n",
      "        0.9134, 0.9793, 0.9011, 0.9871, 0.9371, 0.9794, 0.8847, 0.8121, 0.8703,\n",
      "        1.0157, 0.9521, 0.9644, 0.7973, 1.0204, 0.9471, 1.1002, 0.8563, 0.9806,\n",
      "        0.9796, 1.0415, 0.9855, 1.0936, 0.9963, 1.0734, 0.7980, 1.0775, 0.9891,\n",
      "        0.8914, 1.0946, 0.9208, 0.7533, 0.9703, 1.0680, 1.0911, 1.1065, 0.8060,\n",
      "        0.9211, 1.0053, 0.9608, 0.9448, 0.8517, 0.9045, 1.0283, 0.9666, 0.9102,\n",
      "        1.0805, 0.9134, 0.8254, 1.0053, 0.9738, 1.0117, 1.0672, 0.9846, 0.9325,\n",
      "        0.9254, 1.0012, 1.0370, 0.9195, 0.9985, 1.0068, 1.1120, 1.0478, 0.8816,\n",
      "        0.7633, 0.9900, 0.9329, 0.9773, 0.9584, 0.9338, 0.8222, 0.9558, 1.0195,\n",
      "        1.0427, 1.0378, 1.0839, 1.1212, 0.9700, 1.0361, 1.0305, 0.8559, 1.0813,\n",
      "        0.8085, 0.8702, 0.9702, 0.9548, 0.7297, 0.9743, 0.8769, 1.0797, 0.9023,\n",
      "        1.1051, 1.0663, 0.9474, 1.0625, 0.9989, 0.9302, 0.8686, 0.9739, 0.9726,\n",
      "        0.9315, 1.0268, 1.0341, 0.8116, 0.9858, 1.0240, 1.0348, 1.1193])\n",
      "birnn_layers.0.layer_norm.bias torch.Size([512])\n",
      "tensor([-0.2656, -0.2072, -0.2908, -0.3151, -0.2650, -0.2220, -0.2866, -0.3353,\n",
      "        -0.2243, -0.2625, -0.2646, -0.2383, -0.2864, -0.2369, -0.2522, -0.2600,\n",
      "        -0.3664, -0.2521, -0.3590, -0.3547, -0.3524, -0.3047, -0.2153, -0.2893,\n",
      "        -0.2700, -0.3195, -0.3339, -0.3250, -0.2454, -0.3367, -0.2974, -0.3225,\n",
      "        -0.2736, -0.3159, -0.2076, -0.2499, -0.2779, -0.2645, -0.3097, -0.3410,\n",
      "        -0.3151, -0.3093, -0.2119, -0.3860, -0.3377, -0.3329, -0.2911, -0.3551,\n",
      "        -0.3152, -0.3194, -0.3403, -0.2931, -0.1838, -0.2572, -0.2579, -0.3510,\n",
      "        -0.2506, -0.3243, -0.3166, -0.3245, -0.2605, -0.3456, -0.3256, -0.2954,\n",
      "        -0.3005, -0.3014, -0.3530, -0.2644, -0.3249, -0.3177, -0.2835, -0.1400,\n",
      "        -0.2745, -0.2064, -0.3911, -0.3028, -0.3433, -0.2809, -0.2261, -0.3424,\n",
      "        -0.2492, -0.2729, -0.3057, -0.3301, -0.3003, -0.2814, -0.3004, -0.2571,\n",
      "        -0.3231, -0.2021, -0.3242, -0.3087, -0.2235, -0.2179, -0.2969, -0.2220,\n",
      "        -0.2536, -0.2975, -0.3366, -0.3165, -0.2276, -0.3435, -0.2694, -0.3033,\n",
      "        -0.3309, -0.2611, -0.2445, -0.3119, -0.2581, -0.2819, -0.2779, -0.3924,\n",
      "        -0.2640, -0.2695, -0.3180, -0.3163, -0.2870, -0.3179, -0.3306, -0.2207,\n",
      "        -0.3022, -0.2310, -0.3151, -0.3042, -0.2426, -0.3036, -0.2599, -0.3021,\n",
      "        -0.3176, -0.2893, -0.2710, -0.3377, -0.2590, -0.2963, -0.2977, -0.3373,\n",
      "        -0.2919, -0.3125, -0.3468, -0.3205, -0.2313, -0.2751, -0.3525, -0.2116,\n",
      "        -0.2745, -0.3228, -0.2453, -0.2427, -0.3136, -0.2303, -0.2530, -0.3182,\n",
      "        -0.3349, -0.3385, -0.3293, -0.2741, -0.3619, -0.2540, -0.1895, -0.2967,\n",
      "        -0.2475, -0.3789, -0.2741, -0.2143, -0.2158, -0.3379, -0.3130, -0.2883,\n",
      "        -0.2894, -0.2992, -0.3115, -0.3471, -0.3189, -0.3147, -0.2942, -0.2428,\n",
      "        -0.2244, -0.3011, -0.2482, -0.1911, -0.3466, -0.3200, -0.2841, -0.2309,\n",
      "        -0.2560, -0.2989, -0.3647, -0.2863, -0.2971, -0.2113, -0.3032, -0.2968,\n",
      "        -0.2387, -0.3095, -0.2467, -0.3154, -0.2778, -0.2802, -0.2747, -0.3084,\n",
      "        -0.3131, -0.3452, -0.3233, -0.3084, -0.2849, -0.2159, -0.2730, -0.2805,\n",
      "        -0.3135, -0.3098, -0.2765, -0.2492, -0.2539, -0.3212, -0.2866, -0.2725,\n",
      "        -0.3494, -0.2221, -0.3032, -0.2183, -0.3056, -0.3685, -0.2018, -0.2641,\n",
      "        -0.3139, -0.2866, -0.2786, -0.2513, -0.2401, -0.2785, -0.2570, -0.3682,\n",
      "        -0.2590, -0.2821, -0.2664, -0.2157, -0.2986, -0.3017, -0.3205, -0.2506,\n",
      "        -0.2241, -0.2802, -0.3349, -0.3254, -0.2921, -0.3100, -0.2613, -0.2267,\n",
      "        -0.3144, -0.2879, -0.3723, -0.3200, -0.2784, -0.2850, -0.3000, -0.2659,\n",
      "        -0.2508, -0.3201, -0.3346, -0.2315, -0.3245, -0.1639, -0.3144, -0.2165,\n",
      "        -0.2748, -0.2999, -0.2141, -0.3002, -0.2603, -0.2824, -0.3528, -0.3420,\n",
      "        -0.3654, -0.3101, -0.2854, -0.2100, -0.3167, -0.3460, -0.2162, -0.3289,\n",
      "        -0.2534, -0.2194, -0.3182, -0.3149, -0.3691, -0.3346, -0.2917, -0.3645,\n",
      "        -0.2457, -0.2950, -0.3114, -0.2933, -0.2906, -0.1926, -0.2616, -0.2980,\n",
      "        -0.2509, -0.3531, -0.3108, -0.2919, -0.3260, -0.3145, -0.2986, -0.2718,\n",
      "        -0.2012, -0.2705, -0.2753, -0.2482, -0.3084, -0.2480, -0.3337, -0.3574,\n",
      "        -0.3059, -0.2797, -0.2717, -0.3600, -0.2721, -0.3271, -0.2831, -0.3378,\n",
      "        -0.3374, -0.3629, -0.3327, -0.2915, -0.3730, -0.3110, -0.3075, -0.2084,\n",
      "        -0.3056, -0.2442, -0.2947, -0.2802, -0.3338, -0.2885, -0.2944, -0.3066,\n",
      "        -0.3245, -0.3281, -0.2386, -0.2679, -0.2411, -0.2670, -0.3024, -0.2688,\n",
      "        -0.2660, -0.3061, -0.2713, -0.3707, -0.2364, -0.2769, -0.3048, -0.3137,\n",
      "        -0.3178, -0.2366, -0.2913, -0.2790, -0.2549, -0.2918, -0.2255, -0.2379,\n",
      "        -0.3015, -0.2820, -0.3242, -0.3531, -0.2202, -0.2722, -0.2962, -0.2799,\n",
      "        -0.2488, -0.2320, -0.3093, -0.3092, -0.1885, -0.2896, -0.3307, -0.2147,\n",
      "        -0.3107, -0.2650, -0.2365, -0.2657, -0.2245, -0.2046, -0.2858, -0.3064,\n",
      "        -0.2943, -0.3093, -0.2456, -0.3338, -0.2714, -0.2690, -0.2241, -0.3019,\n",
      "        -0.2498, -0.3364, -0.3299, -0.3362, -0.3541, -0.3040, -0.3112, -0.2514,\n",
      "        -0.3162, -0.3245, -0.2845, -0.2845, -0.2303, -0.2663, -0.2875, -0.3554,\n",
      "        -0.3231, -0.3274, -0.2944, -0.3379, -0.3322, -0.3273, -0.2641, -0.2898,\n",
      "        -0.3237, -0.2955, -0.2647, -0.3189, -0.2583, -0.2964, -0.3036, -0.2837,\n",
      "        -0.2905, -0.2975, -0.2211, -0.3021, -0.3141, -0.3473, -0.2671, -0.3222,\n",
      "        -0.2937, -0.2345, -0.3401, -0.3386, -0.3729, -0.2810, -0.2693, -0.2221,\n",
      "        -0.2861, -0.3149, -0.3055, -0.3258, -0.2767, -0.3020, -0.3526, -0.2635,\n",
      "        -0.2874, -0.3302, -0.2621, -0.3059, -0.3506, -0.2652, -0.2668, -0.3323,\n",
      "        -0.2018, -0.3211, -0.2659, -0.2990, -0.2162, -0.2895, -0.3166, -0.3395,\n",
      "        -0.2280, -0.1986, -0.3030, -0.2599, -0.3478, -0.2482, -0.3520, -0.3372,\n",
      "        -0.2716, -0.3569, -0.2965, -0.2843, -0.2428, -0.2878, -0.2335, -0.2712,\n",
      "        -0.1935, -0.3066, -0.3161, -0.2736, -0.3539, -0.3303, -0.2781, -0.3172,\n",
      "        -0.3039, -0.2569, -0.3358, -0.2785, -0.3708, -0.2059, -0.3319, -0.2647,\n",
      "        -0.2525, -0.3120, -0.2968, -0.3003, -0.3075, -0.3242, -0.3584, -0.2903,\n",
      "        -0.3002, -0.2588, -0.3005, -0.2731, -0.2958, -0.2830, -0.2617, -0.2823])\n",
      "birnn_layers.1.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-4.0749e-02,  2.5860e-02,  3.3416e-02,  ...,  1.6926e-02,\n",
      "          5.2254e-02,  8.6259e-02],\n",
      "        [-5.4942e-02,  2.7755e-03, -5.6558e-02,  ..., -1.6686e-02,\n",
      "          1.9007e-04, -7.8790e-03],\n",
      "        [-1.5168e-02, -5.5302e-02, -7.6471e-02,  ..., -1.5813e-01,\n",
      "         -5.8911e-02, -3.5354e-02],\n",
      "        ...,\n",
      "        [ 2.5529e-02,  1.0092e-01, -1.8838e-01,  ..., -1.9758e-01,\n",
      "          1.1819e-01, -3.4608e-02],\n",
      "        [ 3.5857e-02,  2.6838e-02,  2.5866e-02,  ..., -5.6563e-02,\n",
      "         -8.9034e-03,  9.2882e-02],\n",
      "        [ 6.6663e-02, -9.7909e-03, -6.7720e-02,  ..., -1.2028e-01,\n",
      "         -1.3379e-01,  1.8732e-02]])\n",
      "birnn_layers.1.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[-0.0968,  0.0952, -0.0956,  ..., -0.0583, -0.0014,  0.0649],\n",
      "        [-0.0022,  0.0240, -0.0437,  ...,  0.0258,  0.0588,  0.0657],\n",
      "        [-0.1044,  0.0877, -0.0634,  ...,  0.1098,  0.0749,  0.0699],\n",
      "        ...,\n",
      "        [-0.1156, -0.0596,  0.0363,  ..., -0.0612,  0.0935,  0.0510],\n",
      "        [ 0.0410,  0.0771, -0.0008,  ..., -0.0213, -0.0456,  0.0260],\n",
      "        [ 0.1352,  0.1117,  0.0381,  ...,  0.0198, -0.0818,  0.0325]])\n",
      "birnn_layers.1.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0118, -0.0717, -0.0848,  ..., -0.0458, -0.0108, -0.0562])\n",
      "birnn_layers.1.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([ 0.0272, -0.1033, -0.0736,  ..., -0.0162, -0.0229, -0.0044])\n",
      "birnn_layers.1.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0318, -0.0851, -0.0815,  ..., -0.0505,  0.0120,  0.0124],\n",
      "        [-0.0427, -0.0460,  0.0212,  ..., -0.0116, -0.0056, -0.0422],\n",
      "        [-0.0860, -0.1137, -0.0410,  ..., -0.0980, -0.0123, -0.0068],\n",
      "        ...,\n",
      "        [-0.0099, -0.0026, -0.0438,  ..., -0.0839, -0.0232, -0.0492],\n",
      "        [-0.0739,  0.0157,  0.0958,  ...,  0.0468,  0.0357, -0.0007],\n",
      "        [-0.0440,  0.0167,  0.0334,  ...,  0.1471,  0.0213,  0.0315]])\n",
      "birnn_layers.1.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0374,  0.0327, -0.0563,  ..., -0.0177,  0.0108,  0.0889],\n",
      "        [ 0.0319, -0.0455, -0.0692,  ...,  0.0258,  0.0083,  0.0289],\n",
      "        [ 0.0434,  0.0602,  0.0209,  ..., -0.0076,  0.0397,  0.0543],\n",
      "        ...,\n",
      "        [ 0.0092, -0.0474, -0.1089,  ..., -0.0392, -0.0398,  0.0657],\n",
      "        [ 0.1336,  0.0599,  0.0465,  ..., -0.0087, -0.1221,  0.0197],\n",
      "        [ 0.0155,  0.0266, -0.0210,  ...,  0.0706, -0.1504, -0.2127]])\n",
      "birnn_layers.1.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.1111, -0.0725, -0.1104,  ...,  0.0569, -0.0073,  0.0484])\n",
      "birnn_layers.1.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0809, -0.1063, -0.0925,  ..., -0.0028,  0.0679,  0.0041])\n",
      "birnn_layers.1.layer_norm.weight torch.Size([1024])\n",
      "tensor([1.0723, 0.8115, 1.0615,  ..., 0.9304, 0.8759, 0.9804])\n",
      "birnn_layers.1.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0514, -0.1684, -0.0307,  ..., -0.0752, -0.0861, -0.0365])\n",
      "birnn_layers.2.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-0.1035, -0.0071, -0.0158,  ...,  0.0523, -0.1274, -0.0811],\n",
      "        [ 0.0907,  0.0086,  0.0523,  ...,  0.0434, -0.0040,  0.0354],\n",
      "        [-0.1450, -0.0481,  0.0034,  ..., -0.0133, -0.0193, -0.0234],\n",
      "        ...,\n",
      "        [-0.0310, -0.0777,  0.0117,  ..., -0.0175, -0.0002, -0.0723],\n",
      "        [-0.0757, -0.1065, -0.1464,  ..., -0.0529,  0.0158,  0.0574],\n",
      "        [-0.0056,  0.0003, -0.0148,  ...,  0.0122, -0.0465, -0.0229]])\n",
      "birnn_layers.2.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0162, -0.1385,  0.0093,  ..., -0.0103, -0.0655,  0.0159],\n",
      "        [ 0.0454, -0.0007,  0.0876,  ...,  0.0523,  0.0153, -0.0135],\n",
      "        [ 0.0168,  0.0762, -0.0349,  ...,  0.0498,  0.0479,  0.1164],\n",
      "        ...,\n",
      "        [-0.1120, -0.0379,  0.0369,  ..., -0.0895,  0.0394,  0.0645],\n",
      "        [ 0.1218,  0.0573,  0.0744,  ..., -0.0671, -0.0975,  0.0612],\n",
      "        [-0.0314,  0.0247,  0.0074,  ...,  0.0437,  0.0407, -0.0200]])\n",
      "birnn_layers.2.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0821,  0.0565, -0.1398,  ...,  0.0177, -0.0471, -0.0047])\n",
      "birnn_layers.2.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0668,  0.0110, -0.0747,  ..., -0.0406, -0.1050, -0.0136])\n",
      "birnn_layers.2.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0281,  0.0293,  0.0044,  ..., -0.0379, -0.0091, -0.0407],\n",
      "        [ 0.0846, -0.0756, -0.0893,  ..., -0.0319, -0.0560,  0.0481],\n",
      "        [-0.0535,  0.0422, -0.0514,  ..., -0.0536, -0.0419, -0.0180],\n",
      "        ...,\n",
      "        [-0.0081, -0.0263, -0.0233,  ..., -0.0430, -0.0040, -0.0643],\n",
      "        [-0.0859,  0.0839, -0.1001,  ..., -0.0487, -0.0578, -0.0933],\n",
      "        [-0.0478,  0.0943,  0.0491,  ..., -0.0268, -0.0274,  0.0008]])\n",
      "birnn_layers.2.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0233,  0.0094,  0.0405,  ..., -0.0369, -0.0468,  0.0029],\n",
      "        [ 0.0665,  0.0087,  0.0765,  ...,  0.0262,  0.0115, -0.0361],\n",
      "        [ 0.0389, -0.0362,  0.0185,  ...,  0.0498,  0.0649,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0345,  0.0138,  0.0442,  ...,  0.0201,  0.0154,  0.0278],\n",
      "        [ 0.0255,  0.0429, -0.0604,  ..., -0.0036, -0.0312, -0.0417],\n",
      "        [-0.0516,  0.0439,  0.1152,  ...,  0.0295, -0.0106,  0.0308]])\n",
      "birnn_layers.2.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0184, -0.0440, -0.0515,  ..., -0.0150, -0.0241,  0.0184])\n",
      "birnn_layers.2.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0222, -0.0087, -0.0461,  ...,  0.0293, -0.0516, -0.0431])\n",
      "birnn_layers.2.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9952, 0.8569, 0.8963,  ..., 0.8023, 1.1400, 0.9208])\n",
      "birnn_layers.2.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0509, -0.1743, -0.1549,  ..., -0.1750,  0.1085, -0.0406])\n",
      "birnn_layers.3.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-0.0295,  0.0215,  0.0380,  ...,  0.0078,  0.0027,  0.0039],\n",
      "        [-0.0283, -0.0257, -0.0241,  ..., -0.0086, -0.0488, -0.0317],\n",
      "        [-0.0137, -0.0091, -0.0298,  ...,  0.0290,  0.0221,  0.0253],\n",
      "        ...,\n",
      "        [-0.0222, -0.0154, -0.0008,  ...,  0.0178,  0.0041,  0.0294],\n",
      "        [-0.0321, -0.0563,  0.0460,  ...,  0.0089,  0.0080,  0.0649],\n",
      "        [ 0.0445, -0.0047,  0.0163,  ...,  0.0071, -0.0692, -0.0395]])\n",
      "birnn_layers.3.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[-0.0176,  0.0428,  0.0405,  ..., -0.0024,  0.0304, -0.0026],\n",
      "        [ 0.0152,  0.0184,  0.0071,  ...,  0.0610, -0.0430,  0.0654],\n",
      "        [ 0.0520, -0.0054,  0.0021,  ..., -0.0030, -0.0035, -0.0237],\n",
      "        ...,\n",
      "        [-0.0316, -0.0488, -0.0581,  ...,  0.0311,  0.0323,  0.0249],\n",
      "        [ 0.0215,  0.0485, -0.0080,  ..., -0.0162, -0.0110, -0.0425],\n",
      "        [ 0.0575, -0.0128, -0.0226,  ...,  0.0594, -0.0626, -0.0319]])\n",
      "birnn_layers.3.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0925, -0.0668,  0.0110,  ..., -0.0018,  0.0443, -0.1026])\n",
      "birnn_layers.3.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0402, -0.1166, -0.0215,  ..., -0.0443, -0.0130,  0.0020])\n",
      "birnn_layers.3.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0160, -0.0260,  0.0400,  ..., -0.0241, -0.0257,  0.0161],\n",
      "        [-0.0086,  0.0823,  0.0270,  ...,  0.0510, -0.0298, -0.0411],\n",
      "        [ 0.0374,  0.0528,  0.0310,  ..., -0.0150,  0.0601, -0.0056],\n",
      "        ...,\n",
      "        [-0.0753, -0.0401, -0.1058,  ..., -0.0160, -0.1544, -0.0969],\n",
      "        [ 0.0450,  0.0257,  0.0501,  ..., -0.0250, -0.0606, -0.0094],\n",
      "        [-0.1208, -0.1011, -0.1130,  ..., -0.0857, -0.1303, -0.1268]])\n",
      "birnn_layers.3.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0089, -0.0079, -0.0321,  ..., -0.0328,  0.0056, -0.0122],\n",
      "        [ 0.0157, -0.0437,  0.0005,  ..., -0.1245, -0.0734, -0.0548],\n",
      "        [ 0.0183,  0.0303,  0.0322,  ..., -0.0768,  0.0108, -0.1295],\n",
      "        ...,\n",
      "        [ 0.0431, -0.0429,  0.0038,  ...,  0.1242,  0.0200,  0.0566],\n",
      "        [-0.0615,  0.0502,  0.0041,  ...,  0.0558, -0.0271, -0.0475],\n",
      "        [ 0.0384,  0.0385, -0.0498,  ..., -0.0840, -0.0774, -0.0553]])\n",
      "birnn_layers.3.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0072,  0.0286,  0.0840,  ..., -0.0688,  0.0108,  0.0080])\n",
      "birnn_layers.3.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([ 0.0456, -0.0029,  0.1205,  ..., -0.0017,  0.0725, -0.0161])\n",
      "birnn_layers.3.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9404, 0.8036, 1.0270,  ..., 0.7630, 1.1184, 0.8939])\n",
      "birnn_layers.3.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0680, -0.0605,  0.0125,  ..., -0.1477, -0.0604, -0.0834])\n",
      "birnn_layers.4.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[ 0.0901, -0.0802, -0.0680,  ..., -0.0797, -0.0852, -0.0435],\n",
      "        [-0.0189, -0.0436, -0.0020,  ...,  0.0251,  0.0227, -0.0071],\n",
      "        [ 0.0079, -0.0355,  0.0211,  ..., -0.0263, -0.0132,  0.0112],\n",
      "        ...,\n",
      "        [-0.0417, -0.0360,  0.0030,  ...,  0.0653, -0.0164, -0.0568],\n",
      "        [-0.0392,  0.0003, -0.0217,  ..., -0.0343,  0.0024,  0.0199],\n",
      "        [ 0.0501, -0.0479, -0.0886,  ..., -0.0519, -0.0230, -0.0543]])\n",
      "birnn_layers.4.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0745,  0.0194, -0.0599,  ...,  0.0388, -0.0888,  0.0088],\n",
      "        [ 0.0142,  0.0019, -0.0327,  ..., -0.0349,  0.0180,  0.0375],\n",
      "        [-0.0137,  0.0170,  0.0249,  ...,  0.0345,  0.0576,  0.0057],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0440, -0.0034,  ...,  0.0350, -0.0308,  0.0144],\n",
      "        [-0.0225, -0.0872, -0.0169,  ...,  0.0069,  0.0068, -0.0361],\n",
      "        [ 0.0203,  0.0354,  0.0389,  ...,  0.0319,  0.0689, -0.0889]])\n",
      "birnn_layers.4.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0611,  0.0204,  0.0048,  ..., -0.0091, -0.0118, -0.0268])\n",
      "birnn_layers.4.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0460, -0.0236, -0.0044,  ...,  0.0003,  0.0227,  0.0232])\n",
      "birnn_layers.4.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0824, -0.1633,  0.0063,  ...,  0.0559, -0.0423, -0.1143],\n",
      "        [ 0.1176, -0.0872,  0.0148,  ..., -0.0755,  0.0051,  0.0804],\n",
      "        [ 0.0301, -0.0099, -0.0458,  ..., -0.0675,  0.0087, -0.0357],\n",
      "        ...,\n",
      "        [-0.0345, -0.0113,  0.0893,  ...,  0.0568,  0.0724,  0.0520],\n",
      "        [-0.0395, -0.0170, -0.0299,  ..., -0.0496, -0.0350,  0.0142],\n",
      "        [-0.0285, -0.0133, -0.0854,  ..., -0.0049, -0.1000, -0.0373]])\n",
      "birnn_layers.4.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0579, -0.0812,  0.1168,  ..., -0.0680, -0.0216,  0.0231],\n",
      "        [ 0.0051, -0.1418, -0.0353,  ...,  0.0372,  0.0122,  0.0803],\n",
      "        [-0.1306, -0.0338, -0.1962,  ...,  0.0522,  0.0222, -0.0335],\n",
      "        ...,\n",
      "        [-0.0985,  0.0978,  0.0221,  ...,  0.0401,  0.0003,  0.0456],\n",
      "        [-0.0066, -0.0143,  0.0313,  ..., -0.0273, -0.0300, -0.0039],\n",
      "        [-0.0285,  0.0329,  0.0339,  ..., -0.0605, -0.0532, -0.0445]])\n",
      "birnn_layers.4.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([0.0003, 0.0689, 0.0098,  ..., 0.1109, 0.0236, 0.0180])\n",
      "birnn_layers.4.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0376,  0.0794,  0.0086,  ...,  0.0013, -0.0325, -0.0449])\n",
      "birnn_layers.4.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9454, 1.0155, 0.8411,  ..., 0.9289, 0.9416, 1.0805])\n",
      "birnn_layers.4.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.1183,  0.0189, -0.1610,  ..., -0.1536, -0.0685, -0.1491])\n",
      "classifier.0.weight torch.Size([512, 1024])\n",
      "tensor([[ 0.0253, -0.0013,  0.0156,  ..., -0.0284,  0.0294, -0.0086],\n",
      "        [ 0.0598, -0.0060, -0.0225,  ...,  0.0075,  0.0461, -0.0010],\n",
      "        [ 0.0347,  0.0089, -0.0455,  ...,  0.0188,  0.0101,  0.0130],\n",
      "        ...,\n",
      "        [ 0.0660, -0.0314, -0.0152,  ...,  0.0216, -0.0243, -0.0248],\n",
      "        [ 0.0469, -0.0137, -0.0011,  ...,  0.0471,  0.0360, -0.0058],\n",
      "        [ 0.0285,  0.0112,  0.0189,  ...,  0.0047, -0.0084, -0.0073]])\n",
      "classifier.0.bias torch.Size([512])\n",
      "tensor([-0.0946, -0.1049, -0.1129, -0.0970, -0.0987, -0.1217, -0.0326, -0.1329,\n",
      "        -0.0087, -0.1007, -0.0867, -0.1086, -0.0930, -0.1021, -0.0983, -0.1097,\n",
      "        -0.0705, -0.1266, -0.0771, -0.0916, -0.1201,  0.0038, -0.0823, -0.0320,\n",
      "        -0.1071, -0.0986, -0.1040, -0.0163,  0.0282, -0.1330, -0.1431, -0.1072,\n",
      "        -0.1273, -0.0979, -0.1346, -0.1428, -0.1061, -0.0065, -0.0970, -0.1323,\n",
      "        -0.0591, -0.1117, -0.0522, -0.1109, -0.0727, -0.1040, -0.1343, -0.1322,\n",
      "        -0.1158, -0.1171, -0.1062, -0.0704, -0.1163, -0.1075, -0.1484, -0.1323,\n",
      "        -0.0998, -0.0981, -0.0995, -0.1289, -0.1118, -0.0878, -0.0805, -0.1267,\n",
      "        -0.0969, -0.1133, -0.0703, -0.0743, -0.1149, -0.1074, -0.0993, -0.1094,\n",
      "        -0.1225, -0.1147, -0.0960, -0.0947, -0.0469, -0.0905, -0.1362, -0.1461,\n",
      "        -0.0917, -0.1041, -0.0977,  0.0253, -0.1306, -0.1373, -0.0930, -0.1056,\n",
      "        -0.1388, -0.0125, -0.1040, -0.1420, -0.1180, -0.1119,  0.0743, -0.0361,\n",
      "        -0.0420, -0.1132, -0.0633, -0.1125, -0.1451, -0.1178, -0.1010, -0.1333,\n",
      "        -0.1076, -0.0941, -0.0815,  0.0125, -0.0840, -0.1189, -0.0988, -0.1007,\n",
      "        -0.1386, -0.1135, -0.0917, -0.1008, -0.0956, -0.0985, -0.1127, -0.0338,\n",
      "        -0.0655, -0.0567, -0.1230,  0.0079, -0.1054, -0.1109, -0.0291, -0.1028,\n",
      "        -0.0313, -0.1062, -0.1030, -0.0960, -0.0877, -0.0831, -0.0696, -0.0916,\n",
      "        -0.1306, -0.0921, -0.1227, -0.1122,  0.0354, -0.1080, -0.1336, -0.1352,\n",
      "        -0.1449, -0.0611, -0.0926, -0.0665, -0.1233, -0.0864, -0.0979, -0.1117,\n",
      "        -0.1344, -0.1292, -0.0541, -0.1312, -0.1207, -0.1078, -0.1377, -0.1338,\n",
      "        -0.1108, -0.0868, -0.1316, -0.1024, -0.0966, -0.0769, -0.1438, -0.0776,\n",
      "        -0.1210, -0.1177, -0.1270, -0.1178, -0.1155, -0.1090, -0.1184, -0.1488,\n",
      "        -0.1424, -0.0975, -0.0678, -0.1356, -0.1021, -0.1179, -0.1071, -0.1470,\n",
      "        -0.1285, -0.1149, -0.0807, -0.1208, -0.0992, -0.1039, -0.1249, -0.0950,\n",
      "        -0.1189, -0.0579, -0.1025, -0.1488, -0.1210, -0.0942, -0.0798, -0.0947,\n",
      "        -0.1312, -0.1131, -0.0887, -0.0890, -0.0619,  0.0141, -0.0201, -0.0786,\n",
      "        -0.1392, -0.0867, -0.1379, -0.1106, -0.1132, -0.0890, -0.1133, -0.1110,\n",
      "        -0.0979, -0.1245, -0.0836, -0.1268, -0.1174, -0.0942, -0.1231, -0.1334,\n",
      "        -0.0708, -0.1008, -0.0884, -0.1162, -0.0841, -0.1144, -0.1205, -0.1133,\n",
      "        -0.1293, -0.1055, -0.0734, -0.1032, -0.1156, -0.0665, -0.1136, -0.1401,\n",
      "        -0.0895, -0.1233, -0.0774,  0.0012, -0.0875, -0.0974, -0.1137, -0.1086,\n",
      "        -0.0926, -0.1050, -0.1462, -0.1100, -0.1190,  0.0450, -0.1463, -0.0676,\n",
      "        -0.1012, -0.0949, -0.1417, -0.1224, -0.0932, -0.0925, -0.1071, -0.1114,\n",
      "        -0.1329, -0.1057, -0.0761, -0.1412, -0.1254, -0.1083, -0.1344, -0.0871,\n",
      "        -0.0864, -0.1129, -0.0814, -0.1215, -0.1008, -0.1501, -0.0876, -0.0971,\n",
      "        -0.0361, -0.0853, -0.0717, -0.1326, -0.1236, -0.1319, -0.0771, -0.1394,\n",
      "        -0.1278, -0.0885, -0.1073, -0.1579, -0.1068,  0.0157, -0.0856, -0.1402,\n",
      "        -0.0327, -0.1131, -0.1341, -0.1428, -0.0992, -0.0450, -0.1453, -0.1433,\n",
      "        -0.1162, -0.0942, -0.1358, -0.0856, -0.1090, -0.1065, -0.1439, -0.1372,\n",
      "        -0.1188, -0.0964, -0.1071, -0.0891, -0.0906, -0.0879, -0.0937, -0.1426,\n",
      "        -0.1137, -0.0764, -0.1069, -0.0620, -0.1011, -0.1017, -0.0792, -0.1327,\n",
      "        -0.0836, -0.1489, -0.0894, -0.0864, -0.0585, -0.0949, -0.1480, -0.1300,\n",
      "        -0.1090, -0.1281, -0.1060, -0.1507, -0.1174, -0.0869, -0.0954, -0.1108,\n",
      "        -0.1486, -0.1383, -0.1042, -0.1046, -0.0861, -0.0989, -0.1255, -0.1017,\n",
      "        -0.0866, -0.0632, -0.0092, -0.0829, -0.1207, -0.0912, -0.0894, -0.1201,\n",
      "        -0.1402, -0.1105, -0.1028, -0.1311, -0.0546, -0.0981, -0.0478, -0.1074,\n",
      "        -0.0918, -0.0831, -0.0971, -0.1468, -0.0979, -0.0844, -0.1129, -0.1352,\n",
      "        -0.0974, -0.1311, -0.1175, -0.1225, -0.1045, -0.1057, -0.1013, -0.1268,\n",
      "        -0.1336, -0.0977, -0.1232, -0.1297, -0.0953, -0.0946, -0.0802, -0.0755,\n",
      "        -0.1042, -0.1137, -0.1003, -0.1380,  0.0393, -0.1038, -0.1331, -0.0924,\n",
      "        -0.1320, -0.1293, -0.1497, -0.0821, -0.1374, -0.1408, -0.0967, -0.1069,\n",
      "        -0.0483,  0.0015, -0.0489, -0.1095, -0.1375, -0.0362, -0.1365, -0.1394,\n",
      "        -0.1289, -0.0961, -0.0911, -0.1258, -0.1421, -0.1260, -0.0628, -0.1052,\n",
      "        -0.0739, -0.1175, -0.1364, -0.0287, -0.1005, -0.1002, -0.0938, -0.0316,\n",
      "        -0.1420, -0.1060, -0.1238, -0.0927, -0.1160, -0.0654, -0.0763,  0.0696,\n",
      "        -0.0951, -0.0785, -0.0467, -0.1124, -0.0872,  0.0126, -0.0972, -0.1381,\n",
      "        -0.1073, -0.1237, -0.1435, -0.0547, -0.1075, -0.1162, -0.1375, -0.1426,\n",
      "        -0.1075, -0.1490, -0.1232, -0.1377, -0.1243, -0.0937, -0.0937, -0.0865,\n",
      "        -0.0826, -0.1132, -0.1024, -0.0783, -0.0115, -0.0901, -0.0617, -0.1110,\n",
      "        -0.0940, -0.0796, -0.1423, -0.0966, -0.1274, -0.1026,  0.0441, -0.0922,\n",
      "        -0.1141, -0.0217, -0.1066, -0.0871,  0.0140, -0.1404, -0.0983, -0.1054,\n",
      "        -0.0512, -0.0599, -0.1096, -0.0885, -0.1283, -0.1031, -0.1246, -0.1248,\n",
      "        -0.1013, -0.1165, -0.1046, -0.0862, -0.0801, -0.0795, -0.0836, -0.1154,\n",
      "        -0.1050, -0.1021, -0.0732, -0.1189, -0.0947, -0.1061, -0.1355, -0.1109])\n",
      "classifier.3.weight torch.Size([4, 512])\n",
      "tensor([[-0.0390, -0.0180, -0.0041,  ..., -0.0037,  0.0099,  0.0460],\n",
      "        [ 0.0344, -0.0040, -0.0207,  ..., -0.0316,  0.0018,  0.0096],\n",
      "        [-0.0154,  0.0267,  0.0404,  ...,  0.0055,  0.0274,  0.0553],\n",
      "        [-0.0044, -0.0151,  0.0124,  ...,  0.0031,  0.0157,  0.0511]])\n",
      "classifier.3.bias torch.Size([4])\n",
      "tensor([ 0.3475, -0.1841, -0.2394, -0.0884])\n"
     ]
    }
   ],
   "source": [
    "for name, param in client1_model.state_dict().items():\n",
    "    print(name, param.size())\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.weight torch.Size([64, 1, 3, 3])\n",
      "tensor([[[[ 2.0512e-01,  7.2431e-02,  6.2728e-02],\n",
      "          [ 4.3865e-02, -8.3963e-02, -3.0666e-02],\n",
      "          [ 1.2385e-01, -2.1298e-01, -8.8034e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5720e-01,  6.3179e-02,  2.3700e-01],\n",
      "          [-3.9580e-01,  1.0185e-01,  9.4279e-02],\n",
      "          [-3.2643e-02,  5.7972e-02, -4.4562e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3066e-01,  3.5706e-01,  2.2272e-01],\n",
      "          [ 7.7470e-01,  7.0127e-01, -7.3897e-02],\n",
      "          [ 9.9122e-02,  5.4484e-01,  2.7862e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7211e-02,  4.1028e-01,  1.7376e-01],\n",
      "          [-3.0796e-01,  3.0852e-01,  5.9514e-01],\n",
      "          [-4.6496e-01, -2.5293e-01, -2.0051e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7365e-02,  1.5878e-02,  4.0099e-01],\n",
      "          [-3.4755e-02, -3.7033e-01, -5.0605e-02],\n",
      "          [-4.3512e-01,  9.8792e-02,  1.2856e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6495e-01,  2.4388e-01, -1.3144e-01],\n",
      "          [ 3.3662e-02,  1.6983e-01,  1.7115e-01],\n",
      "          [-1.0561e-01,  3.6429e-01,  9.3323e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8630e-01, -4.4181e-02,  2.1686e-01],\n",
      "          [-6.1187e-01,  2.5993e-01, -7.6597e-02],\n",
      "          [-3.6404e-01,  1.8568e-01,  2.0569e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9607e-02,  3.4190e-01,  1.9420e-01],\n",
      "          [ 5.5854e-02, -3.4596e-02,  1.4051e-01],\n",
      "          [ 8.4503e-02, -4.1086e-01, -2.7588e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2798e-02,  2.1234e-01, -3.7859e-01],\n",
      "          [ 3.2895e-01, -1.1550e-01, -2.1611e-01],\n",
      "          [ 2.3493e-01, -2.0708e-01, -3.1944e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6597e-02,  2.3841e-01, -4.1665e-01],\n",
      "          [ 3.9176e-03,  6.6911e-02, -5.3988e-01],\n",
      "          [ 2.5818e-02,  2.7799e-01, -1.5922e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0458e-02, -1.0947e-01, -3.2630e-01],\n",
      "          [-1.6748e-01,  3.8013e-01,  1.8486e-01],\n",
      "          [ 1.7209e-01,  1.3380e-01, -3.2427e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4335e-02,  3.8322e-02, -5.1226e-02],\n",
      "          [ 2.5174e-01,  3.6941e-01, -1.2139e-01],\n",
      "          [ 1.7023e-01, -3.7542e-01,  1.0880e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.0179e-02, -1.2992e-01,  5.9222e-02],\n",
      "          [ 3.2558e-01, -2.2712e-01, -1.4350e-01],\n",
      "          [ 2.0058e-01, -2.0261e-01, -1.7110e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0354e-02, -1.3451e-01,  2.0044e-01],\n",
      "          [-4.0916e-02, -1.9846e-01,  3.3182e-01],\n",
      "          [-1.4720e-01,  8.4015e-02, -7.1542e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0883e-01, -1.9476e-01,  1.1036e-01],\n",
      "          [-5.4182e-01, -4.1254e-01,  1.4152e-01],\n",
      "          [-2.6409e-02, -1.4999e-01,  6.5530e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2115e-01,  2.3203e-01,  1.1225e-01],\n",
      "          [-2.2830e-01, -2.3248e-01,  3.3800e-01],\n",
      "          [-1.9270e-02, -8.4032e-03, -1.3443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1289e-01, -1.0952e-01, -2.2484e-01],\n",
      "          [ 3.3210e-01,  4.1664e-01,  3.8110e-01],\n",
      "          [-1.7604e-01, -8.3023e-02,  9.3360e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5751e-01, -2.9908e-02,  1.1989e-02],\n",
      "          [-8.0549e-02,  4.3304e-01, -2.7009e-01],\n",
      "          [ 1.7803e-01,  1.1019e-01, -1.0367e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4798e-01, -1.5791e-01,  2.7664e-02],\n",
      "          [-3.6898e-01, -4.6454e-01, -4.8063e-01],\n",
      "          [-6.4756e-02,  1.6250e-01,  4.7222e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0951e-01, -5.7674e-01, -4.0509e-01],\n",
      "          [-5.7269e-01, -8.0917e-01, -6.8364e-01],\n",
      "          [-3.6965e-01, -4.3457e-01,  2.6070e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2244e-01, -1.2398e-01,  2.4610e-01],\n",
      "          [ 1.1603e-01, -2.6904e-01,  1.4713e-01],\n",
      "          [-2.5993e-01, -1.8791e-01,  1.2413e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1559e-02, -2.8030e-01,  4.0576e-02],\n",
      "          [ 1.2134e-01, -4.1734e-01, -3.7635e-02],\n",
      "          [-2.9416e-01, -6.0942e-01, -2.3849e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8314e-01,  1.5619e-01,  1.7100e-01],\n",
      "          [-7.7810e-02,  7.3641e-02, -5.3417e-01],\n",
      "          [ 1.5324e-01, -2.4239e-03, -1.5393e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0982e-01, -1.5390e-01, -1.4070e-01],\n",
      "          [ 3.0012e-01, -1.0918e-01, -5.4631e-01],\n",
      "          [ 9.6589e-02,  7.8534e-04, -1.2856e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4346e-01,  8.7733e-02, -1.5375e-01],\n",
      "          [-2.1591e-01,  9.3726e-03,  2.1909e-01],\n",
      "          [-1.4148e-01,  4.9920e-02, -2.8015e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4257e-01, -2.3874e-01,  2.2603e-01],\n",
      "          [-2.7629e-01, -3.0642e-01, -5.2870e-01],\n",
      "          [ 2.3676e-01,  1.2519e-01, -1.2426e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0007e-01, -1.3663e-01, -1.8060e-01],\n",
      "          [ 2.8600e-01,  1.1977e-01, -4.1542e-01],\n",
      "          [-8.6933e-02,  1.4778e-01,  5.0464e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9234e-01,  2.6354e-01,  1.7473e-01],\n",
      "          [-5.5337e-01, -5.9278e-02, -8.2698e-02],\n",
      "          [ 6.8563e-02, -1.2027e-01,  3.5994e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8951e-02, -7.1172e-02,  8.2499e-02],\n",
      "          [ 3.4558e-02, -5.6816e-01, -4.0331e-02],\n",
      "          [-2.6756e-02, -2.0193e-01,  1.1696e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7456e-01,  6.6141e-01,  5.1446e-01],\n",
      "          [ 2.6180e-01, -4.1012e-01, -5.6517e-02],\n",
      "          [-1.6789e-01, -1.9364e-01, -1.0959e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3292e-01,  1.9230e-02, -9.7219e-02],\n",
      "          [-3.1219e-01, -1.7270e-01, -5.1328e-01],\n",
      "          [-1.9873e-02,  1.1051e-01, -1.8751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6599e-01, -4.9488e-01,  1.7570e-01],\n",
      "          [-6.6951e-01, -7.0127e-01, -1.0405e-01],\n",
      "          [-5.4883e-01, -6.1011e-01, -2.6280e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3084e-02, -8.5187e-02,  6.3028e-02],\n",
      "          [-2.5011e-01,  2.6007e-01,  7.3771e-03],\n",
      "          [ 3.5648e-02, -6.1673e-02, -4.7666e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2246e-01, -2.4640e-01,  4.3214e-02],\n",
      "          [ 3.2913e-01,  4.4396e-01,  6.8471e-02],\n",
      "          [ 2.3414e-01,  6.0770e-02, -1.9080e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5231e-01, -1.2926e-02,  3.4034e-02],\n",
      "          [-7.8257e-02,  2.6468e-01,  3.8926e-02],\n",
      "          [-3.1285e-01, -3.6947e-02,  2.4750e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5082e-02, -1.4985e-01, -3.1165e-01],\n",
      "          [ 2.5597e-01, -1.7375e-01,  3.3636e-01],\n",
      "          [-2.1567e-01,  1.7923e-01,  3.3193e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8563e-01,  8.7874e-01,  7.1943e-01],\n",
      "          [-1.2607e-01,  4.5160e-01,  4.6832e-01],\n",
      "          [-2.7252e-01,  2.5398e-01,  3.0853e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3231e-02, -2.1274e-01,  1.6220e-01],\n",
      "          [-5.4551e-02, -3.0914e-01,  1.0177e-01],\n",
      "          [ 3.2015e-04, -2.4697e-01,  2.1074e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3133e-01, -3.8524e-01, -4.0383e-01],\n",
      "          [ 1.1695e-01, -4.8313e-01,  2.4966e-01],\n",
      "          [ 3.2252e-01,  8.6259e-02,  9.2355e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0017e-01, -2.0094e-01,  9.1035e-02],\n",
      "          [ 1.4961e-01, -4.1750e-01,  1.7862e-01],\n",
      "          [ 1.0840e-01,  3.0545e-01,  4.5513e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8315e-02, -1.6623e-02, -5.3598e-01],\n",
      "          [ 2.9536e-01,  1.9930e-01, -2.3660e-01],\n",
      "          [ 2.0357e-01,  1.1880e-01,  1.1669e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6160e-01, -3.0476e-01,  2.0839e-02],\n",
      "          [ 2.0370e-01,  4.0161e-02, -2.9739e-01],\n",
      "          [ 5.0399e-02, -2.8033e-01,  1.0344e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9750e-02,  2.9781e-01,  1.2287e-02],\n",
      "          [-6.6046e-01,  5.7854e-02, -9.6577e-02],\n",
      "          [-3.2581e-01,  3.9436e-03,  3.4411e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2032e-02,  2.8175e-02, -1.8958e-02],\n",
      "          [-1.8752e-01,  3.5191e-01, -1.1005e-01],\n",
      "          [-1.3020e-02,  1.4461e-01, -1.3927e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8279e-01, -1.2143e-01,  5.1426e-02],\n",
      "          [-5.1624e-01, -5.2494e-01,  2.2898e-01],\n",
      "          [ 2.3102e-01, -9.8672e-03,  1.2908e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8794e-01,  3.7940e-01,  6.5280e-01],\n",
      "          [ 3.1780e-01, -1.5062e-01, -1.3964e-01],\n",
      "          [ 9.3486e-02,  1.8861e-01,  2.5274e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7282e-02, -3.7106e-02,  5.0239e-02],\n",
      "          [-2.2192e-01,  1.1019e-01,  7.6275e-02],\n",
      "          [-3.7255e-01,  1.4453e-01, -5.2314e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9948e-01, -8.6322e-02, -2.9702e-01],\n",
      "          [-3.6073e-01,  3.2152e-02,  3.1401e-01],\n",
      "          [ 1.0966e-01, -1.0459e-02,  1.8944e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3582e-01, -2.1879e-01,  1.0742e-01],\n",
      "          [-4.9595e-01, -3.9526e-01, -7.8265e-02],\n",
      "          [-9.8344e-02, -2.3346e-01,  2.4187e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0138e-01, -8.8316e-02,  5.8336e-02],\n",
      "          [-2.7246e-01, -2.9311e-01,  2.8239e-01],\n",
      "          [ 1.9717e-03, -1.1606e-01, -1.7958e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0153e-01,  2.7303e-03, -1.2000e-01],\n",
      "          [-2.0496e-01, -5.9141e-01, -3.1631e-01],\n",
      "          [ 8.2242e-02, -1.2086e-01, -7.5543e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2985e-01,  1.9772e-01,  3.5545e-01],\n",
      "          [-6.3352e-01, -1.8363e-01, -3.0193e-01],\n",
      "          [ 7.8351e-02, -1.5945e-01,  1.9370e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8562e-02, -3.6853e-01,  5.8694e-02],\n",
      "          [ 4.8355e-01,  3.4987e-01,  4.4453e-01],\n",
      "          [-1.7106e-03, -3.6552e-01,  9.5171e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0259e-01, -2.1834e-01, -1.1317e-01],\n",
      "          [ 2.0404e-01, -2.8500e-01,  6.0946e-02],\n",
      "          [ 1.6112e-01,  1.5568e-01, -1.4599e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0356e-01, -2.7005e-01,  2.5561e-01],\n",
      "          [-4.2596e-01,  3.0941e-01,  2.2501e-01],\n",
      "          [-2.7744e-01, -1.3164e-01,  2.1034e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0690e-01,  1.0329e-01, -2.8483e-01],\n",
      "          [-8.4821e-02,  1.0237e-01, -2.5630e-01],\n",
      "          [ 2.0743e-01,  1.8704e-01, -3.6797e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6236e-01, -6.6729e-02, -2.5336e-01],\n",
      "          [ 2.3890e-01, -1.5719e-01,  3.8809e-02],\n",
      "          [-2.2965e-01,  4.7923e-02,  1.9919e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0321e-01, -2.9619e-01,  4.8075e-02],\n",
      "          [ 5.5561e-02,  3.0437e-01, -3.7854e-02],\n",
      "          [-3.2685e-01, -4.7091e-02,  3.8990e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9751e-02, -3.4649e-02, -2.3609e-01],\n",
      "          [ 3.9784e-01,  4.3019e-01,  6.0739e-03],\n",
      "          [ 2.9462e-01, -1.0934e-01, -9.0605e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0033e-01,  2.0967e-02, -1.8067e-01],\n",
      "          [-3.0198e-01, -1.3686e-01,  3.2976e-01],\n",
      "          [-1.5874e-01, -1.7779e-01,  1.2274e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6822e-01,  1.0304e-01, -3.7904e-02],\n",
      "          [-2.7405e-01,  2.4792e-01,  8.9926e-02],\n",
      "          [-2.7372e-01,  2.8380e-02, -7.9592e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.5310e-02,  1.2474e-01, -1.3104e-02],\n",
      "          [-1.7063e-01,  2.5694e-01,  2.9062e-03],\n",
      "          [-6.4669e-02,  9.9005e-02,  9.3317e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5149e-02, -6.4729e-02, -2.0714e-01],\n",
      "          [ 7.2465e-02,  3.3585e-01,  6.0231e-01],\n",
      "          [-2.3748e-01, -1.0283e-01,  5.7275e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5752e-01,  2.7080e-01, -1.2921e-01],\n",
      "          [-4.5815e-01,  1.1190e-01,  2.3639e-03],\n",
      "          [-3.2153e-01,  1.5415e-01,  4.4100e-02]]]])\n",
      "cnn.bias torch.Size([64])\n",
      "tensor([-0.2349,  0.2491, -0.1681,  0.3627,  0.1046, -0.0632, -0.2694, -0.1596,\n",
      "         0.1694,  0.2237,  0.2918, -0.2621, -0.2930, -0.0591, -0.1676, -0.2492,\n",
      "         0.2570, -0.0773,  0.0644,  0.2140, -0.1997,  0.1447,  0.1134,  0.1485,\n",
      "         0.3318, -0.1719, -0.0824,  0.2153, -0.1529,  0.3396, -0.1009, -0.2149,\n",
      "         0.2552, -0.1794, -0.0218,  0.0545, -0.1404,  0.0708, -0.2485,  0.0345,\n",
      "        -0.0409,  0.2784,  0.0193,  0.2424, -0.1290, -0.1767,  0.0871, -0.1508,\n",
      "         0.0900, -0.3183, -0.0587, -0.1073,  0.1104, -0.0763, -0.1154, -0.3622,\n",
      "         0.2006,  0.0687, -0.0460, -0.3268,  0.2923, -0.2638, -0.0292,  0.2495])\n",
      "rescnn_layers.0.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-0.2141, -0.1756, -0.1142],\n",
      "          [ 0.0282,  0.1589,  0.1762],\n",
      "          [ 0.0306,  0.0628,  0.0718]],\n",
      "\n",
      "         [[ 0.0746,  0.0256, -0.1330],\n",
      "          [ 0.0938,  0.0757, -0.0381],\n",
      "          [ 0.0210, -0.0993, -0.2604]],\n",
      "\n",
      "         [[-0.1319, -0.0546, -0.0459],\n",
      "          [-0.0269, -0.0234, -0.0774],\n",
      "          [-0.0995, -0.0477, -0.1239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0007, -0.0620,  0.0255],\n",
      "          [ 0.0312, -0.0057,  0.0707],\n",
      "          [ 0.0369,  0.0177, -0.0453]],\n",
      "\n",
      "         [[-0.0956, -0.0813, -0.0799],\n",
      "          [-0.0201,  0.0400,  0.0373],\n",
      "          [ 0.0118,  0.0683,  0.0446]],\n",
      "\n",
      "         [[ 0.1022,  0.0467, -0.1982],\n",
      "          [ 0.0607, -0.0195, -0.1846],\n",
      "          [ 0.0695,  0.0022, -0.1422]]],\n",
      "\n",
      "\n",
      "        [[[-0.0248, -0.0804, -0.0272],\n",
      "          [ 0.0953,  0.1514,  0.0686],\n",
      "          [ 0.1141,  0.1426,  0.0496]],\n",
      "\n",
      "         [[ 0.0223, -0.1296, -0.1380],\n",
      "          [-0.0332, -0.2041, -0.2246],\n",
      "          [-0.0215, -0.2423, -0.2103]],\n",
      "\n",
      "         [[ 0.0304, -0.0479, -0.0676],\n",
      "          [ 0.1268,  0.0464, -0.0746],\n",
      "          [ 0.0393, -0.0598, -0.0679]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0465, -0.0447, -0.0152],\n",
      "          [ 0.0444, -0.0650,  0.0222],\n",
      "          [-0.0320, -0.0779, -0.0680]],\n",
      "\n",
      "         [[-0.1108, -0.1119, -0.0870],\n",
      "          [ 0.1021,  0.0347, -0.0102],\n",
      "          [ 0.0318,  0.0434,  0.0600]],\n",
      "\n",
      "         [[ 0.0340, -0.1761, -0.0515],\n",
      "          [ 0.0310, -0.1968, -0.1161],\n",
      "          [ 0.0476, -0.1903, -0.1314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0199,  0.1120,  0.0489],\n",
      "          [ 0.0873, -0.0266,  0.0655],\n",
      "          [-0.0303, -0.0029,  0.0663]],\n",
      "\n",
      "         [[ 0.0348, -0.1030, -0.0022],\n",
      "          [-0.0394,  0.0260,  0.0253],\n",
      "          [-0.0029,  0.0404,  0.0299]],\n",
      "\n",
      "         [[-0.0494, -0.0958, -0.1547],\n",
      "          [-0.1175, -0.1922, -0.0928],\n",
      "          [-0.1993, -0.1757, -0.1106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0724, -0.0070, -0.0038],\n",
      "          [-0.0117, -0.0889,  0.0723],\n",
      "          [-0.0594, -0.0207, -0.0320]],\n",
      "\n",
      "         [[-0.0463, -0.0083, -0.0379],\n",
      "          [-0.0490, -0.1570, -0.0031],\n",
      "          [-0.1785, -0.2494, -0.0830]],\n",
      "\n",
      "         [[-0.0038, -0.0518, -0.0905],\n",
      "          [ 0.0423, -0.0429, -0.0382],\n",
      "          [ 0.0043,  0.0758, -0.0340]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0220,  0.0042],\n",
      "          [ 0.0686, -0.0052,  0.0605],\n",
      "          [-0.0145,  0.0117, -0.0014]],\n",
      "\n",
      "         [[-0.0548,  0.0105,  0.0935],\n",
      "          [-0.1295, -0.0325,  0.0912],\n",
      "          [-0.0351, -0.1065, -0.0701]],\n",
      "\n",
      "         [[-0.0476, -0.1570, -0.1241],\n",
      "          [-0.1238, -0.0841, -0.1288],\n",
      "          [-0.0670, -0.0265, -0.1562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714, -0.0952, -0.0513],\n",
      "          [ 0.0785, -0.0345, -0.0693],\n",
      "          [ 0.1114, -0.0270, -0.0569]],\n",
      "\n",
      "         [[-0.0082, -0.1878, -0.1386],\n",
      "          [-0.0520, -0.2119, -0.2024],\n",
      "          [ 0.0829,  0.0083, -0.1015]],\n",
      "\n",
      "         [[-0.0704,  0.0114, -0.0353],\n",
      "          [-0.0185,  0.0364, -0.0150],\n",
      "          [ 0.0612, -0.0374, -0.0578]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1209, -0.1422, -0.0708],\n",
      "          [ 0.1189, -0.1747, -0.1772],\n",
      "          [ 0.1158, -0.1927, -0.2298]],\n",
      "\n",
      "         [[-0.0123,  0.1583,  0.0898],\n",
      "          [ 0.0236,  0.1609,  0.0831],\n",
      "          [ 0.0434,  0.0150,  0.0366]],\n",
      "\n",
      "         [[-0.0254, -0.0828, -0.0648],\n",
      "          [-0.0409, -0.0543, -0.1736],\n",
      "          [ 0.0460, -0.0817, -0.1931]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0644, -0.0097,  0.0472],\n",
      "          [-0.0596,  0.0486,  0.1453],\n",
      "          [-0.0445, -0.0846,  0.0922]],\n",
      "\n",
      "         [[-0.0110,  0.0599,  0.0833],\n",
      "          [-0.0710,  0.0892,  0.0537],\n",
      "          [-0.0884, -0.0433, -0.0138]],\n",
      "\n",
      "         [[-0.0465,  0.1468,  0.0851],\n",
      "          [-0.0781,  0.1972,  0.0817],\n",
      "          [-0.0452,  0.0608, -0.0015]]],\n",
      "\n",
      "\n",
      "        [[[-0.0774, -0.0303,  0.0644],\n",
      "          [ 0.1069,  0.1132,  0.1358],\n",
      "          [ 0.1527,  0.0649,  0.0943]],\n",
      "\n",
      "         [[-0.0747, -0.0250,  0.0066],\n",
      "          [-0.1648, -0.1073, -0.0730],\n",
      "          [-0.2818, -0.2129, -0.0313]],\n",
      "\n",
      "         [[-0.0825, -0.0718, -0.0511],\n",
      "          [ 0.0424, -0.0039,  0.0036],\n",
      "          [-0.0182, -0.0847, -0.1591]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473,  0.0559,  0.0348],\n",
      "          [ 0.1272, -0.0742, -0.0216],\n",
      "          [-0.0214, -0.0555, -0.1111]],\n",
      "\n",
      "         [[-0.1752, -0.1544, -0.0503],\n",
      "          [ 0.0926,  0.0490,  0.0460],\n",
      "          [-0.0950, -0.0420,  0.0202]],\n",
      "\n",
      "         [[-0.0196, -0.0176, -0.0317],\n",
      "          [-0.0421, -0.1692, -0.1179],\n",
      "          [ 0.0042, -0.0410, -0.0674]]]])\n",
      "rescnn_layers.0.cnn1.bias torch.Size([64])\n",
      "tensor([ 0.0669, -0.0927, -0.0270, -0.0124, -0.0323, -0.0278,  0.0577, -0.0231,\n",
      "        -0.0204, -0.0288, -0.0508, -0.0267, -0.0275, -0.0318,  0.0601,  0.0318,\n",
      "         0.0162, -0.0066, -0.0066,  0.0187, -0.0005, -0.0156, -0.0048, -0.0095,\n",
      "         0.0024,  0.0156, -0.0075, -0.0051, -0.0179,  0.0583, -0.0056,  0.0012,\n",
      "         0.0384, -0.0108,  0.0002,  0.0188,  0.0001,  0.0561, -0.0024, -0.0454,\n",
      "         0.0370,  0.0117, -0.0130,  0.0120,  0.0052, -0.0225, -0.0095,  0.0089,\n",
      "         0.0137,  0.0699,  0.0442, -0.0633,  0.0439, -0.0030,  0.0067, -0.0064,\n",
      "        -0.0251,  0.0049,  0.0274, -0.0859, -0.0346,  0.0270, -0.0181, -0.0359])\n",
      "rescnn_layers.0.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 2.0591e-02, -2.1748e-02,  3.7966e-02],\n",
      "          [-5.9231e-02, -1.8977e-02,  2.5983e-02],\n",
      "          [ 8.7965e-02,  1.0769e-01,  5.7031e-03]],\n",
      "\n",
      "         [[ 5.0613e-02, -6.4764e-02, -1.1730e-01],\n",
      "          [-5.0278e-02, -5.8590e-02, -3.1438e-02],\n",
      "          [-1.8603e-02, -2.3823e-02,  2.6413e-02]],\n",
      "\n",
      "         [[ 1.3256e-01, -8.1401e-02, -1.0101e-01],\n",
      "          [ 1.0599e-01, -2.2371e-01, -2.3418e-01],\n",
      "          [ 1.9345e-02, -1.6353e-01, -1.1984e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8692e-02, -3.8127e-02, -6.9202e-02],\n",
      "          [-1.2012e-01, -2.3457e-01, -7.9784e-02],\n",
      "          [-6.2534e-02, -1.2175e-01, -7.0889e-02]],\n",
      "\n",
      "         [[-1.6577e-02, -3.9641e-02, -2.5732e-01],\n",
      "          [ 1.1476e-03, -3.3640e-02, -3.3945e-01],\n",
      "          [-1.1865e-01,  4.1971e-02, -9.0256e-02]],\n",
      "\n",
      "         [[ 1.4091e-01,  2.4099e-02, -1.5460e-01],\n",
      "          [ 3.5980e-02, -4.5559e-02, -1.6222e-01],\n",
      "          [ 2.5200e-02,  7.6011e-02, -9.0197e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.8515e-02,  5.6571e-03,  1.3316e-01],\n",
      "          [-7.0760e-02,  7.5247e-02,  1.4336e-01],\n",
      "          [-2.2727e-02,  7.3092e-02,  9.0630e-02]],\n",
      "\n",
      "         [[-2.0384e-01, -1.4442e-01,  2.9520e-02],\n",
      "          [-2.2181e-01, -7.5015e-02,  6.4788e-02],\n",
      "          [-1.5561e-01, -1.7615e-01, -8.5763e-02]],\n",
      "\n",
      "         [[ 7.1063e-02,  7.9881e-02,  1.1333e-01],\n",
      "          [ 3.3217e-02,  4.3258e-02,  1.0991e-01],\n",
      "          [ 2.2705e-01,  1.3099e-01,  8.6758e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8239e-02, -1.8788e-02,  5.8520e-02],\n",
      "          [-1.1010e-01, -4.8425e-02,  2.3053e-02],\n",
      "          [-4.6453e-02,  1.5062e-02,  1.6684e-02]],\n",
      "\n",
      "         [[-9.5920e-03, -5.4497e-02, -7.2305e-02],\n",
      "          [ 2.8950e-02,  4.8062e-03, -1.2225e-01],\n",
      "          [ 7.2671e-03,  2.0027e-02, -5.5114e-02]],\n",
      "\n",
      "         [[-3.0637e-02,  1.7890e-02, -3.9030e-03],\n",
      "          [-5.4509e-02,  5.2172e-03, -5.2575e-02],\n",
      "          [-5.6292e-02, -8.0013e-02, -3.7431e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0648e-01,  3.3196e-02,  1.4051e-02],\n",
      "          [-1.8525e-02, -3.5780e-02,  3.1624e-02],\n",
      "          [ 8.0272e-02,  3.9693e-02,  4.8181e-03]],\n",
      "\n",
      "         [[-8.5615e-02, -3.9849e-02,  1.3043e-02],\n",
      "          [-2.7301e-02,  3.9639e-02,  6.3512e-02],\n",
      "          [-4.2120e-02,  5.1158e-05,  4.2097e-03]],\n",
      "\n",
      "         [[-6.0739e-02, -2.6401e-02, -7.1098e-03],\n",
      "          [ 1.0761e-02,  3.4883e-04,  5.0152e-02],\n",
      "          [ 5.6737e-02,  5.6301e-02,  5.8723e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.8519e-02,  2.4529e-02, -3.0382e-02],\n",
      "          [-3.7220e-02, -2.6107e-02, -5.2471e-02],\n",
      "          [ 4.4875e-02,  9.0887e-02, -1.8350e-02]],\n",
      "\n",
      "         [[ 5.5160e-02, -3.7254e-02, -2.8530e-02],\n",
      "          [ 4.8615e-02, -6.3174e-02, -3.4986e-02],\n",
      "          [ 9.6492e-03, -2.9328e-02, -6.3148e-03]],\n",
      "\n",
      "         [[-5.8440e-02, -5.1718e-02, -2.6184e-02],\n",
      "          [ 4.9901e-02,  1.0399e-01, -4.0422e-02],\n",
      "          [-1.4105e-02, -2.3061e-02, -4.4279e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7896e-01,  2.2283e-01,  1.4676e-01],\n",
      "          [ 5.9900e-02,  5.4876e-02, -1.0128e-02],\n",
      "          [ 1.3658e-01,  4.7175e-02,  1.1815e-04]],\n",
      "\n",
      "         [[-7.1391e-02,  3.6582e-02,  9.9459e-02],\n",
      "          [-7.1757e-02, -1.5302e-01, -5.7639e-02],\n",
      "          [ 3.9455e-02, -4.5041e-02,  3.6501e-02]],\n",
      "\n",
      "         [[ 1.3538e-02,  7.2786e-02,  1.1019e-01],\n",
      "          [ 8.0299e-02,  6.5031e-02,  7.5186e-02],\n",
      "          [ 1.6709e-02, -2.4617e-02,  5.4437e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2362e-01,  8.0741e-03, -1.2957e-01],\n",
      "          [-9.2219e-03,  3.7314e-02, -3.3071e-02],\n",
      "          [ 7.1613e-03,  1.5711e-01, -8.2424e-02]],\n",
      "\n",
      "         [[-3.4758e-03, -1.9268e-02, -1.1477e-02],\n",
      "          [ 1.2420e-01,  1.8316e-02,  3.3878e-02],\n",
      "          [ 8.9143e-03,  5.9344e-02, -3.0186e-02]],\n",
      "\n",
      "         [[ 3.3640e-02,  9.2627e-02, -2.7333e-04],\n",
      "          [-1.0281e-01, -5.4005e-02, -1.0365e-01],\n",
      "          [-1.0960e-03,  4.3421e-02, -3.4299e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3587e-02, -9.0958e-03,  1.1513e-01],\n",
      "          [-1.7867e-03, -2.2473e-02,  1.8811e-01],\n",
      "          [-2.7640e-01, -2.3104e-01, -8.0007e-03]],\n",
      "\n",
      "         [[ 1.1552e-02, -1.5364e-02,  4.2286e-02],\n",
      "          [ 3.4598e-02, -9.8240e-02,  1.6853e-02],\n",
      "          [-8.0095e-02, -1.8503e-01, -8.5277e-02]],\n",
      "\n",
      "         [[-5.2786e-02, -5.5924e-02,  8.9357e-02],\n",
      "          [-1.2272e-02,  4.9581e-02,  7.2490e-02],\n",
      "          [-3.9546e-02, -7.3517e-02,  1.7349e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1342e-01,  9.7274e-02,  4.2318e-02],\n",
      "          [ 1.5317e-01,  1.5088e-02,  3.1398e-03],\n",
      "          [ 1.4259e-01, -5.2444e-02,  5.2925e-02]],\n",
      "\n",
      "         [[ 8.4503e-02, -2.9754e-02,  1.0406e-01],\n",
      "          [ 9.1370e-02, -5.6125e-02,  1.0158e-01],\n",
      "          [ 1.1369e-02,  4.5768e-02,  7.6150e-02]],\n",
      "\n",
      "         [[ 8.5458e-02,  3.4266e-02,  6.5898e-02],\n",
      "          [ 1.7230e-01, -2.2570e-02,  1.0218e-01],\n",
      "          [-4.1134e-02, -2.2532e-01, -1.2223e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.6501e-02, -5.8470e-02, -5.6231e-02],\n",
      "          [-1.1279e-01, -3.1136e-02, -9.4677e-02],\n",
      "          [-2.4545e-02,  3.2430e-02,  2.5645e-02]],\n",
      "\n",
      "         [[-2.7848e-02, -1.5353e-03, -2.2714e-02],\n",
      "          [-6.6030e-02, -4.4343e-02, -4.4823e-02],\n",
      "          [-3.0747e-02,  3.8984e-02,  7.1001e-02]],\n",
      "\n",
      "         [[ 1.1874e-01,  7.8366e-02,  1.8981e-01],\n",
      "          [ 1.7230e-03,  4.6714e-02,  7.0276e-02],\n",
      "          [ 5.6799e-02,  8.2765e-02,  6.1717e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3448e-02,  1.8773e-02,  6.1214e-03],\n",
      "          [ 3.0943e-03,  8.5055e-02,  1.1360e-01],\n",
      "          [ 1.2601e-01,  3.8685e-02,  1.3164e-01]],\n",
      "\n",
      "         [[-9.5313e-03,  8.6980e-03,  7.8122e-02],\n",
      "          [-8.7228e-02, -1.0558e-02,  6.7288e-02],\n",
      "          [-7.8520e-03,  7.6027e-02,  1.2103e-01]],\n",
      "\n",
      "         [[ 7.5457e-02,  1.9883e-02,  4.3425e-02],\n",
      "          [ 2.2533e-02, -7.4463e-03,  6.3271e-02],\n",
      "          [ 4.3953e-02,  6.8199e-02,  1.7428e-01]]]])\n",
      "rescnn_layers.0.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0501,  0.0495, -0.0760,  0.0492,  0.0428,  0.0515,  0.0399,  0.0576,\n",
      "         0.0266, -0.1046,  0.1124, -0.1123, -0.0720,  0.0401,  0.0426,  0.0033,\n",
      "         0.0902, -0.0403, -0.0325,  0.0742, -0.0062,  0.0055,  0.0735, -0.0067,\n",
      "         0.0303, -0.0771,  0.0106,  0.0491,  0.0371,  0.1004,  0.0594, -0.0365,\n",
      "        -0.0166,  0.0291,  0.0221, -0.0320, -0.0856,  0.0685,  0.0589,  0.0879,\n",
      "        -0.0766,  0.0183, -0.0404,  0.0905, -0.0421, -0.0430, -0.0971, -0.0768,\n",
      "         0.0763, -0.1259,  0.0641,  0.1261, -0.0205, -0.0027, -0.0106, -0.1141,\n",
      "         0.0459, -0.0475, -0.0081, -0.0695,  0.0350, -0.0870, -0.0040, -0.0021])\n",
      "rescnn_layers.0.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.1641, 1.0815, 0.9759, 0.8925, 0.8272, 0.6712, 0.7322, 0.6275, 0.6731,\n",
      "        0.8524, 0.8983, 0.7246, 0.7887, 0.8932, 1.0591, 0.9162, 1.0240, 0.9814,\n",
      "        0.9971, 1.0348, 1.0230, 1.0546, 1.0258, 1.0440, 1.0254, 1.0227, 1.0449,\n",
      "        1.0403, 1.0577, 1.0449, 1.0083, 1.0228, 1.0344, 1.0241, 0.9840, 0.9936,\n",
      "        0.9943, 1.0218, 1.0264, 1.0907, 1.0612, 1.0514, 1.0174, 1.0617, 1.0062,\n",
      "        0.9954, 1.0105, 1.0116, 1.0114, 0.9902, 0.9876, 1.0254, 1.0027, 1.0198,\n",
      "        0.9798, 0.9721, 0.9726, 0.9829, 0.9866, 1.0017, 1.0287, 1.0345, 1.0183,\n",
      "        1.1058])\n",
      "rescnn_layers.0.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0323, -0.0050, -0.0086, -0.0083,  0.0013, -0.0322,  0.0119, -0.0262,\n",
      "        -0.0085,  0.0062,  0.0172,  0.0124, -0.0095, -0.0035, -0.0151, -0.0135,\n",
      "         0.0096,  0.0130,  0.0058,  0.0259, -0.0108, -0.0060,  0.0019, -0.0043,\n",
      "        -0.0146,  0.0269, -0.0191, -0.0074, -0.0067, -0.0270,  0.0141, -0.0059,\n",
      "         0.0031,  0.0007,  0.0003,  0.0447,  0.0344,  0.0345, -0.0250, -0.0233,\n",
      "        -0.0335,  0.0077, -0.0041, -0.0281,  0.0072,  0.0018,  0.0088,  0.0132,\n",
      "         0.0055,  0.0100,  0.0235, -0.0101, -0.0092, -0.0075, -0.0102, -0.0074,\n",
      "         0.0014,  0.0012,  0.0072, -0.0009,  0.0045, -0.0023, -0.0044, -0.0016])\n",
      "rescnn_layers.0.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0428, 0.8819, 0.9407, 1.0345, 0.7583, 0.8341, 0.7799, 0.8675, 0.9994,\n",
      "        1.0303, 0.9036, 0.8074, 0.8812, 1.0014, 1.0809, 0.9876, 1.0997, 1.0485,\n",
      "        1.0471, 1.0396, 1.0516, 1.0585, 1.0288, 1.0754, 1.0476, 1.0445, 1.0034,\n",
      "        1.0308, 1.0297, 1.0668, 1.0296, 1.0088, 1.0644, 1.0886, 1.0262, 1.0058,\n",
      "        0.9990, 0.9928, 1.0365, 1.0534, 1.0416, 1.0128, 1.0118, 0.9968, 1.0289,\n",
      "        1.0139, 1.0793, 0.9746, 0.9912, 1.0258, 0.9786, 0.9665, 1.0171, 0.9623,\n",
      "        0.9660, 0.9685, 0.9618, 0.9871, 0.9749, 0.9376, 0.9258, 0.9801, 0.9868,\n",
      "        0.9478])\n",
      "rescnn_layers.0.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0608, -0.0294,  0.0134,  0.0422,  0.0436,  0.0177,  0.0216,  0.0061,\n",
      "         0.0080,  0.0472,  0.0311,  0.0124, -0.0009, -0.0064, -0.0048, -0.0012,\n",
      "        -0.0179, -0.0114,  0.0067,  0.0084, -0.0039, -0.0152,  0.0002, -0.0189,\n",
      "         0.0021, -0.0002, -0.0142, -0.0234, -0.0358, -0.0034, -0.0114, -0.0257,\n",
      "        -0.0213, -0.0104, -0.0047, -0.0108, -0.0253, -0.0368, -0.0114, -0.0060,\n",
      "        -0.0075, -0.0068, -0.0039, -0.0125, -0.0155, -0.0236, -0.0078, -0.0029,\n",
      "         0.0022,  0.0056, -0.0182, -0.0056, -0.0046, -0.0104, -0.0100,  0.0009,\n",
      "         0.0037, -0.0050, -0.0147, -0.0154, -0.0120, -0.0055, -0.0096, -0.0283])\n",
      "rescnn_layers.1.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-8.0538e-02,  2.6647e-02,  5.3537e-02],\n",
      "          [-5.2994e-03,  3.1620e-02,  7.2629e-02],\n",
      "          [-6.1395e-02, -6.5121e-02,  1.3210e-02]],\n",
      "\n",
      "         [[ 3.3114e-02,  2.5685e-02,  1.4952e-01],\n",
      "          [-4.1348e-02, -3.4526e-02,  1.1120e-01],\n",
      "          [-1.0491e-01, -1.4237e-01,  2.7734e-02]],\n",
      "\n",
      "         [[-4.0877e-02,  3.1638e-02,  1.6837e-01],\n",
      "          [-1.1858e-01, -1.5809e-01, -3.4373e-02],\n",
      "          [-8.0121e-02, -2.2605e-01, -1.7675e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7711e-02,  3.7470e-02,  6.9572e-02],\n",
      "          [-1.4478e-01, -6.5908e-02,  1.0688e-01],\n",
      "          [-1.2398e-01, -1.3421e-01,  1.1336e-01]],\n",
      "\n",
      "         [[-5.9003e-02,  1.1342e-02,  3.7012e-02],\n",
      "          [-2.0431e-02,  1.7347e-01,  1.8566e-01],\n",
      "          [ 5.3625e-02,  1.2995e-01,  1.0568e-01]],\n",
      "\n",
      "         [[-3.6046e-02, -7.7837e-02, -1.7773e-02],\n",
      "          [ 6.1799e-03, -6.8946e-02, -4.9852e-03],\n",
      "          [ 4.0103e-03, -3.2879e-02, -6.9071e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9688e-02,  5.0495e-02, -4.6995e-03],\n",
      "          [ 1.3345e-01,  2.9556e-02, -4.6081e-02],\n",
      "          [ 1.5498e-02,  1.2658e-02, -3.5098e-02]],\n",
      "\n",
      "         [[-5.5817e-02,  1.0944e-01, -1.0973e-02],\n",
      "          [-1.2217e-01,  1.5349e-01,  9.2264e-03],\n",
      "          [-1.2942e-02,  1.2258e-01,  9.3798e-02]],\n",
      "\n",
      "         [[-4.6964e-02, -6.9858e-02,  4.3950e-02],\n",
      "          [-8.8360e-02, -2.4402e-02,  8.3481e-02],\n",
      "          [-4.4668e-02, -1.1121e-02,  3.1103e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1570e-03,  1.5703e-01,  8.8092e-02],\n",
      "          [-1.2113e-02,  1.6700e-01,  6.8095e-02],\n",
      "          [ 5.3074e-03,  1.0267e-01,  1.1386e-01]],\n",
      "\n",
      "         [[-5.7325e-02, -1.9885e-02,  7.7986e-02],\n",
      "          [ 2.8848e-02,  3.6525e-02,  5.9234e-02],\n",
      "          [ 3.3478e-02, -4.9718e-02,  9.0366e-02]],\n",
      "\n",
      "         [[-1.3478e-01, -5.5395e-02, -2.8064e-02],\n",
      "          [-4.3576e-03,  1.1382e-02, -2.8968e-02],\n",
      "          [ 7.5633e-02,  4.9845e-02, -5.4210e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6497e-02, -4.6780e-02, -8.6895e-02],\n",
      "          [ 3.5318e-02, -7.3964e-02, -8.3110e-02],\n",
      "          [ 6.6393e-03, -1.0018e-01, -1.2043e-01]],\n",
      "\n",
      "         [[ 1.7000e-02, -1.1867e-01,  1.0286e-01],\n",
      "          [ 5.0789e-02, -1.1541e-01,  1.5693e-01],\n",
      "          [-2.1374e-02, -6.1387e-02,  7.1207e-02]],\n",
      "\n",
      "         [[-5.9828e-02, -1.6572e-01, -5.2568e-02],\n",
      "          [-1.6148e-01, -1.2198e-01, -5.6571e-02],\n",
      "          [-2.3512e-01, -1.3638e-01, -5.5567e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.8569e-03,  5.4268e-03,  2.9633e-02],\n",
      "          [-2.0181e-04, -5.0264e-02,  8.9658e-02],\n",
      "          [-4.8286e-02, -3.6913e-02,  1.3970e-02]],\n",
      "\n",
      "         [[-1.3086e-02, -2.8186e-02,  9.5720e-02],\n",
      "          [-1.6263e-03,  1.2812e-02,  9.0124e-02],\n",
      "          [-3.4620e-02, -4.9880e-02, -1.2586e-02]],\n",
      "\n",
      "         [[ 1.1905e-01,  1.2347e-01,  1.6690e-01],\n",
      "          [ 1.1359e-02,  8.0931e-02,  1.4696e-01],\n",
      "          [-5.1932e-03,  4.4725e-02,  1.5148e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.6672e-03,  4.4934e-02, -1.8259e-02],\n",
      "          [ 4.5226e-02,  5.6644e-02, -1.0799e-02],\n",
      "          [ 2.5007e-02,  1.2228e-02, -8.0866e-03]],\n",
      "\n",
      "         [[ 7.8478e-02,  1.1528e-01, -2.8965e-02],\n",
      "          [ 8.0312e-02,  1.3114e-01,  4.1130e-02],\n",
      "          [-8.0483e-03,  2.2043e-02, -8.6044e-03]],\n",
      "\n",
      "         [[ 9.3671e-02,  4.8801e-02,  7.2342e-02],\n",
      "          [ 7.8012e-03, -1.5022e-03, -3.3188e-02],\n",
      "          [ 6.7050e-03, -6.6657e-02, -2.6206e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9887e-02, -9.9662e-02, -1.0167e-03],\n",
      "          [ 3.8706e-02, -2.5286e-02, -6.1222e-02],\n",
      "          [ 5.9074e-02,  4.9687e-02, -1.3500e-02]],\n",
      "\n",
      "         [[ 3.9940e-02,  3.6006e-02,  1.2523e-01],\n",
      "          [-1.2511e-03,  4.8160e-02,  8.8924e-02],\n",
      "          [ 1.8106e-02, -8.9264e-02,  3.8395e-03]],\n",
      "\n",
      "         [[-3.3119e-02, -3.5544e-02, -3.5618e-03],\n",
      "          [ 4.9316e-02,  1.1477e-02, -3.4017e-02],\n",
      "          [ 5.5880e-02, -7.1387e-03,  1.3588e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8976e-02, -1.0427e-01, -1.2535e-01],\n",
      "          [-2.5548e-02, -1.5340e-02, -5.7759e-02],\n",
      "          [-7.3741e-03, -3.4539e-02, -5.1753e-02]],\n",
      "\n",
      "         [[ 2.5903e-02,  2.3933e-02,  8.6535e-02],\n",
      "          [-2.8357e-03, -3.0426e-02,  3.8212e-02],\n",
      "          [-1.1251e-03, -2.2634e-02, -7.7233e-02]],\n",
      "\n",
      "         [[-5.3420e-03, -9.8692e-02, -8.7527e-02],\n",
      "          [-4.1945e-02, -2.3188e-02, -4.3927e-02],\n",
      "          [-1.1411e-01, -6.6143e-02,  2.8453e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1249e-01, -9.6142e-02, -1.8881e-01],\n",
      "          [ 5.4392e-03, -9.5151e-02, -1.5589e-01],\n",
      "          [-4.1534e-02, -9.7590e-02, -2.3136e-01]],\n",
      "\n",
      "         [[ 3.3503e-02, -6.0365e-02, -1.0052e-01],\n",
      "          [-4.6590e-02, -1.1550e-01, -1.4898e-01],\n",
      "          [-8.7010e-02, -1.6289e-01, -1.2979e-01]],\n",
      "\n",
      "         [[-1.1014e-02, -3.5657e-02,  7.0586e-02],\n",
      "          [-3.0164e-02, -7.7695e-03,  2.1052e-02],\n",
      "          [ 4.9621e-04, -1.2116e-02,  1.0227e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7324e-03, -6.6822e-02, -2.9502e-01],\n",
      "          [-5.1806e-02, -7.1479e-03, -2.8953e-01],\n",
      "          [-5.0307e-02, -3.1424e-03, -1.8965e-01]],\n",
      "\n",
      "         [[-1.9356e-01,  1.0798e-01, -2.1315e-02],\n",
      "          [-1.8007e-01,  1.0404e-01,  6.0146e-02],\n",
      "          [-9.9404e-02,  2.9937e-02,  3.0697e-02]],\n",
      "\n",
      "         [[ 4.9504e-02, -5.6703e-02, -1.2045e-01],\n",
      "          [ 4.4023e-02,  2.9224e-02,  4.0629e-02],\n",
      "          [-3.3622e-02, -6.8949e-02, -3.5420e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3943e-02,  3.7043e-02, -3.1373e-03],\n",
      "          [-1.0891e-01, -1.4630e-01, -1.5142e-01],\n",
      "          [-5.8348e-02, -9.5940e-02, -4.7022e-02]],\n",
      "\n",
      "         [[ 5.6965e-02, -6.0914e-02, -7.7286e-02],\n",
      "          [ 6.5740e-02,  2.3571e-02, -2.4570e-03],\n",
      "          [ 1.2640e-01, -2.5366e-02,  1.5494e-02]],\n",
      "\n",
      "         [[-1.8226e-01, -2.6878e-02, -4.9289e-03],\n",
      "          [-1.3393e-01,  4.3014e-02,  4.1319e-02],\n",
      "          [-4.7549e-02,  1.5949e-02,  4.3875e-02]]]])\n",
      "rescnn_layers.1.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0327, -0.0333,  0.0154,  0.0232, -0.0311,  0.0218, -0.0103,  0.0263,\n",
      "         0.0139, -0.0177,  0.0112,  0.0367, -0.0361,  0.0427, -0.0308, -0.0317,\n",
      "         0.0128,  0.0249,  0.0385,  0.0319,  0.0040, -0.0038, -0.0291,  0.0020,\n",
      "         0.0263, -0.0381,  0.0371, -0.0227,  0.0259,  0.0039, -0.0250,  0.0046,\n",
      "        -0.0043,  0.0316, -0.0293, -0.0146,  0.0284, -0.0416,  0.0105,  0.0248,\n",
      "         0.0342,  0.0376, -0.0176, -0.0100, -0.0356, -0.0188, -0.0054,  0.0189,\n",
      "         0.0003,  0.0179,  0.0254,  0.0149,  0.0061, -0.0414, -0.0139, -0.0089,\n",
      "         0.0095, -0.0385,  0.0409, -0.0033, -0.0389, -0.0263, -0.0129,  0.0116])\n",
      "rescnn_layers.1.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 0.0185, -0.0009, -0.0792],\n",
      "          [-0.0282, -0.0212, -0.2501],\n",
      "          [ 0.0604,  0.0983, -0.1514]],\n",
      "\n",
      "         [[-0.0517,  0.0367, -0.0035],\n",
      "          [-0.1060,  0.0248, -0.0032],\n",
      "          [-0.0723,  0.0112,  0.0406]],\n",
      "\n",
      "         [[ 0.0575, -0.0405,  0.0177],\n",
      "          [ 0.0423, -0.1490, -0.1031],\n",
      "          [-0.0340, -0.1650, -0.1500]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0481,  0.0550,  0.0311],\n",
      "          [ 0.0562,  0.1053,  0.1252],\n",
      "          [ 0.0476,  0.0801,  0.1263]],\n",
      "\n",
      "         [[-0.0116,  0.0496,  0.0300],\n",
      "          [ 0.0584,  0.0802, -0.0052],\n",
      "          [ 0.0453,  0.0150, -0.0060]],\n",
      "\n",
      "         [[-0.0560, -0.0443, -0.1017],\n",
      "          [-0.0693,  0.0226, -0.0382],\n",
      "          [-0.1770,  0.0346, -0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0055, -0.0404, -0.0066],\n",
      "          [ 0.0860, -0.0108, -0.0590],\n",
      "          [-0.0417,  0.0150, -0.0142]],\n",
      "\n",
      "         [[ 0.0987,  0.0430, -0.0545],\n",
      "          [ 0.0750,  0.1202, -0.0601],\n",
      "          [ 0.0942,  0.0923,  0.0657]],\n",
      "\n",
      "         [[ 0.0138, -0.1463, -0.2441],\n",
      "          [ 0.0295, -0.1478, -0.2368],\n",
      "          [ 0.0590,  0.0091, -0.0454]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0551,  0.0160, -0.1533],\n",
      "          [ 0.1023,  0.0429,  0.0173],\n",
      "          [ 0.0850,  0.0422,  0.0268]],\n",
      "\n",
      "         [[-0.0542, -0.0910, -0.1681],\n",
      "          [-0.0459, -0.1546, -0.2041],\n",
      "          [ 0.0730, -0.0650, -0.1178]],\n",
      "\n",
      "         [[ 0.0216,  0.0210,  0.0649],\n",
      "          [-0.0062,  0.1027,  0.0963],\n",
      "          [ 0.0781,  0.1217,  0.1648]]],\n",
      "\n",
      "\n",
      "        [[[-0.0840, -0.0604, -0.1048],\n",
      "          [ 0.0050, -0.0269, -0.0598],\n",
      "          [ 0.0543, -0.0162,  0.0746]],\n",
      "\n",
      "         [[ 0.0714, -0.0949, -0.0633],\n",
      "          [ 0.0028, -0.0647, -0.0687],\n",
      "          [ 0.0378, -0.0507, -0.0294]],\n",
      "\n",
      "         [[-0.1622, -0.0559,  0.0084],\n",
      "          [-0.1019, -0.0703,  0.0209],\n",
      "          [-0.0760,  0.0060, -0.0343]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0835, -0.0558, -0.0366],\n",
      "          [-0.0245,  0.0304,  0.0267],\n",
      "          [ 0.0077,  0.0967,  0.1665]],\n",
      "\n",
      "         [[-0.0194, -0.0309,  0.0407],\n",
      "          [-0.0620, -0.0535, -0.0118],\n",
      "          [ 0.0259,  0.0354, -0.0310]],\n",
      "\n",
      "         [[ 0.0145,  0.0112, -0.0916],\n",
      "          [ 0.0663,  0.0586,  0.0409],\n",
      "          [ 0.0842,  0.0362,  0.0395]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0403, -0.0423, -0.0465],\n",
      "          [-0.0241, -0.1455, -0.1617],\n",
      "          [-0.0679, -0.1491, -0.2013]],\n",
      "\n",
      "         [[ 0.0982,  0.0121, -0.1197],\n",
      "          [ 0.1059,  0.0716, -0.0809],\n",
      "          [ 0.0575,  0.0421, -0.0874]],\n",
      "\n",
      "         [[ 0.0824,  0.0636,  0.0258],\n",
      "          [ 0.1021,  0.0765,  0.0218],\n",
      "          [ 0.0250,  0.0167,  0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0314,  0.0241,  0.0481],\n",
      "          [-0.0588,  0.0096, -0.0500],\n",
      "          [-0.1616, -0.1402, -0.1753]],\n",
      "\n",
      "         [[ 0.0720,  0.0792,  0.0090],\n",
      "          [ 0.1451,  0.1471,  0.0531],\n",
      "          [ 0.0982,  0.0613,  0.1012]],\n",
      "\n",
      "         [[ 0.0501,  0.0621,  0.0510],\n",
      "          [-0.0531,  0.0012,  0.0112],\n",
      "          [ 0.1568,  0.1367, -0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0750, -0.0805, -0.1158],\n",
      "          [ 0.1142,  0.1145, -0.1092],\n",
      "          [ 0.1301,  0.0937, -0.0344]],\n",
      "\n",
      "         [[ 0.0190,  0.0193,  0.0189],\n",
      "          [-0.1078,  0.0234,  0.0243],\n",
      "          [-0.1590, -0.0393, -0.0830]],\n",
      "\n",
      "         [[ 0.0021, -0.0070, -0.0724],\n",
      "          [-0.0015,  0.0409, -0.1242],\n",
      "          [-0.0008, -0.0578, -0.1625]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1442, -0.1199, -0.0122],\n",
      "          [-0.0914, -0.1198, -0.0634],\n",
      "          [-0.0145, -0.1144, -0.0687]],\n",
      "\n",
      "         [[-0.2061, -0.0947, -0.0236],\n",
      "          [-0.2022, -0.0858,  0.0705],\n",
      "          [-0.1216, -0.0031,  0.0544]],\n",
      "\n",
      "         [[-0.0135, -0.0321,  0.0574],\n",
      "          [-0.0284,  0.0314,  0.0714],\n",
      "          [-0.0661, -0.0489,  0.0611]]],\n",
      "\n",
      "\n",
      "        [[[-0.0189, -0.0957, -0.1116],\n",
      "          [ 0.0370, -0.0481, -0.1166],\n",
      "          [-0.0197, -0.0674, -0.0397]],\n",
      "\n",
      "         [[ 0.0533,  0.1001,  0.0303],\n",
      "          [ 0.0491,  0.1305,  0.0769],\n",
      "          [ 0.0807,  0.0742, -0.0209]],\n",
      "\n",
      "         [[ 0.0366,  0.1046,  0.0401],\n",
      "          [-0.0241,  0.0444,  0.0605],\n",
      "          [-0.0381,  0.0562,  0.0124]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0380,  0.0395, -0.0012],\n",
      "          [ 0.0087, -0.0615, -0.0407],\n",
      "          [-0.0901, -0.0994, -0.1523]],\n",
      "\n",
      "         [[ 0.0722, -0.0025,  0.0089],\n",
      "          [ 0.1353,  0.0853,  0.0725],\n",
      "          [ 0.1138,  0.1047, -0.0218]],\n",
      "\n",
      "         [[ 0.1966,  0.1235, -0.0192],\n",
      "          [ 0.2194,  0.0926, -0.0309],\n",
      "          [ 0.0511, -0.0930, -0.0590]]]])\n",
      "rescnn_layers.1.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0603,  0.0663, -0.1395,  0.1278,  0.0384,  0.0669,  0.0086,  0.0542,\n",
      "         0.0607, -0.0818,  0.1494, -0.1313, -0.0568,  0.0252,  0.0518, -0.0061,\n",
      "         0.1271,  0.0295, -0.0220,  0.0315, -0.0066,  0.0295,  0.0519,  0.0518,\n",
      "        -0.0217, -0.0937,  0.0239,  0.0956,  0.0355,  0.0911,  0.1345, -0.1175,\n",
      "         0.0241, -0.0228,  0.0954,  0.0426, -0.1063,  0.0458,  0.0780,  0.0217,\n",
      "        -0.0845,  0.0427,  0.0029,  0.0830, -0.0545, -0.0291, -0.0974, -0.1034,\n",
      "        -0.0014, -0.1148,  0.0270,  0.1400, -0.0622, -0.0042,  0.0048, -0.1202,\n",
      "         0.0550, -0.0321, -0.0526, -0.1123,  0.0430, -0.0415, -0.0063, -0.0447])\n",
      "rescnn_layers.1.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([0.9428, 1.0034, 0.9800, 0.8155, 0.9468, 0.7985, 0.9213, 0.7959, 0.6956,\n",
      "        0.7595, 0.8575, 0.8468, 0.9112, 0.8568, 0.9105, 0.8765, 0.9937, 0.9815,\n",
      "        1.0059, 1.0530, 1.0945, 1.0436, 1.0574, 1.0939, 1.0800, 1.0777, 1.0730,\n",
      "        1.0255, 1.0888, 1.0353, 1.0477, 1.0432, 1.0686, 1.0566, 1.0177, 1.0642,\n",
      "        1.0355, 1.0374, 0.9866, 1.0042, 1.0174, 1.0308, 1.0767, 1.0873, 1.0137,\n",
      "        1.0695, 1.0327, 0.9776, 1.0413, 1.0718, 1.0668, 1.0381, 1.0319, 1.0154,\n",
      "        0.9591, 1.0216, 0.9768, 0.9537, 1.0499, 1.0696, 1.0768, 1.0212, 1.0387,\n",
      "        1.0688])\n",
      "rescnn_layers.1.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([-4.2164e-02,  4.1855e-03, -9.9507e-03, -2.0053e-03,  4.8524e-02,\n",
      "        -1.9555e-02, -4.8178e-02, -3.6412e-02, -2.7734e-02, -1.9500e-03,\n",
      "         1.2582e-02, -1.8386e-03,  1.0548e-02, -3.8188e-03, -1.7672e-02,\n",
      "        -2.2342e-02,  4.1486e-03,  7.2988e-03, -1.4494e-02,  4.1731e-03,\n",
      "        -2.2092e-02, -2.5943e-02, -1.3628e-02, -2.4598e-02,  3.8689e-03,\n",
      "         1.9587e-02,  2.0081e-02,  1.3795e-02,  4.8700e-03, -1.2046e-03,\n",
      "        -1.7247e-03, -5.4266e-04, -3.0546e-02, -4.4911e-02, -3.0627e-02,\n",
      "        -1.3219e-02, -5.0835e-02, -3.6425e-02, -2.6563e-02, -1.2260e-02,\n",
      "         6.7742e-03, -6.6005e-03,  3.7398e-03,  3.3020e-02, -9.6453e-03,\n",
      "        -2.2302e-02, -1.8200e-02, -1.2204e-02,  1.1242e-02, -2.6851e-03,\n",
      "        -2.2722e-02,  9.3737e-03,  3.3959e-04, -7.8684e-03, -8.1120e-03,\n",
      "         7.4902e-03, -1.2223e-02, -3.1634e-02,  3.5892e-06, -4.3040e-04,\n",
      "         1.2971e-03, -1.3548e-02, -4.7268e-02, -2.3031e-02])\n",
      "rescnn_layers.1.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([0.9588, 0.8650, 0.8236, 0.7692, 0.8149, 0.8482, 0.7843, 0.8242, 0.7746,\n",
      "        0.8494, 0.8726, 0.8458, 0.7956, 0.9042, 0.9211, 0.9360, 0.9477, 1.0103,\n",
      "        1.0386, 1.0649, 1.0022, 1.0372, 1.0417, 1.0574, 1.0758, 1.1041, 1.1038,\n",
      "        1.0601, 1.0782, 1.1657, 1.1198, 1.0875, 1.0663, 1.1569, 1.0369, 1.0459,\n",
      "        1.0509, 1.0111, 0.9916, 1.0841, 1.0607, 1.1292, 1.1315, 1.0563, 1.0206,\n",
      "        1.1222, 1.0523, 1.0788, 0.9919, 1.1182, 1.1009, 1.0825, 1.1075, 1.0648,\n",
      "        0.9984, 0.9967, 1.0394, 1.0386, 1.1174, 1.1596, 1.0475, 1.0388, 1.1061,\n",
      "        1.1157])\n",
      "rescnn_layers.1.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([ 3.2483e-02, -1.6127e-02, -6.7930e-02, -1.4568e-01, -1.3609e-01,\n",
      "        -1.3972e-01, -1.2350e-01, -1.2595e-01, -1.2793e-01, -7.3419e-02,\n",
      "        -6.3467e-02, -7.1907e-02, -1.5524e-01, -7.9389e-02, -9.6323e-02,\n",
      "        -2.9517e-02, -1.0032e-05, -3.3376e-03, -7.2539e-02, -4.7793e-02,\n",
      "        -1.7287e-02, -8.1532e-03, -3.2639e-02, -4.7886e-02,  8.8097e-03,\n",
      "        -1.4446e-02, -3.0500e-02, -1.9368e-02, -5.8971e-02, -9.5664e-03,\n",
      "        -3.5974e-02, -3.7268e-02, -7.0336e-02, -3.9023e-03, -2.9076e-02,\n",
      "        -7.8745e-03, -1.2193e-02,  8.1065e-03, -2.3708e-02, -3.1279e-02,\n",
      "        -1.5496e-02, -1.2011e-02, -2.5852e-02, -5.2848e-02, -6.3846e-02,\n",
      "        -1.9233e-02, -1.9217e-03, -3.3226e-02, -5.5424e-02, -7.8016e-02,\n",
      "        -7.2469e-02, -4.7509e-02, -6.3252e-02, -5.7915e-02, -6.0266e-02,\n",
      "        -7.3126e-02, -4.0500e-02, -1.4701e-02,  6.7213e-02,  9.2505e-02,\n",
      "         4.4904e-02,  5.7531e-04, -1.4158e-02, -9.8646e-03])\n",
      "rescnn_layers.2.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 2.9487e-02, -5.9985e-02,  7.1496e-02],\n",
      "          [ 1.2532e-01, -3.9349e-03,  1.5966e-02],\n",
      "          [ 1.3988e-01,  3.6254e-02, -2.6489e-03]],\n",
      "\n",
      "         [[ 9.1750e-02, -5.3771e-02, -1.2528e-01],\n",
      "          [-1.1041e-02, -9.6532e-02, -2.5212e-01],\n",
      "          [-3.7619e-02, -1.8631e-02, -8.7502e-02]],\n",
      "\n",
      "         [[-4.6100e-02, -2.0169e-02,  6.2501e-02],\n",
      "          [-1.3633e-01, -5.3858e-02, -8.4416e-03],\n",
      "          [ 1.0723e-02,  3.1008e-02,  4.8299e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3569e-02,  2.3770e-02, -5.1029e-02],\n",
      "          [ 1.4290e-02, -2.6700e-02, -1.5727e-01],\n",
      "          [-3.7231e-02, -1.1971e-01, -9.5658e-02]],\n",
      "\n",
      "         [[-1.1284e-02, -1.7975e-02, -8.5252e-02],\n",
      "          [ 3.2500e-02, -3.7690e-02, -5.3778e-02],\n",
      "          [-7.1759e-03, -6.2390e-02, -1.2747e-01]],\n",
      "\n",
      "         [[-3.4105e-02,  1.7182e-01,  1.0607e-01],\n",
      "          [-1.4085e-01,  5.0782e-02,  3.4370e-02],\n",
      "          [-1.1284e-01,  3.0453e-02,  9.2131e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0837e-01,  1.5494e-01, -2.5575e-03],\n",
      "          [ 3.9033e-02,  6.3262e-02,  1.2159e-02],\n",
      "          [-3.3518e-02, -4.2100e-02, -5.1142e-03]],\n",
      "\n",
      "         [[-4.1665e-02, -7.0473e-02, -1.4081e-01],\n",
      "          [ 8.8109e-02,  1.1423e-01,  5.9670e-02],\n",
      "          [-2.7801e-02,  4.7928e-02,  7.1881e-02]],\n",
      "\n",
      "         [[-7.5940e-02,  4.1127e-02, -5.2220e-03],\n",
      "          [-1.6159e-01, -6.4515e-02, -2.7598e-02],\n",
      "          [ 2.6822e-02,  9.9752e-02, -2.3062e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1585e-02,  1.2721e-02,  1.6603e-02],\n",
      "          [ 6.6110e-03,  9.1922e-02,  1.6231e-01],\n",
      "          [-9.6945e-02, -5.9214e-02,  4.4701e-04]],\n",
      "\n",
      "         [[ 2.6966e-03,  9.4340e-02,  4.0401e-02],\n",
      "          [-1.8104e-02,  1.0127e-01,  4.8555e-02],\n",
      "          [ 1.5568e-01,  2.0186e-01,  1.9306e-01]],\n",
      "\n",
      "         [[-2.5253e-02, -2.5157e-02, -2.1403e-02],\n",
      "          [-8.0888e-02, -1.8087e-02,  3.0390e-02],\n",
      "          [ 3.5842e-02, -3.3415e-02,  3.9596e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3119e-02, -1.2179e-03, -6.0791e-02],\n",
      "          [ 7.7248e-02, -9.5589e-02, -9.5550e-02],\n",
      "          [ 2.9972e-02, -1.3120e-01, -8.8147e-02]],\n",
      "\n",
      "         [[ 2.4378e-01,  2.2844e-01,  1.9944e-01],\n",
      "          [ 8.8534e-02,  8.8992e-02,  7.3067e-02],\n",
      "          [ 1.8091e-02, -1.9201e-02, -1.1962e-01]],\n",
      "\n",
      "         [[ 1.2732e-02,  7.2791e-03, -1.3505e-01],\n",
      "          [ 8.9505e-02,  8.9044e-02, -9.8617e-02],\n",
      "          [ 6.1678e-02,  3.1703e-02, -1.9526e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0901e-01,  4.6319e-02, -9.7810e-04],\n",
      "          [ 3.7117e-02, -7.6787e-02, -9.4183e-02],\n",
      "          [ 1.2937e-01,  8.5005e-03, -5.0565e-02]],\n",
      "\n",
      "         [[-1.3073e-01, -8.2882e-02, -1.5735e-02],\n",
      "          [-1.7235e-02, -5.4175e-02, -5.8339e-02],\n",
      "          [-6.4479e-02, -5.5674e-02, -5.4742e-02]],\n",
      "\n",
      "         [[-9.3667e-03,  1.1676e-01, -7.3756e-02],\n",
      "          [ 3.1219e-02,  6.7786e-02, -3.4168e-02],\n",
      "          [ 8.7017e-02,  4.6372e-02,  2.8908e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5338e-03,  4.9890e-02,  9.4832e-02],\n",
      "          [ 2.2124e-02, -7.6533e-02, -1.9186e-02],\n",
      "          [ 1.0826e-02, -7.8806e-02, -4.7890e-02]],\n",
      "\n",
      "         [[ 3.1182e-02, -2.1798e-03, -2.9510e-02],\n",
      "          [ 1.2165e-01,  6.1379e-02,  5.3984e-02],\n",
      "          [ 8.3794e-02,  7.7943e-02,  5.2674e-02]],\n",
      "\n",
      "         [[-1.1091e-01,  5.7857e-02,  1.5661e-01],\n",
      "          [-1.5592e-01, -1.2744e-01,  4.8581e-02],\n",
      "          [-1.9974e-01, -1.5114e-01, -1.5339e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2551e-02, -6.1011e-02, -5.5197e-02],\n",
      "          [-2.1603e-02, -6.7762e-02,  6.6540e-03],\n",
      "          [ 4.3280e-03, -3.6028e-02, -1.3785e-02]],\n",
      "\n",
      "         [[ 3.2694e-02,  9.1975e-02,  1.3036e-01],\n",
      "          [ 7.7830e-03, -3.4670e-03,  2.0003e-01],\n",
      "          [ 2.2560e-02, -1.0012e-01, -6.4807e-02]],\n",
      "\n",
      "         [[-2.5893e-02, -5.3041e-02, -7.2525e-02],\n",
      "          [-3.8377e-02, -2.8121e-02, -9.5511e-02],\n",
      "          [-7.8982e-03, -2.0677e-02, -7.6546e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5474e-02, -6.2489e-02,  1.0558e-02],\n",
      "          [-2.8114e-03, -1.2846e-01, -1.3113e-02],\n",
      "          [ 2.8204e-02, -4.0377e-02,  4.8218e-02]],\n",
      "\n",
      "         [[-4.1963e-02, -4.4884e-02,  6.4281e-02],\n",
      "          [ 7.7012e-02, -1.4780e-02,  2.7762e-02],\n",
      "          [-4.2073e-03,  1.3101e-01,  9.5071e-02]],\n",
      "\n",
      "         [[ 1.0017e-01,  4.4707e-02, -3.5561e-02],\n",
      "          [ 5.2901e-02,  4.1959e-02, -2.2922e-02],\n",
      "          [-8.2983e-02, -1.0353e-01, -1.9408e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4803e-02,  2.0364e-02, -6.2721e-02],\n",
      "          [ 3.4383e-02, -1.7443e-02, -8.8764e-02],\n",
      "          [ 5.4896e-02,  7.2226e-02, -3.7540e-02]],\n",
      "\n",
      "         [[-2.6638e-02, -1.0646e-01, -6.3925e-02],\n",
      "          [-4.8988e-03, -7.0714e-02, -2.2687e-02],\n",
      "          [-9.6829e-02, -1.4391e-01, -1.4240e-02]],\n",
      "\n",
      "         [[ 6.7688e-03,  1.1305e-01,  2.3831e-02],\n",
      "          [-4.5537e-02,  3.3007e-02, -4.6986e-03],\n",
      "          [-5.9097e-02, -9.9141e-04, -5.0214e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4241e-01, -9.8232e-02,  8.2700e-03],\n",
      "          [-1.3171e-01, -1.7005e-01,  9.5013e-03],\n",
      "          [-9.7456e-02, -1.1727e-01, -7.9249e-02]],\n",
      "\n",
      "         [[-2.4090e-01, -4.1485e-02,  9.9159e-02],\n",
      "          [-2.8610e-01, -6.0783e-02,  2.1228e-01],\n",
      "          [-1.8502e-01, -1.2922e-01,  4.0821e-02]],\n",
      "\n",
      "         [[ 1.2968e-02, -1.0751e-01,  5.6922e-02],\n",
      "          [ 1.9961e-01, -3.8162e-02, -3.7119e-02],\n",
      "          [ 1.1545e-02, -4.6339e-02, -6.2654e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0639e-04, -1.0281e-01,  6.5521e-02],\n",
      "          [-1.0019e-01, -1.0174e-01,  4.4578e-02],\n",
      "          [ 9.5612e-02,  2.2078e-02,  7.6227e-02]],\n",
      "\n",
      "         [[-6.6114e-02, -1.8790e-02,  6.3873e-02],\n",
      "          [ 6.5585e-02,  5.4318e-05, -1.1641e-02],\n",
      "          [ 4.5619e-02,  7.7866e-05, -1.9650e-03]],\n",
      "\n",
      "         [[-1.6987e-01, -1.7493e-01, -1.6375e-01],\n",
      "          [-1.7784e-01, -1.1604e-01, -1.1001e-01],\n",
      "          [-1.1874e-01, -5.1212e-02, -3.0957e-02]]]])\n",
      "rescnn_layers.2.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0072,  0.0148,  0.0341,  0.0193,  0.0344,  0.0266,  0.0187, -0.0038,\n",
      "        -0.0045,  0.0323, -0.0069, -0.0069,  0.0123, -0.0397,  0.0010,  0.0265,\n",
      "        -0.0202, -0.0207,  0.0072,  0.0090, -0.0238,  0.0173, -0.0180, -0.0233,\n",
      "        -0.0140, -0.0050,  0.0263, -0.0085, -0.0346,  0.0168, -0.0207,  0.0051,\n",
      "        -0.0017, -0.0165, -0.0214, -0.0022, -0.0222, -0.0231,  0.0061,  0.0372,\n",
      "         0.0100, -0.0354, -0.0110,  0.0335, -0.0111,  0.0257,  0.0172, -0.0131,\n",
      "         0.0114,  0.0297,  0.0318,  0.0271,  0.0400, -0.0296, -0.0242, -0.0271,\n",
      "        -0.0273, -0.0410,  0.0189, -0.0166, -0.0281,  0.0315,  0.0212, -0.0424])\n",
      "rescnn_layers.2.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-0.0365, -0.0254,  0.0926],\n",
      "          [-0.0800, -0.0600,  0.0599],\n",
      "          [-0.0202, -0.0681,  0.0583]],\n",
      "\n",
      "         [[ 0.0537,  0.0784,  0.0146],\n",
      "          [-0.0636, -0.0336, -0.0846],\n",
      "          [-0.0396,  0.0058,  0.0247]],\n",
      "\n",
      "         [[ 0.0102,  0.1024,  0.1989],\n",
      "          [ 0.0369,  0.0468,  0.1713],\n",
      "          [-0.0599, -0.0567,  0.0217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0288,  0.0064,  0.0586],\n",
      "          [-0.0428, -0.0200, -0.0765],\n",
      "          [ 0.0313, -0.0049, -0.0755]],\n",
      "\n",
      "         [[-0.0444, -0.0812,  0.0863],\n",
      "          [-0.0865, -0.1335,  0.0859],\n",
      "          [-0.0676, -0.0183,  0.1398]],\n",
      "\n",
      "         [[ 0.1051,  0.1574,  0.0470],\n",
      "          [ 0.1267,  0.0995, -0.0288],\n",
      "          [ 0.0978,  0.0510, -0.1054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0722, -0.0828, -0.0862],\n",
      "          [ 0.0303,  0.0506, -0.0348],\n",
      "          [ 0.0140,  0.0052,  0.0275]],\n",
      "\n",
      "         [[ 0.0055, -0.0048,  0.0160],\n",
      "          [ 0.0780,  0.0739,  0.0287],\n",
      "          [ 0.0497,  0.0079,  0.0212]],\n",
      "\n",
      "         [[-0.0272, -0.0049, -0.0382],\n",
      "          [ 0.0424, -0.0398, -0.0023],\n",
      "          [ 0.0500,  0.0676,  0.0400]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0327,  0.0296, -0.0369],\n",
      "          [ 0.1523,  0.0311,  0.0637],\n",
      "          [ 0.0518,  0.0353,  0.0684]],\n",
      "\n",
      "         [[ 0.1359,  0.0922,  0.0535],\n",
      "          [-0.0133, -0.0416,  0.0882],\n",
      "          [-0.1265, -0.1299, -0.0493]],\n",
      "\n",
      "         [[-0.0681,  0.0962,  0.0031],\n",
      "          [-0.0361,  0.0124, -0.0246],\n",
      "          [ 0.0470,  0.0900,  0.0609]]],\n",
      "\n",
      "\n",
      "        [[[-0.0732, -0.0618, -0.0479],\n",
      "          [-0.0034, -0.0529, -0.0916],\n",
      "          [ 0.1018, -0.0465, -0.1055]],\n",
      "\n",
      "         [[-0.0057, -0.0713, -0.0277],\n",
      "          [-0.0709, -0.1713, -0.0774],\n",
      "          [ 0.0408, -0.0689,  0.0306]],\n",
      "\n",
      "         [[-0.0134,  0.1119,  0.0137],\n",
      "          [ 0.0801,  0.0757,  0.0599],\n",
      "          [ 0.0561,  0.0933,  0.0407]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0706, -0.0594, -0.1196],\n",
      "          [-0.0886, -0.0144, -0.0763],\n",
      "          [-0.0135,  0.0860,  0.0008]],\n",
      "\n",
      "         [[-0.1215,  0.0163, -0.1168],\n",
      "          [-0.0134, -0.0049, -0.0545],\n",
      "          [-0.0182,  0.0502,  0.0361]],\n",
      "\n",
      "         [[-0.0030, -0.0615, -0.0505],\n",
      "          [ 0.0183, -0.0192,  0.0350],\n",
      "          [-0.0406, -0.0216,  0.0561]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0062,  0.1112,  0.0977],\n",
      "          [ 0.0906,  0.1369,  0.1728],\n",
      "          [ 0.0124,  0.0841,  0.1430]],\n",
      "\n",
      "         [[-0.0063, -0.0274,  0.0557],\n",
      "          [ 0.1897,  0.1560,  0.1273],\n",
      "          [ 0.0621,  0.0459,  0.0437]],\n",
      "\n",
      "         [[-0.1170,  0.0159, -0.0186],\n",
      "          [-0.0989,  0.0752, -0.0419],\n",
      "          [-0.0353,  0.0456,  0.0118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0626,  0.0428,  0.0249],\n",
      "          [ 0.1043,  0.0983,  0.0265],\n",
      "          [ 0.0730, -0.0360, -0.0349]],\n",
      "\n",
      "         [[-0.0084,  0.0920,  0.0279],\n",
      "          [-0.0788,  0.0645,  0.0188],\n",
      "          [-0.1585, -0.0600, -0.0495]],\n",
      "\n",
      "         [[-0.0660,  0.0932,  0.1194],\n",
      "          [-0.1104, -0.1171, -0.0025],\n",
      "          [-0.0669, -0.1560, -0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1475,  0.0705,  0.0674],\n",
      "          [ 0.1282,  0.0182,  0.1162],\n",
      "          [ 0.0891,  0.0327,  0.0304]],\n",
      "\n",
      "         [[ 0.0735,  0.1417,  0.0192],\n",
      "          [ 0.0155,  0.0441,  0.0193],\n",
      "          [-0.0258,  0.0784, -0.0369]],\n",
      "\n",
      "         [[ 0.0335, -0.0132,  0.1133],\n",
      "          [ 0.0358, -0.0251,  0.1152],\n",
      "          [-0.0455, -0.1223, -0.0073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0315,  0.0368, -0.0976],\n",
      "          [ 0.0555,  0.0529, -0.1506],\n",
      "          [ 0.0886,  0.0710, -0.1101]],\n",
      "\n",
      "         [[ 0.0879, -0.0372, -0.0873],\n",
      "          [ 0.1059, -0.0651, -0.0494],\n",
      "          [ 0.0298,  0.0280,  0.0813]],\n",
      "\n",
      "         [[ 0.1036, -0.0105, -0.0921],\n",
      "          [ 0.1782, -0.0506, -0.1825],\n",
      "          [ 0.0132, -0.0298, -0.1438]]],\n",
      "\n",
      "\n",
      "        [[[-0.1275, -0.0600, -0.0007],\n",
      "          [-0.0491, -0.0783,  0.0129],\n",
      "          [-0.0940,  0.0398,  0.0190]],\n",
      "\n",
      "         [[-0.0385,  0.0894,  0.0822],\n",
      "          [-0.1008, -0.0013,  0.1080],\n",
      "          [-0.1342, -0.0056,  0.0044]],\n",
      "\n",
      "         [[-0.0636, -0.0587,  0.0550],\n",
      "          [-0.1171, -0.0801,  0.0495],\n",
      "          [-0.1232,  0.0014,  0.0649]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0134,  0.0259, -0.0511],\n",
      "          [-0.0341, -0.0512, -0.1308],\n",
      "          [ 0.0264, -0.0927, -0.1747]],\n",
      "\n",
      "         [[ 0.0451, -0.0360,  0.0090],\n",
      "          [ 0.0694,  0.0125, -0.0252],\n",
      "          [ 0.1046,  0.0985,  0.0574]],\n",
      "\n",
      "         [[ 0.1396,  0.0407,  0.0117],\n",
      "          [ 0.1945,  0.0859, -0.0358],\n",
      "          [ 0.1064,  0.0115, -0.0523]]]])\n",
      "rescnn_layers.2.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0761,  0.0400, -0.1013,  0.0725, -0.0214,  0.0193, -0.0594,  0.1160,\n",
      "         0.0364, -0.0450,  0.1654, -0.1332, -0.0891,  0.0704,  0.0480, -0.0468,\n",
      "         0.1627,  0.0067, -0.0092,  0.0564, -0.0103,  0.0735,  0.0324,  0.0377,\n",
      "         0.0390, -0.0995, -0.0233,  0.0537,  0.0274,  0.0753,  0.0947, -0.0865,\n",
      "         0.0048, -0.0283,  0.0534,  0.0309, -0.0929,  0.0863,  0.0787,  0.0565,\n",
      "        -0.1150,  0.0977,  0.0019,  0.1039, -0.0092, -0.0595, -0.0956, -0.0637,\n",
      "         0.0057, -0.0905,  0.0456,  0.1354, -0.0201, -0.0207,  0.0043, -0.1821,\n",
      "         0.0671, -0.0541, -0.0168, -0.1202,  0.0544, -0.0471, -0.0540, -0.0807])\n",
      "rescnn_layers.2.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0193, 0.9680, 0.9875, 0.9660, 0.9342, 0.8509, 0.8651, 0.9053, 0.7754,\n",
      "        0.8115, 0.8567, 0.8562, 0.8603, 0.8322, 0.8382, 0.8623, 0.9231, 1.0081,\n",
      "        1.0266, 1.0439, 1.0185, 1.1195, 1.1402, 1.0674, 1.1100, 1.1130, 1.0103,\n",
      "        1.0756, 1.0563, 1.0492, 1.0595, 1.0524, 1.0600, 1.0720, 1.0341, 1.0678,\n",
      "        1.0608, 1.0639, 1.0262, 1.1027, 1.0941, 1.0819, 1.1013, 1.0192, 1.0201,\n",
      "        1.0943, 1.1287, 1.0270, 1.0042, 1.0854, 1.1192, 1.1111, 1.0973, 1.0475,\n",
      "        0.9914, 1.0200, 1.0493, 0.9307, 1.0106, 1.0458, 0.9742, 0.9897, 1.0689,\n",
      "        1.0576])\n",
      "rescnn_layers.2.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.0313, -0.0746, -0.0379, -0.0024,  0.0655,  0.0397,  0.0027,  0.0174,\n",
      "        -0.0433,  0.0398,  0.0091,  0.0416,  0.0274,  0.0602,  0.0064,  0.0513,\n",
      "         0.0593,  0.0316, -0.0531,  0.0226,  0.0375,  0.0321,  0.0118, -0.0429,\n",
      "         0.0069,  0.0109, -0.0087,  0.0233, -0.0026,  0.0276,  0.0295,  0.0248,\n",
      "        -0.0582, -0.0734, -0.0388,  0.0155, -0.0499, -0.0856, -0.0660,  0.0138,\n",
      "        -0.0074, -0.0414,  0.0210,  0.0182,  0.0198, -0.0294, -0.0256, -0.0348,\n",
      "        -0.0456, -0.0347, -0.0207, -0.0227,  0.0201,  0.0098,  0.0123,  0.0076,\n",
      "         0.0158, -0.0472, -0.0131, -0.0274, -0.0853, -0.1275, -0.0965, -0.0223])\n",
      "rescnn_layers.2.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0047, 0.9536, 0.9478, 0.9694, 0.9035, 0.9243, 0.9432, 0.9365, 0.9178,\n",
      "        0.9092, 0.9674, 0.8925, 0.8536, 0.8652, 0.9300, 0.9770, 1.0133, 0.9590,\n",
      "        1.0025, 1.0202, 1.0628, 1.0632, 1.0551, 1.0414, 1.0257, 1.0261, 1.0652,\n",
      "        1.0718, 1.0268, 1.0468, 1.0289, 1.0027, 0.9997, 1.0155, 1.0181, 1.0200,\n",
      "        1.0144, 0.9846, 0.9776, 1.0285, 1.0434, 1.0178, 1.0051, 0.9776, 0.9520,\n",
      "        0.9491, 1.0157, 0.9850, 1.0206, 1.0840, 1.0514, 1.0352, 1.0371, 1.0577,\n",
      "        0.9609, 0.9595, 0.9977, 0.9677, 0.9738, 0.9959, 1.0070, 1.0047, 1.0233,\n",
      "        1.0328])\n",
      "rescnn_layers.2.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([-0.0324, -0.0810, -0.0859, -0.1296, -0.1342, -0.1239, -0.0784, -0.1195,\n",
      "        -0.1036, -0.0946, -0.0934, -0.1495, -0.1839, -0.1831, -0.1749, -0.1015,\n",
      "        -0.0730, -0.1199, -0.1231, -0.1276, -0.1123, -0.0998, -0.1122, -0.1136,\n",
      "        -0.1011, -0.0906, -0.0549, -0.0871, -0.1267, -0.0984, -0.1110, -0.1006,\n",
      "        -0.1038, -0.0884, -0.0611, -0.0890, -0.0751, -0.0904, -0.0908, -0.0726,\n",
      "        -0.0305, -0.0692, -0.0858, -0.0990, -0.1097, -0.0865, -0.0486, -0.0508,\n",
      "        -0.0177, -0.0251, -0.0375, -0.0293, -0.0799, -0.0830, -0.1008, -0.1085,\n",
      "        -0.0603, -0.0003,  0.0528,  0.0928,  0.0483,  0.0254, -0.0280, -0.0481])\n",
      "rescnn_layers.3.cnn1.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[-1.8673e-01, -9.1919e-02,  2.6868e-02],\n",
      "          [-1.0117e-01, -6.8607e-02,  3.7005e-03],\n",
      "          [-1.6866e-01, -1.9178e-01, -8.7254e-02]],\n",
      "\n",
      "         [[-1.7049e-01, -6.5365e-02,  5.5313e-02],\n",
      "          [-1.2035e-01, -9.0378e-02, -4.7467e-02],\n",
      "          [-7.8959e-02, -1.2238e-01, -5.9624e-02]],\n",
      "\n",
      "         [[ 1.5775e-01, -7.4542e-02, -1.1379e-01],\n",
      "          [ 2.5646e-01,  4.6434e-02, -8.2799e-02],\n",
      "          [ 6.0124e-02, -2.6397e-02, -1.3649e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3735e-04, -3.9063e-02,  1.4743e-01],\n",
      "          [ 2.7959e-02,  7.5376e-02,  1.7816e-01],\n",
      "          [-1.2564e-02,  3.3280e-02,  3.7902e-02]],\n",
      "\n",
      "         [[-1.7358e-01, -7.0760e-02, -1.3037e-01],\n",
      "          [-1.1774e-02, -1.4313e-02, -2.8685e-02],\n",
      "          [ 4.0928e-02,  8.5732e-02,  2.0990e-02]],\n",
      "\n",
      "         [[-1.5237e-01, -4.5581e-02,  3.4446e-02],\n",
      "          [-1.2729e-01,  6.7151e-02,  1.1826e-01],\n",
      "          [-2.2441e-02,  5.7555e-02,  2.0000e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4993e-02, -3.3504e-02,  2.8698e-02],\n",
      "          [-8.0990e-02, -7.2636e-02,  1.5827e-02],\n",
      "          [-1.4854e-01, -9.6606e-02, -6.5398e-02]],\n",
      "\n",
      "         [[-7.9113e-02,  5.5228e-02, -4.6591e-02],\n",
      "          [-5.0641e-02,  2.5282e-02, -5.7341e-02],\n",
      "          [ 1.6025e-02,  6.8621e-02,  6.2822e-02]],\n",
      "\n",
      "         [[ 4.2634e-02, -2.6381e-02, -3.2392e-02],\n",
      "          [ 3.3297e-02,  6.5564e-03, -3.3177e-02],\n",
      "          [-1.5515e-02,  1.4602e-02, -2.1865e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1315e-01, -8.9117e-02,  1.9858e-02],\n",
      "          [-1.9604e-01, -7.9414e-02,  7.5899e-02],\n",
      "          [-1.3605e-01, -7.5300e-02,  1.2231e-02]],\n",
      "\n",
      "         [[ 6.0867e-02, -6.9799e-02, -4.0460e-02],\n",
      "          [ 4.0769e-02, -1.0408e-01, -8.1646e-02],\n",
      "          [ 5.1372e-02, -6.2665e-02, -1.3973e-01]],\n",
      "\n",
      "         [[ 9.4343e-02,  7.6613e-02,  4.0257e-02],\n",
      "          [ 9.1263e-02,  6.6372e-02,  5.1123e-02],\n",
      "          [ 1.1658e-01,  6.0227e-02,  1.2650e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9626e-03,  1.3771e-02, -5.2698e-03],\n",
      "          [ 4.9046e-02,  2.3808e-02, -1.4085e-02],\n",
      "          [-7.2668e-02, -5.3563e-02, -9.4363e-02]],\n",
      "\n",
      "         [[ 3.3070e-02, -1.6063e-02, -1.3564e-02],\n",
      "          [ 7.9351e-03,  9.1128e-02,  4.7417e-02],\n",
      "          [-6.8074e-03,  8.9851e-02,  1.1709e-01]],\n",
      "\n",
      "         [[-5.0424e-02, -2.5605e-02, -5.6634e-02],\n",
      "          [ 4.7397e-02, -2.6549e-02,  9.1809e-02],\n",
      "          [ 6.0855e-02,  6.8469e-02,  1.3900e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0743e-01, -1.4350e-01, -1.1638e-01],\n",
      "          [-1.4785e-01, -9.8498e-02, -1.2268e-02],\n",
      "          [-1.8412e-01, -4.4047e-02,  1.7439e-02]],\n",
      "\n",
      "         [[-5.3470e-02, -3.1752e-03, -6.6625e-02],\n",
      "          [-5.6489e-02, -6.0848e-02, -7.9050e-02],\n",
      "          [ 1.9769e-02,  3.8071e-02,  5.7395e-02]],\n",
      "\n",
      "         [[-2.5944e-02, -7.9864e-02, -1.1298e-01],\n",
      "          [-7.9749e-03, -5.1475e-02, -1.4063e-01],\n",
      "          [ 2.9945e-04, -2.7472e-02, -8.6354e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9581e-02,  6.0210e-02,  1.7817e-02],\n",
      "          [ 5.2533e-02,  8.6578e-02,  2.1283e-02],\n",
      "          [-4.3438e-03,  1.1845e-01,  4.2896e-02]],\n",
      "\n",
      "         [[ 5.7720e-02,  3.5820e-02,  5.0361e-02],\n",
      "          [ 7.6607e-02,  4.6949e-02,  8.0739e-02],\n",
      "          [-7.5042e-02, -5.1876e-02,  2.5418e-02]],\n",
      "\n",
      "         [[ 1.1142e-02, -5.5692e-02, -8.2968e-02],\n",
      "          [-2.3755e-02, -1.8219e-02,  3.5950e-02],\n",
      "          [-4.5190e-02, -1.5933e-03,  5.2358e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6504e-02, -2.7476e-02, -4.8989e-02],\n",
      "          [ 1.6318e-02,  1.9344e-02, -2.3096e-02],\n",
      "          [-4.8291e-02, -2.7719e-02,  3.3453e-02]],\n",
      "\n",
      "         [[ 1.3114e-02,  1.3393e-02, -4.8468e-02],\n",
      "          [-1.0678e-01, -2.0282e-02, -7.9641e-02],\n",
      "          [-1.0194e-01, -6.2231e-02, -1.2774e-01]],\n",
      "\n",
      "         [[-1.6773e-01, -9.4964e-02,  3.0276e-02],\n",
      "          [-1.5876e-01, -1.1096e-01, -1.8427e-02],\n",
      "          [ 1.0756e-04, -1.9681e-02,  2.3893e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1976e-02, -2.8818e-02, -5.2061e-02],\n",
      "          [ 1.1654e-01,  4.6808e-02, -6.3516e-02],\n",
      "          [ 1.0525e-01,  5.0303e-02,  4.3797e-02]],\n",
      "\n",
      "         [[-1.1531e-01, -9.8998e-02, -1.9236e-01],\n",
      "          [-4.1795e-02, -1.2508e-02, -1.2682e-01],\n",
      "          [-9.1177e-03,  4.8789e-04, -6.7704e-02]],\n",
      "\n",
      "         [[ 1.5873e-01,  3.3640e-02, -4.7249e-02],\n",
      "          [ 1.3413e-01,  3.8000e-02, -4.5818e-02],\n",
      "          [ 4.9848e-02,  3.6740e-02,  2.5458e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4790e-02,  4.2784e-02,  7.5444e-02],\n",
      "          [ 7.9074e-02,  1.6104e-01,  6.9204e-02],\n",
      "          [ 2.4394e-02,  5.5778e-02,  3.2212e-02]],\n",
      "\n",
      "         [[-9.8287e-02, -5.7840e-02, -4.1110e-02],\n",
      "          [-5.5362e-02, -3.2348e-02,  5.4211e-02],\n",
      "          [ 5.2742e-02,  3.6083e-02,  8.0182e-02]],\n",
      "\n",
      "         [[ 8.0165e-02,  8.7370e-02,  1.8511e-01],\n",
      "          [-6.6806e-03,  5.0927e-02,  1.7172e-01],\n",
      "          [-2.6348e-02, -3.6647e-02,  6.7477e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7656e-02, -5.7198e-02,  3.5476e-02],\n",
      "          [-4.1806e-02, -2.9986e-02,  7.9840e-02],\n",
      "          [-3.7832e-02, -2.0115e-03,  8.7566e-02]],\n",
      "\n",
      "         [[-6.9752e-02, -7.4427e-03,  2.4683e-02],\n",
      "          [-2.2988e-01, -7.7460e-02,  3.8436e-02],\n",
      "          [-2.7849e-01, -1.7482e-01,  7.4726e-02]],\n",
      "\n",
      "         [[-5.7656e-02, -2.1514e-01, -2.4796e-01],\n",
      "          [-4.9103e-02, -1.3209e-01, -1.1927e-01],\n",
      "          [-5.9370e-03,  1.4370e-02, -8.6441e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9903e-02,  7.6398e-02, -2.0551e-02],\n",
      "          [-1.5546e-01, -6.5011e-02, -1.1548e-01],\n",
      "          [-7.1793e-02, -9.4051e-02, -2.8240e-02]],\n",
      "\n",
      "         [[ 8.1725e-02,  7.2336e-02,  3.5046e-02],\n",
      "          [ 1.3463e-01,  1.0155e-01,  4.7327e-02],\n",
      "          [ 8.7791e-02,  1.9220e-02,  1.3363e-02]],\n",
      "\n",
      "         [[-6.4861e-02,  2.2721e-02,  9.6831e-02],\n",
      "          [-9.6183e-02,  1.3377e-02,  1.4452e-01],\n",
      "          [-6.2572e-03,  8.1825e-02,  1.4462e-01]]]])\n",
      "rescnn_layers.3.cnn1.bias torch.Size([64])\n",
      "tensor([-0.0364, -0.0174, -0.0201, -0.0335, -0.0256,  0.0337, -0.0386, -0.0298,\n",
      "         0.0401,  0.0186,  0.0256,  0.0379, -0.0060,  0.0091,  0.0143, -0.0123,\n",
      "         0.0094,  0.0242,  0.0086,  0.0053,  0.0238, -0.0403, -0.0242, -0.0167,\n",
      "         0.0061, -0.0195,  0.0157, -0.0267,  0.0210, -0.0039, -0.0350, -0.0355,\n",
      "        -0.0418,  0.0171, -0.0140, -0.0174, -0.0117,  0.0327,  0.0052,  0.0141,\n",
      "         0.0083, -0.0385,  0.0219, -0.0074,  0.0186, -0.0142,  0.0422,  0.0362,\n",
      "         0.0254, -0.0174,  0.0053,  0.0341, -0.0133,  0.0182,  0.0247,  0.0064,\n",
      "         0.0169, -0.0027,  0.0188,  0.0223, -0.0286,  0.0196,  0.0388,  0.0078])\n",
      "rescnn_layers.3.cnn2.weight torch.Size([64, 64, 3, 3])\n",
      "tensor([[[[ 1.7481e-02,  5.7277e-02,  8.6197e-02],\n",
      "          [ 7.1446e-02,  1.0398e-01,  7.5126e-02],\n",
      "          [ 1.2633e-01,  1.1971e-01,  5.5420e-02]],\n",
      "\n",
      "         [[-3.4997e-02, -2.7678e-02,  4.3471e-02],\n",
      "          [-7.6284e-02,  2.8245e-02,  9.8508e-02],\n",
      "          [ 5.5751e-02,  3.1614e-02,  1.2139e-01]],\n",
      "\n",
      "         [[-1.8514e-02,  4.3700e-02,  1.3582e-01],\n",
      "          [-8.6156e-02,  2.2654e-02,  8.5358e-02],\n",
      "          [-2.4641e-02, -2.4085e-02,  5.2346e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1174e-01,  9.1877e-02,  1.3905e-01],\n",
      "          [ 7.2797e-02,  3.2484e-02,  7.6224e-02],\n",
      "          [-6.8892e-02, -8.9818e-02, -2.6911e-02]],\n",
      "\n",
      "         [[ 1.5100e-02, -1.2620e-02, -7.9082e-03],\n",
      "          [-4.2714e-02, -3.1223e-02,  5.3809e-02],\n",
      "          [ 5.8226e-03,  1.3940e-02,  6.1622e-02]],\n",
      "\n",
      "         [[-4.2486e-02, -4.2767e-02,  1.4614e-02],\n",
      "          [ 9.0436e-03, -1.9607e-02,  6.2873e-02],\n",
      "          [ 5.7145e-02, -4.0135e-02,  6.7633e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3722e-02,  1.8933e-01,  1.3702e-01],\n",
      "          [ 5.2890e-04,  8.1965e-02,  8.1330e-02],\n",
      "          [ 3.1405e-03,  8.4268e-02,  1.5705e-03]],\n",
      "\n",
      "         [[-4.5312e-02, -1.5630e-02,  1.2201e-01],\n",
      "          [ 4.3387e-02, -5.1906e-03,  1.3098e-01],\n",
      "          [-5.9578e-03, -3.7826e-05,  4.5515e-02]],\n",
      "\n",
      "         [[-5.1950e-02, -4.6152e-02, -5.2469e-02],\n",
      "          [ 1.7785e-02, -1.3891e-02, -1.7782e-02],\n",
      "          [ 1.3822e-01,  8.5735e-02,  6.5859e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5933e-02, -3.7548e-02, -9.1635e-02],\n",
      "          [-4.8450e-02,  5.7036e-03,  4.5313e-02],\n",
      "          [-3.6172e-02, -5.8770e-03, -1.7729e-02]],\n",
      "\n",
      "         [[ 7.4698e-02,  7.7847e-02,  2.2394e-02],\n",
      "          [ 7.5417e-02,  5.7256e-02,  1.4700e-03],\n",
      "          [ 6.7042e-02, -6.4940e-03, -7.1044e-03]],\n",
      "\n",
      "         [[-1.9075e-02,  6.2327e-02,  1.5722e-01],\n",
      "          [-2.4153e-02,  7.3098e-02,  1.6657e-01],\n",
      "          [ 9.8425e-02,  1.0767e-01,  1.2363e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0116e-03,  2.1360e-02,  1.0335e-01],\n",
      "          [ 1.4616e-01,  7.8205e-02,  9.6176e-02],\n",
      "          [ 6.1524e-02,  1.7487e-02,  5.9531e-02]],\n",
      "\n",
      "         [[-2.9441e-02, -5.5644e-02, -1.2253e-02],\n",
      "          [-8.8200e-02, -3.3446e-02,  1.3499e-02],\n",
      "          [-4.4844e-03,  3.0980e-02,  9.0324e-02]],\n",
      "\n",
      "         [[-1.0871e-01, -1.3772e-01, -8.7340e-02],\n",
      "          [-4.7217e-02, -1.2667e-01, -1.6123e-01],\n",
      "          [ 4.1789e-02,  5.2577e-02,  2.0558e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0970e-02,  5.0858e-02,  7.2658e-02],\n",
      "          [ 4.7312e-02,  7.0775e-02,  7.0433e-02],\n",
      "          [ 2.8700e-02,  5.3567e-02,  4.1703e-02]],\n",
      "\n",
      "         [[-1.8000e-01, -4.1015e-02,  3.6676e-02],\n",
      "          [-1.2475e-01, -3.3055e-02,  4.4787e-02],\n",
      "          [-2.1955e-02, -6.2622e-02,  4.5790e-02]],\n",
      "\n",
      "         [[-1.3119e-03,  6.6680e-02,  5.3515e-02],\n",
      "          [ 3.7629e-02,  5.9352e-02,  9.8878e-02],\n",
      "          [-3.8737e-02,  1.7582e-01,  1.3190e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3286e-01, -1.0247e-01,  4.9748e-02],\n",
      "          [-1.4515e-01, -1.6123e-01, -4.7319e-02],\n",
      "          [-5.1332e-02, -5.3000e-02, -6.7102e-02]],\n",
      "\n",
      "         [[ 8.8951e-03,  5.7356e-02,  2.6403e-02],\n",
      "          [ 1.1244e-02,  4.2789e-02,  8.0278e-02],\n",
      "          [ 5.1835e-02,  8.6424e-02,  3.7089e-02]],\n",
      "\n",
      "         [[-5.7207e-02, -9.7138e-02, -1.2938e-01],\n",
      "          [ 6.1122e-02,  9.0252e-03,  3.2589e-02],\n",
      "          [-2.1934e-02,  5.6936e-02,  9.4172e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8351e-02, -4.9005e-02, -5.1000e-02],\n",
      "          [ 3.4035e-03, -4.2368e-02, -7.5396e-02],\n",
      "          [-5.4641e-02, -8.7565e-03, -3.7534e-02]],\n",
      "\n",
      "         [[ 2.1401e-02,  1.8282e-02,  7.8780e-02],\n",
      "          [ 5.4702e-02,  4.6534e-02,  7.1562e-02],\n",
      "          [ 4.5271e-02,  5.1188e-04,  5.4424e-03]],\n",
      "\n",
      "         [[ 4.9532e-02,  3.1763e-02,  3.1090e-02],\n",
      "          [ 8.3513e-02,  4.6507e-02,  5.0751e-02],\n",
      "          [ 6.9677e-02, -6.6060e-02, -3.4521e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0069e-03, -9.7768e-02, -1.3200e-01],\n",
      "          [ 1.1612e-01, -2.9365e-02, -4.9472e-02],\n",
      "          [ 1.5348e-01,  2.2453e-02,  1.4432e-02]],\n",
      "\n",
      "         [[-1.2098e-01, -6.3190e-02, -2.3475e-02],\n",
      "          [-4.3154e-02,  2.5321e-03,  1.9423e-02],\n",
      "          [-5.1291e-03,  3.4478e-02,  6.6924e-02]],\n",
      "\n",
      "         [[-3.8497e-02,  3.5438e-02,  8.6134e-02],\n",
      "          [ 4.6340e-03,  1.8075e-02,  9.3160e-02],\n",
      "          [ 2.6280e-02,  7.5581e-02,  1.1370e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2036e-02,  2.1857e-03,  1.2765e-01],\n",
      "          [ 9.3767e-02,  7.4899e-02,  6.1974e-02],\n",
      "          [ 1.0400e-01,  6.3834e-02,  5.9788e-02]],\n",
      "\n",
      "         [[-9.4054e-03, -7.9465e-02,  4.3660e-02],\n",
      "          [ 1.2531e-02, -4.0305e-02, -7.2494e-02],\n",
      "          [ 2.0962e-02, -7.7167e-02, -8.1526e-02]],\n",
      "\n",
      "         [[-9.7983e-02, -8.7998e-02, -4.2500e-02],\n",
      "          [-1.2536e-01, -7.3483e-02, -2.3069e-02],\n",
      "          [-1.0861e-01, -5.4141e-02,  1.8095e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3429e-02,  1.3839e-02, -4.7136e-02],\n",
      "          [-1.2678e-02, -3.7308e-02, -6.0929e-03],\n",
      "          [-6.0259e-02, -1.1115e-01, -3.2513e-02]],\n",
      "\n",
      "         [[-9.4118e-02, -1.0121e-01, -7.3127e-02],\n",
      "          [-1.2552e-01, -1.1424e-01, -1.0506e-01],\n",
      "          [-8.3852e-02, -6.7868e-02, -5.9884e-02]],\n",
      "\n",
      "         [[ 3.0682e-02,  1.9508e-02,  1.7103e-02],\n",
      "          [-8.5010e-02, -9.8061e-02,  1.2283e-02],\n",
      "          [-1.1170e-01, -1.4609e-01, -7.2906e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0704e-03,  7.0891e-02,  6.6265e-02],\n",
      "          [ 3.1903e-02,  1.0788e-01,  5.4343e-02],\n",
      "          [ 5.7261e-02,  9.4061e-02,  6.3131e-02]],\n",
      "\n",
      "         [[ 1.1120e-01, -5.9335e-03,  4.5907e-02],\n",
      "          [ 1.1824e-01,  2.5387e-02,  7.5634e-02],\n",
      "          [ 7.2784e-02,  7.6822e-02,  1.1169e-01]],\n",
      "\n",
      "         [[-1.0468e-01, -1.7221e-01, -1.2221e-01],\n",
      "          [-9.5812e-02, -1.4506e-01, -8.0496e-02],\n",
      "          [-1.0558e-01, -1.6526e-01, -1.4846e-01]]]])\n",
      "rescnn_layers.3.cnn2.bias torch.Size([64])\n",
      "tensor([ 0.0236,  0.0826, -0.1467,  0.1186, -0.0292,  0.0676, -0.0580,  0.1264,\n",
      "         0.0692, -0.1072,  0.1494, -0.0921, -0.1065,  0.0764,  0.0249, -0.0037,\n",
      "         0.1700,  0.0190, -0.0153,  0.0394, -0.0249,  0.0337,  0.0779, -0.0003,\n",
      "         0.0265, -0.0711,  0.0091,  0.0617,  0.0310,  0.1135,  0.1342, -0.0913,\n",
      "        -0.0031, -0.0308,  0.0162,  0.0376, -0.1246,  0.0603,  0.0637,  0.0466,\n",
      "        -0.0918,  0.0619,  0.0090,  0.0739, -0.0278, -0.0125, -0.1076, -0.0915,\n",
      "         0.0735, -0.1155,  0.0442,  0.1215, -0.0244, -0.0729,  0.0108, -0.1933,\n",
      "         0.0299, -0.0185, -0.0534, -0.1097,  0.0300, -0.0977,  0.0067, -0.0508])\n",
      "rescnn_layers.3.layer_norm1.layer_norm.weight torch.Size([64])\n",
      "tensor([1.1419, 1.0835, 1.0124, 1.1018, 1.0586, 0.9852, 0.9996, 0.9448, 0.9856,\n",
      "        0.9187, 0.9588, 0.8860, 0.8716, 0.9498, 0.9279, 0.9354, 0.9384, 0.9358,\n",
      "        0.9398, 1.0164, 0.9917, 1.0643, 1.0516, 1.0141, 1.0522, 1.0543, 1.0498,\n",
      "        1.0857, 1.0508, 0.9924, 1.0018, 1.0206, 1.0132, 0.9845, 0.9978, 1.0308,\n",
      "        1.0191, 1.1129, 1.0507, 1.1052, 1.0915, 1.0272, 1.0543, 1.0031, 1.0208,\n",
      "        1.1269, 1.0687, 1.0423, 1.0960, 1.1537, 1.1690, 1.0348, 1.0767, 1.0529,\n",
      "        1.0501, 1.0704, 1.0930, 0.9801, 0.9994, 1.0187, 0.9941, 0.9454, 0.9810,\n",
      "        1.0911])\n",
      "rescnn_layers.3.layer_norm1.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.1472,  0.0764, -0.0801, -0.0295,  0.0196,  0.0110, -0.0072,  0.0034,\n",
      "        -0.0015, -0.0083,  0.0347,  0.0159, -0.0699, -0.0163, -0.0298, -0.0162,\n",
      "        -0.0106, -0.0151, -0.0841, -0.0644, -0.0820, -0.0841, -0.0965, -0.1440,\n",
      "        -0.1034, -0.0631, -0.0492, -0.0216, -0.0854, -0.1002, -0.1184, -0.1132,\n",
      "        -0.0676, -0.0773, -0.0533, -0.0203, -0.0461,  0.0056, -0.0014,  0.0185,\n",
      "         0.0407, -0.0152, -0.0034, -0.0095,  0.0116,  0.0337, -0.0251,  0.0036,\n",
      "         0.0424,  0.0978,  0.0869, -0.0057,  0.0312,  0.0397,  0.0301,  0.0417,\n",
      "         0.0807,  0.0342,  0.0721,  0.0634,  0.0095, -0.0405, -0.0400,  0.0291])\n",
      "rescnn_layers.3.layer_norm2.layer_norm.weight torch.Size([64])\n",
      "tensor([1.0346, 1.0085, 0.9941, 1.0171, 0.9962, 0.9934, 1.0234, 1.0574, 1.0629,\n",
      "        1.0376, 1.0333, 1.0484, 1.0759, 1.0756, 1.0432, 1.0375, 1.0250, 0.9777,\n",
      "        0.9440, 0.9769, 0.9924, 1.0432, 0.9812, 0.9638, 0.9489, 0.9314, 0.9434,\n",
      "        1.0309, 1.0173, 0.9997, 1.0306, 1.0002, 0.9764, 0.9312, 0.9300, 0.9297,\n",
      "        0.9795, 1.0364, 1.0002, 1.0076, 0.9983, 0.9925, 0.9650, 0.9592, 0.9681,\n",
      "        0.9622, 0.9762, 0.9553, 0.9359, 0.9661, 0.9601, 0.9029, 0.9037, 0.9567,\n",
      "        0.8421, 0.8630, 0.8197, 0.8210, 0.8158, 0.8533, 0.8679, 0.8747, 0.9593,\n",
      "        1.0019])\n",
      "rescnn_layers.3.layer_norm2.layer_norm.bias torch.Size([64])\n",
      "tensor([ 0.0350,  0.0301, -0.0188, -0.0587, -0.0321, -0.0820, -0.0495, -0.0512,\n",
      "        -0.0518, -0.0434, -0.0535, -0.0918, -0.0759, -0.0768, -0.0939, -0.1231,\n",
      "        -0.1229, -0.1108, -0.1625, -0.1802, -0.1971, -0.1702, -0.2281, -0.2571,\n",
      "        -0.2246, -0.2135, -0.1925, -0.1621, -0.2135, -0.1848, -0.2215, -0.1925,\n",
      "        -0.1634, -0.2134, -0.1679, -0.1686, -0.1721, -0.1358, -0.1481, -0.1567,\n",
      "        -0.1806, -0.1542, -0.1770, -0.2047, -0.2034, -0.2177, -0.2074, -0.2239,\n",
      "        -0.2535, -0.2447, -0.2072, -0.2143, -0.2274, -0.1792, -0.1655, -0.1315,\n",
      "        -0.1192, -0.1664, -0.1557, -0.1610, -0.1895, -0.2030, -0.1326, -0.1034])\n",
      "fully_connected.weight torch.Size([512, 4096])\n",
      "tensor([[ 0.0471, -0.0119, -0.0126,  ...,  0.0010, -0.0172,  0.0104],\n",
      "        [-0.1120, -0.0724, -0.0971,  ..., -0.1049, -0.1205, -0.1110],\n",
      "        [ 0.0587,  0.0571,  0.0567,  ..., -0.0976, -0.0970, -0.1276],\n",
      "        ...,\n",
      "        [ 0.0399,  0.0783,  0.0496,  ..., -0.0725, -0.0342, -0.0083],\n",
      "        [ 0.1459,  0.1096,  0.0202,  ...,  0.0229, -0.0100, -0.0861],\n",
      "        [-0.0516, -0.1062, -0.0901,  ...,  0.0136,  0.0438,  0.0873]])\n",
      "fully_connected.bias torch.Size([512])\n",
      "tensor([ 3.2335e-02,  5.4675e-02,  1.2023e-03, -2.9473e-02, -2.1040e-02,\n",
      "        -6.7584e-02, -7.8663e-02, -9.0847e-02,  7.8098e-04,  6.0234e-02,\n",
      "         1.0030e-02,  1.7840e-02,  3.0811e-02,  1.0063e-01,  7.7384e-02,\n",
      "        -1.6556e-02, -4.4799e-03,  2.2697e-02, -8.0384e-02,  2.9523e-02,\n",
      "         6.4906e-03,  8.6840e-02,  1.3613e-02,  9.1502e-02,  4.9767e-02,\n",
      "         3.3593e-02, -3.0946e-02,  6.6465e-02,  5.3748e-02, -3.9973e-02,\n",
      "        -1.2309e-03,  6.4537e-02,  4.1011e-03,  7.4065e-02,  1.0687e-02,\n",
      "         6.3493e-03,  5.0310e-02,  4.0547e-02,  2.6518e-03,  6.6098e-02,\n",
      "         6.6850e-02, -4.8177e-02, -9.5878e-02,  2.0507e-02,  2.0823e-02,\n",
      "         1.7781e-02, -9.1941e-05, -1.7190e-02, -5.6130e-02, -2.7619e-02,\n",
      "         7.0611e-02,  6.8563e-02, -5.9527e-03,  2.5798e-02, -1.7929e-03,\n",
      "        -1.9288e-03,  7.7471e-02,  5.7199e-02, -5.5020e-02,  5.3758e-02,\n",
      "         4.8035e-02,  8.7321e-02,  1.1677e-02, -5.9209e-02,  8.8624e-02,\n",
      "         6.1898e-02,  2.2160e-02, -7.5302e-02, -7.5190e-03, -2.7096e-02,\n",
      "         3.0294e-02,  3.7475e-02, -4.0171e-02, -5.6276e-03, -2.9901e-03,\n",
      "        -2.2498e-02,  2.7285e-02, -5.8073e-02, -2.4402e-02, -4.3731e-02,\n",
      "         3.3722e-02,  2.9530e-03,  4.1421e-02,  3.4903e-02,  2.8346e-02,\n",
      "         4.5946e-02,  3.3601e-02,  4.7388e-02,  1.1441e-02,  4.9146e-02,\n",
      "         1.1914e-02,  7.6116e-02, -5.9756e-02,  8.7160e-03, -2.3241e-04,\n",
      "        -2.3593e-02,  2.9356e-02, -2.5211e-03, -2.9056e-02,  5.5879e-02,\n",
      "         1.3156e-02,  4.3160e-03, -5.6929e-02, -7.1984e-03, -5.7507e-02,\n",
      "         1.0146e-01,  7.0351e-02, -1.4612e-02, -5.8787e-02,  8.1666e-02,\n",
      "         2.3059e-03, -1.8739e-02, -2.7786e-03,  7.7050e-02,  3.5214e-02,\n",
      "         1.9558e-02,  6.7528e-02,  5.6623e-02,  2.6237e-02, -5.1717e-02,\n",
      "        -1.0930e-02, -4.3558e-02,  3.8333e-02,  7.1955e-03, -5.6604e-03,\n",
      "         3.5241e-02,  3.5959e-02,  8.2397e-02, -8.9100e-03,  3.6425e-02,\n",
      "         1.2184e-02,  6.8460e-02,  8.5475e-03,  8.9800e-02, -8.1149e-03,\n",
      "         7.7851e-02,  9.1942e-02, -5.8177e-03, -3.4203e-02,  1.0935e-01,\n",
      "         1.5618e-02, -2.0854e-02, -2.8525e-02,  4.4118e-02,  2.6925e-02,\n",
      "         7.0380e-02,  2.8456e-04, -6.3284e-02, -4.1335e-03, -5.0526e-02,\n",
      "        -3.5433e-02,  2.0754e-02,  3.2423e-02,  4.4622e-02, -4.2897e-02,\n",
      "        -2.8070e-03, -4.1436e-02,  5.1353e-02, -1.8036e-02, -1.0280e-03,\n",
      "        -1.7516e-02, -1.0002e-01,  9.7937e-02,  2.2362e-02, -5.6123e-03,\n",
      "         1.7243e-02, -2.9091e-02, -7.0138e-03, -2.5011e-02,  4.2319e-02,\n",
      "        -5.8742e-02, -6.9785e-02,  2.4504e-02,  9.3008e-02,  5.9272e-02,\n",
      "         9.6117e-03, -1.5045e-02,  4.1111e-02,  6.0865e-03, -8.0235e-02,\n",
      "        -1.2405e-02,  6.0783e-02, -2.4008e-02, -4.0011e-02,  1.4043e-01,\n",
      "         9.2974e-02, -1.0992e-02,  1.0027e-01,  2.1021e-02, -2.0047e-02,\n",
      "         5.2660e-02,  8.8181e-02,  7.1456e-02,  1.4041e-01, -6.3597e-02,\n",
      "         5.5561e-02,  3.8773e-02,  8.2010e-03,  1.7259e-02,  7.6088e-03,\n",
      "         1.0407e-01, -3.4327e-02,  1.8493e-02, -2.7897e-02, -1.9754e-02,\n",
      "        -5.6907e-02,  8.6173e-02,  1.1566e-01,  5.7195e-02, -1.1174e-02,\n",
      "        -7.1352e-02,  4.1432e-02,  4.7576e-02,  4.5041e-02,  1.9228e-02,\n",
      "         6.8984e-02, -2.9222e-02, -1.3522e-02,  4.8507e-02, -4.1198e-02,\n",
      "         6.8173e-02, -2.7577e-02, -7.9414e-02,  4.6954e-02, -6.1282e-02,\n",
      "         9.7858e-03,  7.5223e-02,  2.9097e-02,  3.1491e-02,  3.7866e-02,\n",
      "         3.9324e-02,  8.7874e-03, -6.0706e-02,  5.5934e-02,  2.8578e-02,\n",
      "         3.1717e-02, -6.3130e-02,  1.0511e-01, -3.6924e-02,  5.8177e-02,\n",
      "         5.0919e-02, -1.7254e-02, -6.5887e-02, -2.5378e-02, -1.0742e-02,\n",
      "        -3.9038e-03, -1.3151e-02,  5.6859e-02,  6.3871e-02,  2.1567e-02,\n",
      "        -3.4938e-02,  9.9188e-02, -3.4761e-02, -6.1382e-02,  5.1604e-02,\n",
      "         1.3729e-02, -3.8108e-02,  3.8527e-02,  4.5251e-02, -3.8811e-02,\n",
      "         5.6533e-02,  5.8126e-02,  3.1442e-02,  6.6073e-02, -1.1779e-01,\n",
      "         2.5864e-02,  1.6364e-02, -3.0197e-02, -2.2688e-02, -4.7109e-02,\n",
      "        -4.1087e-02,  2.6220e-02, -3.8199e-02,  7.5542e-02, -4.9094e-02,\n",
      "         1.9614e-02, -1.9929e-02,  2.1529e-02, -7.8362e-02,  1.4441e-01,\n",
      "         1.4367e-02,  7.8431e-03,  6.7643e-02,  5.2319e-02, -4.7038e-03,\n",
      "         8.1727e-02, -2.5319e-03,  1.5903e-02,  7.4721e-02,  8.0121e-03,\n",
      "         1.9286e-02,  2.6815e-02,  1.1265e-01, -1.8165e-02, -3.2091e-02,\n",
      "        -4.6645e-02,  7.1510e-02, -8.5775e-03, -1.9564e-03,  5.7921e-02,\n",
      "         5.7500e-02, -1.8114e-02,  8.7233e-02,  1.0532e-01,  1.6930e-02,\n",
      "         4.7983e-02,  6.9079e-02, -3.3609e-02,  2.0307e-02,  4.7664e-02,\n",
      "         2.2334e-02, -4.1463e-02,  5.8110e-02, -2.9745e-02, -1.9620e-02,\n",
      "        -3.9479e-02,  2.5007e-03,  4.1848e-02,  2.2930e-02,  2.5275e-02,\n",
      "         6.8066e-02, -5.9886e-02,  1.1259e-01,  7.3454e-02,  6.5846e-02,\n",
      "        -5.9014e-03,  1.0153e-01, -2.8686e-02, -4.3136e-02,  3.1473e-03,\n",
      "        -9.3263e-03, -9.1158e-02,  9.2077e-03, -4.2428e-02,  3.0694e-02,\n",
      "         3.5082e-02,  1.0290e-01,  1.0351e-02, -3.1594e-02, -3.3575e-02,\n",
      "        -7.0832e-02,  8.9182e-02,  1.2901e-02, -5.2401e-02, -4.6776e-02,\n",
      "         1.3770e-01, -5.4551e-02, -4.7585e-02,  5.2097e-03, -3.0116e-02,\n",
      "         1.1772e-02,  5.5558e-02,  4.7761e-02,  4.2560e-02, -1.6363e-02,\n",
      "        -2.5774e-02,  3.3113e-02, -8.8588e-03, -4.2873e-02, -6.9394e-03,\n",
      "         6.6175e-02,  6.3367e-02,  4.6558e-02,  1.3616e-03, -4.7215e-02,\n",
      "         4.2956e-02, -9.3053e-02,  6.9128e-02,  7.2664e-03, -4.4448e-02,\n",
      "        -9.6878e-02,  7.3146e-02, -1.0063e-01,  3.3964e-02,  6.8763e-02,\n",
      "         2.3605e-02, -1.3585e-02,  2.0347e-02,  1.2950e-01,  4.1501e-02,\n",
      "        -6.2204e-02,  4.1827e-02,  5.3280e-02,  3.0629e-02, -6.3853e-02,\n",
      "        -8.6799e-02,  3.2857e-03, -4.2931e-02, -9.3707e-03,  3.9668e-02,\n",
      "        -8.0552e-02, -3.7765e-02, -3.0216e-02, -7.6829e-02, -8.7216e-02,\n",
      "        -4.8838e-02,  4.4375e-02, -5.0909e-02, -1.8016e-02, -1.0347e-02,\n",
      "        -9.1811e-02,  5.5460e-02, -8.7773e-03, -7.6508e-03, -1.3200e-02,\n",
      "         1.0597e-01,  9.8177e-03,  4.9932e-02, -7.6639e-03,  5.1276e-02,\n",
      "         4.8575e-02,  5.0593e-02,  8.0468e-02,  2.1914e-02, -1.9310e-02,\n",
      "        -3.0695e-02, -2.9858e-02,  8.3250e-02, -4.4596e-02, -4.2966e-02,\n",
      "        -3.7270e-02,  5.7239e-02, -4.9952e-03, -6.4090e-02, -5.5306e-02,\n",
      "         2.3359e-02,  5.1580e-02,  8.2890e-03, -4.0787e-03, -6.7751e-03,\n",
      "        -8.2365e-02,  7.0654e-02, -1.9578e-02, -8.6593e-03, -2.6877e-02,\n",
      "         7.8049e-02, -2.9659e-02, -8.8613e-02,  2.2189e-02, -3.4782e-02,\n",
      "         1.0168e-01,  6.8357e-02, -1.2892e-02,  1.4641e-02, -9.1440e-03,\n",
      "         1.0594e-01,  7.6655e-02, -1.0056e-01,  8.4966e-02, -6.3221e-02,\n",
      "         1.7519e-02, -8.6116e-02,  9.9080e-03,  2.6546e-02, -2.7089e-02,\n",
      "        -8.7978e-03,  5.5060e-03,  4.0629e-02,  5.6198e-02, -6.8813e-02,\n",
      "         1.5613e-02, -3.3347e-02,  1.2409e-02, -4.1125e-02, -5.9959e-03,\n",
      "         9.0139e-03, -2.5934e-02,  2.8701e-02,  1.2593e-01, -1.0198e-02,\n",
      "         1.7403e-02,  1.2198e-05, -7.9129e-03,  1.6103e-02,  1.0043e-01,\n",
      "         2.5198e-02,  2.5781e-02, -1.2259e-02, -2.0949e-02, -7.1564e-02,\n",
      "         1.9799e-02, -9.4540e-02,  9.2554e-02, -4.3558e-02,  6.8439e-03,\n",
      "         3.4612e-03,  8.1589e-02,  3.6192e-02,  4.3421e-02,  1.1313e-01,\n",
      "         1.0262e-01,  5.1815e-02,  6.4323e-02,  2.0935e-02,  3.8119e-02,\n",
      "        -1.0651e-01,  1.0785e-01,  3.7506e-02, -9.0016e-02, -1.1324e-02,\n",
      "         3.2049e-02,  8.0389e-02,  2.7977e-02, -8.5359e-02,  8.8482e-02,\n",
      "        -1.3443e-02, -1.5320e-02,  7.3164e-02, -7.0057e-03, -5.0559e-02,\n",
      "         3.5507e-03, -4.7592e-02])\n",
      "birnn_layers.0.BiGRU.weight_ih_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0364, -0.0398,  0.0990,  ...,  0.0933,  0.0309,  0.0462],\n",
      "        [-0.0004, -0.0678, -0.0738,  ..., -0.0904, -0.1007,  0.0682],\n",
      "        [-0.0805,  0.1138,  0.0677,  ...,  0.0611, -0.0860, -0.1415],\n",
      "        ...,\n",
      "        [ 0.0652,  0.1942, -0.0245,  ..., -0.0592, -0.0079, -0.0507],\n",
      "        [ 0.0472, -0.1298, -0.1192,  ..., -0.0177,  0.0241, -0.0341],\n",
      "        [ 0.0153,  0.0036, -0.1699,  ..., -0.2150, -0.0404, -0.1017]])\n",
      "birnn_layers.0.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.1229,  0.0685, -0.0007,  ...,  0.0091, -0.0511, -0.1752],\n",
      "        [-0.0450, -0.1500,  0.1576,  ...,  0.0400,  0.0356,  0.0044],\n",
      "        [ 0.0459,  0.0578,  0.1026,  ...,  0.0686, -0.0176,  0.0926],\n",
      "        ...,\n",
      "        [-0.0310, -0.0537, -0.1594,  ..., -0.1423, -0.0835,  0.0529],\n",
      "        [-0.0242,  0.1419,  0.0142,  ...,  0.1108,  0.1386,  0.2034],\n",
      "        [-0.0643,  0.1054, -0.0113,  ..., -0.0358, -0.1075,  0.0164]])\n",
      "birnn_layers.0.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([ 0.1740, -0.0686,  0.0043,  ..., -0.0151, -0.0724,  0.0093])\n",
      "birnn_layers.0.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([ 0.1453, -0.1101, -0.0466,  ...,  0.0113, -0.1087,  0.0242])\n",
      "birnn_layers.0.BiGRU.weight_ih_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[-0.0032, -0.1211, -0.0111,  ...,  0.0337,  0.0543,  0.0109],\n",
      "        [ 0.0552, -0.0649, -0.1692,  ...,  0.0952,  0.0060,  0.1333],\n",
      "        [ 0.0211,  0.0698, -0.0778,  ..., -0.0134,  0.0287,  0.0170],\n",
      "        ...,\n",
      "        [ 0.0491,  0.0286,  0.0559,  ...,  0.0712,  0.2174, -0.0929],\n",
      "        [ 0.0217,  0.0313,  0.1208,  ..., -0.0026,  0.0809, -0.0260],\n",
      "        [-0.0335, -0.0634, -0.0643,  ...,  0.1446,  0.1536,  0.1802]])\n",
      "birnn_layers.0.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0209, -0.0498,  0.1651,  ..., -0.0362, -0.0122, -0.0187],\n",
      "        [-0.0182,  0.1768, -0.0779,  ...,  0.0324, -0.0685,  0.0647],\n",
      "        [ 0.0232, -0.0109,  0.0031,  ...,  0.0582,  0.0038,  0.0618],\n",
      "        ...,\n",
      "        [-0.0285, -0.1014,  0.0419,  ..., -0.0982,  0.0523,  0.0285],\n",
      "        [-0.1307, -0.0875, -0.0627,  ...,  0.1195,  0.0085,  0.0286],\n",
      "        [-0.0058,  0.0578,  0.0606,  ...,  0.0820,  0.0620, -0.1391]])\n",
      "birnn_layers.0.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0090, -0.0164,  0.0789,  ...,  0.0142, -0.0761,  0.0159])\n",
      "birnn_layers.0.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([ 0.0403,  0.0454,  0.0512,  ..., -0.0441, -0.0082, -0.0516])\n",
      "birnn_layers.0.layer_norm.weight torch.Size([512])\n",
      "tensor([0.8492, 1.1129, 1.0210, 1.0241, 1.0918, 1.1598, 0.9579, 0.8984, 1.0593,\n",
      "        0.9685, 1.0013, 0.9928, 0.9555, 1.0907, 0.9485, 0.9533, 0.9241, 1.0265,\n",
      "        0.9888, 0.9061, 0.8793, 0.8868, 1.0783, 0.8583, 1.0659, 0.8932, 0.8824,\n",
      "        0.9223, 0.9441, 1.0029, 0.8867, 0.9398, 0.9959, 0.9056, 1.0571, 1.0143,\n",
      "        0.9095, 0.9720, 0.9787, 0.8846, 0.8921, 1.1129, 1.1391, 0.8893, 0.8856,\n",
      "        0.9835, 0.9685, 0.9863, 0.9924, 0.9763, 0.9828, 0.9255, 1.1263, 0.9988,\n",
      "        1.0325, 0.8643, 0.9537, 0.9021, 1.0148, 0.9863, 1.0130, 0.8617, 0.9801,\n",
      "        0.9303, 0.8344, 0.8103, 0.8753, 1.1892, 1.0209, 0.9252, 0.9418, 1.1473,\n",
      "        1.1248, 1.1092, 0.9552, 1.0016, 0.9207, 1.1376, 0.9947, 0.9606, 0.9378,\n",
      "        0.9471, 0.9596, 0.8825, 0.9912, 0.9648, 0.9249, 1.1051, 0.9011, 1.0406,\n",
      "        0.9036, 0.8522, 1.1919, 1.0760, 0.9173, 1.1293, 1.0629, 0.9477, 0.9478,\n",
      "        0.9529, 1.0710, 0.9491, 1.1158, 0.9219, 0.9194, 0.8821, 0.9509, 1.0008,\n",
      "        1.1668, 1.0325, 0.9711, 0.9054, 1.0940, 0.9885, 0.9295, 0.8762, 0.9957,\n",
      "        0.9534, 0.9273, 1.0370, 0.9507, 1.1511, 0.9448, 1.0670, 1.0611, 1.0075,\n",
      "        1.0256, 0.9184, 1.0031, 1.0045, 0.9651, 0.8783, 1.1192, 0.9424, 0.9903,\n",
      "        0.8398, 0.8032, 0.9764, 0.9150, 0.7570, 1.1125, 0.9726, 0.8798, 1.1751,\n",
      "        0.9975, 0.8890, 1.0608, 1.0983, 1.0754, 1.0601, 1.0846, 0.8680, 0.9650,\n",
      "        0.8364, 0.9031, 1.0270, 0.9548, 1.0356, 1.0357, 0.9686, 1.1308, 0.9688,\n",
      "        0.8963, 1.1046, 1.0554, 0.9216, 0.9193, 1.0788, 1.0793, 0.9304, 1.0946,\n",
      "        0.9857, 0.9725, 0.9163, 0.9139, 0.9889, 1.0493, 1.0280, 1.0212, 1.1593,\n",
      "        0.8803, 0.9070, 0.9589, 1.1115, 0.8396, 0.8853, 0.9046, 0.9255, 0.9474,\n",
      "        1.2481, 0.9784, 0.7983, 0.8707, 0.8578, 1.0787, 0.9013, 0.9857, 1.0014,\n",
      "        1.0378, 0.9521, 0.8890, 0.9832, 0.8689, 0.9318, 1.0842, 1.1168, 0.9066,\n",
      "        0.8804, 0.9785, 1.0063, 1.1872, 0.9846, 0.9672, 0.9473, 0.9866, 0.9055,\n",
      "        0.8909, 1.0193, 0.9504, 1.1475, 1.0053, 0.9913, 1.1118, 1.0794, 1.1064,\n",
      "        0.9297, 0.9508, 1.0182, 0.9447, 0.9716, 0.9964, 0.9081, 1.0951, 0.7945,\n",
      "        0.9954, 1.0935, 0.9084, 0.9045, 0.9114, 1.0402, 1.0167, 1.0717, 0.8925,\n",
      "        0.9953, 1.0045, 1.0126, 1.0875, 0.9841, 0.8945, 1.0200, 0.9008, 0.9082,\n",
      "        1.0594, 1.0546, 0.8315, 1.0505, 1.0700, 0.9008, 0.8156, 1.1074, 0.8218,\n",
      "        1.1637, 1.0098, 1.0487, 1.0370, 0.9520, 1.1340, 0.8927, 1.0071, 0.9159,\n",
      "        0.9532, 0.8156, 0.8700, 0.8343, 0.9992, 1.0646, 0.9826, 0.9497, 1.1662,\n",
      "        0.6908, 1.0126, 1.0470, 0.9340, 1.0249, 1.0274, 0.8996, 1.0905, 0.8477,\n",
      "        1.0272, 1.0592, 0.9321, 1.0286, 0.8330, 1.0552, 1.1052, 1.0429, 0.9153,\n",
      "        0.9284, 0.9684, 0.9693, 0.9155, 1.0440, 0.9284, 0.9633, 1.1672, 1.0481,\n",
      "        0.9572, 1.0821, 0.9641, 1.0106, 0.9243, 1.0396, 0.9719, 1.0667, 1.0352,\n",
      "        1.0070, 1.0251, 0.9619, 0.9136, 0.9238, 0.8187, 0.9040, 0.8177, 0.8907,\n",
      "        0.8480, 0.9686, 0.9008, 1.0701, 0.9231, 1.1096, 1.0590, 0.8924, 1.0291,\n",
      "        1.0425, 1.2134, 0.9075, 0.8694, 0.9328, 0.9649, 0.9595, 1.0249, 0.9009,\n",
      "        0.9462, 1.0663, 1.1302, 0.8362, 1.0735, 0.9802, 1.0729, 1.0790, 0.9523,\n",
      "        0.9066, 0.9769, 1.0068, 0.8585, 1.0385, 1.0016, 1.0384, 1.0897, 1.0043,\n",
      "        0.9521, 0.9454, 0.9136, 0.9961, 1.1533, 1.0382, 1.0708, 0.9626, 1.0789,\n",
      "        1.0697, 0.9625, 0.9134, 1.1572, 0.9303, 0.7515, 1.0271, 0.9673, 0.9977,\n",
      "        0.9351, 0.9026, 1.1111, 1.0845, 1.0431, 1.0180, 0.9841, 0.9675, 1.0818,\n",
      "        0.8958, 1.0517, 0.9984, 1.2023, 1.0828, 1.0265, 0.8973, 1.0640, 0.9954,\n",
      "        0.7729, 0.9407, 1.0495, 1.0853, 1.1005, 0.7768, 0.9296, 0.9751, 1.1191,\n",
      "        0.9134, 0.9793, 0.9012, 0.9871, 0.9371, 0.9794, 0.8847, 0.8122, 0.8704,\n",
      "        1.0156, 0.9521, 0.9643, 0.7973, 1.0204, 0.9471, 1.1003, 0.8563, 0.9806,\n",
      "        0.9797, 1.0415, 0.9856, 1.0937, 0.9963, 1.0733, 0.7980, 1.0774, 0.9891,\n",
      "        0.8914, 1.0946, 0.9207, 0.7533, 0.9703, 1.0680, 1.0911, 1.1065, 0.8061,\n",
      "        0.9211, 1.0053, 0.9608, 0.9448, 0.8516, 0.9045, 1.0283, 0.9666, 0.9102,\n",
      "        1.0804, 0.9134, 0.8253, 1.0053, 0.9738, 1.0117, 1.0672, 0.9845, 0.9324,\n",
      "        0.9254, 1.0012, 1.0369, 0.9194, 0.9985, 1.0068, 1.1120, 1.0478, 0.8816,\n",
      "        0.7632, 0.9899, 0.9328, 0.9772, 0.9584, 0.9339, 0.8221, 0.9557, 1.0194,\n",
      "        1.0427, 1.0377, 1.0839, 1.1211, 0.9700, 1.0360, 1.0304, 0.8559, 1.0813,\n",
      "        0.8085, 0.8702, 0.9702, 0.9548, 0.7297, 0.9744, 0.8769, 1.0798, 0.9022,\n",
      "        1.1051, 1.0662, 0.9474, 1.0625, 0.9989, 0.9302, 0.8686, 0.9739, 0.9726,\n",
      "        0.9315, 1.0269, 1.0341, 0.8116, 0.9858, 1.0241, 1.0348, 1.1194])\n",
      "birnn_layers.0.layer_norm.bias torch.Size([512])\n",
      "tensor([-0.2656, -0.2072, -0.2909, -0.3151, -0.2651, -0.2221, -0.2865, -0.3353,\n",
      "        -0.2243, -0.2626, -0.2646, -0.2383, -0.2864, -0.2369, -0.2523, -0.2600,\n",
      "        -0.3665, -0.2521, -0.3591, -0.3547, -0.3524, -0.3047, -0.2153, -0.2894,\n",
      "        -0.2701, -0.3196, -0.3338, -0.3250, -0.2454, -0.3366, -0.2974, -0.3225,\n",
      "        -0.2736, -0.3160, -0.2077, -0.2500, -0.2779, -0.2646, -0.3097, -0.3410,\n",
      "        -0.3152, -0.3094, -0.2119, -0.3860, -0.3376, -0.3330, -0.2911, -0.3552,\n",
      "        -0.3152, -0.3195, -0.3402, -0.2931, -0.1839, -0.2572, -0.2580, -0.3511,\n",
      "        -0.2507, -0.3243, -0.3166, -0.3245, -0.2605, -0.3456, -0.3255, -0.2955,\n",
      "        -0.3005, -0.3014, -0.3531, -0.2644, -0.3249, -0.3177, -0.2836, -0.1400,\n",
      "        -0.2745, -0.2064, -0.3911, -0.3028, -0.3433, -0.2810, -0.2261, -0.3424,\n",
      "        -0.2492, -0.2730, -0.3057, -0.3300, -0.3003, -0.2815, -0.3004, -0.2572,\n",
      "        -0.3231, -0.2022, -0.3242, -0.3088, -0.2235, -0.2180, -0.2969, -0.2221,\n",
      "        -0.2536, -0.2975, -0.3366, -0.3165, -0.2276, -0.3434, -0.2694, -0.3033,\n",
      "        -0.3310, -0.2612, -0.2445, -0.3120, -0.2581, -0.2819, -0.2779, -0.3924,\n",
      "        -0.2640, -0.2695, -0.3180, -0.3163, -0.2871, -0.3178, -0.3305, -0.2208,\n",
      "        -0.3022, -0.2310, -0.3151, -0.3043, -0.2426, -0.3037, -0.2598, -0.3021,\n",
      "        -0.3177, -0.2894, -0.2711, -0.3377, -0.2590, -0.2963, -0.2977, -0.3373,\n",
      "        -0.2919, -0.3125, -0.3467, -0.3205, -0.2313, -0.2751, -0.3525, -0.2117,\n",
      "        -0.2745, -0.3228, -0.2453, -0.2427, -0.3135, -0.2302, -0.2530, -0.3182,\n",
      "        -0.3349, -0.3385, -0.3293, -0.2741, -0.3619, -0.2541, -0.1896, -0.2967,\n",
      "        -0.2475, -0.3789, -0.2741, -0.2143, -0.2158, -0.3379, -0.3131, -0.2883,\n",
      "        -0.2894, -0.2991, -0.3115, -0.3470, -0.3190, -0.3147, -0.2943, -0.2428,\n",
      "        -0.2244, -0.3012, -0.2482, -0.1911, -0.3466, -0.3201, -0.2842, -0.2310,\n",
      "        -0.2560, -0.2988, -0.3648, -0.2864, -0.2971, -0.2113, -0.3032, -0.2968,\n",
      "        -0.2387, -0.3096, -0.2467, -0.3155, -0.2778, -0.2802, -0.2747, -0.3084,\n",
      "        -0.3131, -0.3452, -0.3233, -0.3084, -0.2849, -0.2160, -0.2730, -0.2806,\n",
      "        -0.3134, -0.3099, -0.2765, -0.2493, -0.2539, -0.3212, -0.2865, -0.2725,\n",
      "        -0.3494, -0.2221, -0.3032, -0.2184, -0.3056, -0.3685, -0.2018, -0.2641,\n",
      "        -0.3140, -0.2865, -0.2786, -0.2512, -0.2401, -0.2785, -0.2570, -0.3681,\n",
      "        -0.2590, -0.2821, -0.2665, -0.2158, -0.2985, -0.3018, -0.3204, -0.2505,\n",
      "        -0.2241, -0.2802, -0.3348, -0.3254, -0.2921, -0.3100, -0.2613, -0.2267,\n",
      "        -0.3144, -0.2879, -0.3723, -0.3200, -0.2784, -0.2850, -0.3000, -0.2659,\n",
      "        -0.2509, -0.3201, -0.3346, -0.2315, -0.3246, -0.1639, -0.3144, -0.2165,\n",
      "        -0.2748, -0.2999, -0.2141, -0.3003, -0.2603, -0.2824, -0.3528, -0.3420,\n",
      "        -0.3653, -0.3101, -0.2855, -0.2100, -0.3167, -0.3461, -0.2162, -0.3289,\n",
      "        -0.2533, -0.2195, -0.3182, -0.3149, -0.3691, -0.3346, -0.2918, -0.3645,\n",
      "        -0.2457, -0.2950, -0.3114, -0.2933, -0.2907, -0.1926, -0.2616, -0.2981,\n",
      "        -0.2509, -0.3532, -0.3108, -0.2920, -0.3260, -0.3146, -0.2986, -0.2718,\n",
      "        -0.2012, -0.2705, -0.2754, -0.2483, -0.3084, -0.2480, -0.3336, -0.3574,\n",
      "        -0.3058, -0.2797, -0.2718, -0.3600, -0.2721, -0.3271, -0.2830, -0.3377,\n",
      "        -0.3374, -0.3629, -0.3328, -0.2914, -0.3731, -0.3111, -0.3075, -0.2084,\n",
      "        -0.3056, -0.2443, -0.2948, -0.2802, -0.3338, -0.2884, -0.2944, -0.3066,\n",
      "        -0.3246, -0.3282, -0.2387, -0.2679, -0.2410, -0.2670, -0.3024, -0.2689,\n",
      "        -0.2660, -0.3062, -0.2714, -0.3707, -0.2365, -0.2769, -0.3048, -0.3138,\n",
      "        -0.3179, -0.2366, -0.2912, -0.2791, -0.2549, -0.2918, -0.2255, -0.2380,\n",
      "        -0.3015, -0.2820, -0.3242, -0.3532, -0.2203, -0.2722, -0.2963, -0.2800,\n",
      "        -0.2489, -0.2320, -0.3093, -0.3093, -0.1885, -0.2896, -0.3307, -0.2147,\n",
      "        -0.3107, -0.2651, -0.2365, -0.2657, -0.2245, -0.2046, -0.2858, -0.3064,\n",
      "        -0.2944, -0.3093, -0.2456, -0.3338, -0.2714, -0.2690, -0.2241, -0.3019,\n",
      "        -0.2498, -0.3365, -0.3299, -0.3362, -0.3542, -0.3040, -0.3112, -0.2514,\n",
      "        -0.3162, -0.3245, -0.2845, -0.2845, -0.2304, -0.2663, -0.2875, -0.3554,\n",
      "        -0.3231, -0.3274, -0.2943, -0.3379, -0.3322, -0.3272, -0.2641, -0.2898,\n",
      "        -0.3238, -0.2955, -0.2647, -0.3189, -0.2582, -0.2964, -0.3037, -0.2837,\n",
      "        -0.2905, -0.2975, -0.2211, -0.3021, -0.3142, -0.3473, -0.2672, -0.3221,\n",
      "        -0.2937, -0.2345, -0.3402, -0.3386, -0.3729, -0.2810, -0.2693, -0.2220,\n",
      "        -0.2861, -0.3149, -0.3056, -0.3257, -0.2768, -0.3021, -0.3526, -0.2635,\n",
      "        -0.2874, -0.3302, -0.2621, -0.3059, -0.3507, -0.2652, -0.2668, -0.3322,\n",
      "        -0.2019, -0.3211, -0.2660, -0.2990, -0.2162, -0.2895, -0.3166, -0.3395,\n",
      "        -0.2280, -0.1987, -0.3031, -0.2600, -0.3479, -0.2482, -0.3520, -0.3372,\n",
      "        -0.2716, -0.3569, -0.2965, -0.2843, -0.2429, -0.2878, -0.2336, -0.2712,\n",
      "        -0.1935, -0.3066, -0.3161, -0.2737, -0.3539, -0.3303, -0.2781, -0.3172,\n",
      "        -0.3038, -0.2569, -0.3358, -0.2785, -0.3708, -0.2059, -0.3320, -0.2647,\n",
      "        -0.2526, -0.3120, -0.2968, -0.3004, -0.3076, -0.3242, -0.3584, -0.2903,\n",
      "        -0.3002, -0.2588, -0.3005, -0.2731, -0.2958, -0.2829, -0.2618, -0.2822])\n",
      "birnn_layers.1.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-4.0760e-02,  2.5850e-02,  3.3439e-02,  ...,  1.6925e-02,\n",
      "          5.2240e-02,  8.6242e-02],\n",
      "        [-5.4940e-02,  2.7746e-03, -5.6558e-02,  ..., -1.6685e-02,\n",
      "          1.9171e-04, -7.8785e-03],\n",
      "        [-1.5144e-02, -5.5330e-02, -7.6472e-02,  ..., -1.5813e-01,\n",
      "         -5.8863e-02, -3.5448e-02],\n",
      "        ...,\n",
      "        [ 2.5511e-02,  1.0087e-01, -1.8846e-01,  ..., -1.9757e-01,\n",
      "          1.1820e-01, -3.4641e-02],\n",
      "        [ 3.5886e-02,  2.6857e-02,  2.5839e-02,  ..., -5.6573e-02,\n",
      "         -8.8841e-03,  9.2914e-02],\n",
      "        [ 6.6649e-02, -9.8130e-03, -6.7730e-02,  ..., -1.2030e-01,\n",
      "         -1.3378e-01,  1.8698e-02]])\n",
      "birnn_layers.1.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[-0.0968,  0.0952, -0.0956,  ..., -0.0583, -0.0014,  0.0649],\n",
      "        [-0.0022,  0.0240, -0.0437,  ...,  0.0258,  0.0588,  0.0657],\n",
      "        [-0.1044,  0.0876, -0.0633,  ...,  0.1098,  0.0749,  0.0700],\n",
      "        ...,\n",
      "        [-0.1156, -0.0596,  0.0363,  ..., -0.0612,  0.0935,  0.0510],\n",
      "        [ 0.0410,  0.0771, -0.0008,  ..., -0.0213, -0.0456,  0.0260],\n",
      "        [ 0.1352,  0.1116,  0.0381,  ...,  0.0197, -0.0818,  0.0325]])\n",
      "birnn_layers.1.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0118, -0.0717, -0.0848,  ..., -0.0458, -0.0109, -0.0562])\n",
      "birnn_layers.1.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([ 0.0272, -0.1033, -0.0736,  ..., -0.0162, -0.0229, -0.0045])\n",
      "birnn_layers.1.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0318, -0.0851, -0.0815,  ..., -0.0505,  0.0120,  0.0125],\n",
      "        [-0.0427, -0.0460,  0.0212,  ..., -0.0116, -0.0056, -0.0422],\n",
      "        [-0.0860, -0.1137, -0.0410,  ..., -0.0980, -0.0123, -0.0068],\n",
      "        ...,\n",
      "        [-0.0099, -0.0026, -0.0438,  ..., -0.0839, -0.0232, -0.0492],\n",
      "        [-0.0739,  0.0157,  0.0959,  ...,  0.0468,  0.0357, -0.0006],\n",
      "        [-0.0440,  0.0167,  0.0335,  ...,  0.1472,  0.0213,  0.0315]])\n",
      "birnn_layers.1.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0374,  0.0327, -0.0563,  ..., -0.0177,  0.0108,  0.0889],\n",
      "        [ 0.0319, -0.0455, -0.0692,  ...,  0.0258,  0.0083,  0.0289],\n",
      "        [ 0.0434,  0.0602,  0.0209,  ..., -0.0076,  0.0397,  0.0543],\n",
      "        ...,\n",
      "        [ 0.0092, -0.0474, -0.1089,  ..., -0.0392, -0.0398,  0.0657],\n",
      "        [ 0.1336,  0.0599,  0.0464,  ..., -0.0087, -0.1221,  0.0197],\n",
      "        [ 0.0155,  0.0265, -0.0209,  ...,  0.0706, -0.1505, -0.2127]])\n",
      "birnn_layers.1.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.1111, -0.0725, -0.1104,  ...,  0.0569, -0.0073,  0.0484])\n",
      "birnn_layers.1.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0808, -0.1063, -0.0925,  ..., -0.0028,  0.0679,  0.0041])\n",
      "birnn_layers.1.layer_norm.weight torch.Size([1024])\n",
      "tensor([1.0723, 0.8115, 1.0616,  ..., 0.9304, 0.8759, 0.9804])\n",
      "birnn_layers.1.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0514, -0.1684, -0.0306,  ..., -0.0752, -0.0861, -0.0365])\n",
      "birnn_layers.2.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-0.1034, -0.0071, -0.0158,  ...,  0.0523, -0.1274, -0.0811],\n",
      "        [ 0.0908,  0.0086,  0.0523,  ...,  0.0434, -0.0040,  0.0354],\n",
      "        [-0.1450, -0.0481,  0.0034,  ..., -0.0133, -0.0193, -0.0234],\n",
      "        ...,\n",
      "        [-0.0311, -0.0777,  0.0117,  ..., -0.0175, -0.0002, -0.0723],\n",
      "        [-0.0757, -0.1066, -0.1465,  ..., -0.0529,  0.0158,  0.0574],\n",
      "        [-0.0056,  0.0003, -0.0148,  ...,  0.0122, -0.0465, -0.0229]])\n",
      "birnn_layers.2.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0162, -0.1385,  0.0093,  ..., -0.0103, -0.0655,  0.0159],\n",
      "        [ 0.0454, -0.0007,  0.0876,  ...,  0.0523,  0.0153, -0.0135],\n",
      "        [ 0.0168,  0.0762, -0.0349,  ...,  0.0498,  0.0479,  0.1164],\n",
      "        ...,\n",
      "        [-0.1119, -0.0379,  0.0369,  ..., -0.0895,  0.0394,  0.0645],\n",
      "        [ 0.1218,  0.0573,  0.0744,  ..., -0.0671, -0.0975,  0.0612],\n",
      "        [-0.0314,  0.0247,  0.0074,  ...,  0.0437,  0.0407, -0.0200]])\n",
      "birnn_layers.2.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0821,  0.0565, -0.1398,  ...,  0.0176, -0.0471, -0.0047])\n",
      "birnn_layers.2.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0668,  0.0110, -0.0747,  ..., -0.0407, -0.1050, -0.0136])\n",
      "birnn_layers.2.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0281,  0.0293,  0.0044,  ..., -0.0379, -0.0091, -0.0407],\n",
      "        [ 0.0846, -0.0756, -0.0894,  ..., -0.0319, -0.0560,  0.0481],\n",
      "        [-0.0535,  0.0422, -0.0514,  ..., -0.0536, -0.0419, -0.0180],\n",
      "        ...,\n",
      "        [-0.0081, -0.0263, -0.0233,  ..., -0.0430, -0.0040, -0.0642],\n",
      "        [-0.0860,  0.0839, -0.1001,  ..., -0.0487, -0.0578, -0.0933],\n",
      "        [-0.0478,  0.0943,  0.0491,  ..., -0.0267, -0.0274,  0.0007]])\n",
      "birnn_layers.2.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0233,  0.0094,  0.0405,  ..., -0.0369, -0.0468,  0.0029],\n",
      "        [ 0.0665,  0.0087,  0.0765,  ...,  0.0262,  0.0115, -0.0361],\n",
      "        [ 0.0389, -0.0362,  0.0185,  ...,  0.0498,  0.0649,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0345,  0.0138,  0.0442,  ...,  0.0201,  0.0154,  0.0278],\n",
      "        [ 0.0255,  0.0429, -0.0604,  ..., -0.0036, -0.0312, -0.0417],\n",
      "        [-0.0516,  0.0439,  0.1152,  ...,  0.0295, -0.0106,  0.0308]])\n",
      "birnn_layers.2.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0184, -0.0440, -0.0515,  ..., -0.0150, -0.0241,  0.0184])\n",
      "birnn_layers.2.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0222, -0.0087, -0.0461,  ...,  0.0293, -0.0516, -0.0431])\n",
      "birnn_layers.2.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9953, 0.8568, 0.8964,  ..., 0.8024, 1.1401, 0.9209])\n",
      "birnn_layers.2.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0508, -0.1743, -0.1548,  ..., -0.1749,  0.1086, -0.0405])\n",
      "birnn_layers.3.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[-0.0295,  0.0215,  0.0381,  ...,  0.0078,  0.0027,  0.0039],\n",
      "        [-0.0283, -0.0257, -0.0241,  ..., -0.0086, -0.0488, -0.0317],\n",
      "        [-0.0137, -0.0091, -0.0298,  ...,  0.0290,  0.0221,  0.0253],\n",
      "        ...,\n",
      "        [-0.0222, -0.0154, -0.0008,  ...,  0.0178,  0.0041,  0.0294],\n",
      "        [-0.0321, -0.0563,  0.0460,  ...,  0.0089,  0.0080,  0.0649],\n",
      "        [ 0.0445, -0.0047,  0.0163,  ...,  0.0071, -0.0692, -0.0395]])\n",
      "birnn_layers.3.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[-0.0176,  0.0427,  0.0405,  ..., -0.0024,  0.0304, -0.0026],\n",
      "        [ 0.0152,  0.0184,  0.0071,  ...,  0.0610, -0.0430,  0.0654],\n",
      "        [ 0.0520, -0.0054,  0.0021,  ..., -0.0030, -0.0035, -0.0237],\n",
      "        ...,\n",
      "        [-0.0316, -0.0488, -0.0581,  ...,  0.0311,  0.0323,  0.0249],\n",
      "        [ 0.0215,  0.0485, -0.0080,  ..., -0.0162, -0.0110, -0.0425],\n",
      "        [ 0.0575, -0.0128, -0.0226,  ...,  0.0594, -0.0626, -0.0319]])\n",
      "birnn_layers.3.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0926, -0.0668,  0.0110,  ..., -0.0018,  0.0443, -0.1026])\n",
      "birnn_layers.3.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0402, -0.1166, -0.0215,  ..., -0.0443, -0.0130,  0.0020])\n",
      "birnn_layers.3.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0160, -0.0260,  0.0400,  ..., -0.0241, -0.0257,  0.0161],\n",
      "        [-0.0086,  0.0823,  0.0270,  ...,  0.0510, -0.0298, -0.0411],\n",
      "        [ 0.0374,  0.0528,  0.0310,  ..., -0.0150,  0.0601, -0.0056],\n",
      "        ...,\n",
      "        [-0.0753, -0.0401, -0.1058,  ..., -0.0160, -0.1544, -0.0969],\n",
      "        [ 0.0449,  0.0257,  0.0500,  ..., -0.0250, -0.0606, -0.0094],\n",
      "        [-0.1209, -0.1011, -0.1130,  ..., -0.0857, -0.1303, -0.1268]])\n",
      "birnn_layers.3.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0089, -0.0079, -0.0321,  ..., -0.0328,  0.0056, -0.0122],\n",
      "        [ 0.0157, -0.0437,  0.0005,  ..., -0.1245, -0.0734, -0.0548],\n",
      "        [ 0.0183,  0.0303,  0.0322,  ..., -0.0768,  0.0108, -0.1295],\n",
      "        ...,\n",
      "        [ 0.0431, -0.0429,  0.0038,  ...,  0.1242,  0.0200,  0.0566],\n",
      "        [-0.0615,  0.0504,  0.0041,  ...,  0.0558, -0.0272, -0.0475],\n",
      "        [ 0.0384,  0.0385, -0.0499,  ..., -0.0841, -0.0774, -0.0553]])\n",
      "birnn_layers.3.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0072,  0.0286,  0.0840,  ..., -0.0688,  0.0107,  0.0080])\n",
      "birnn_layers.3.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([ 0.0456, -0.0028,  0.1205,  ..., -0.0017,  0.0724, -0.0161])\n",
      "birnn_layers.3.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9403, 0.8036, 1.0270,  ..., 0.7630, 1.1183, 0.8939])\n",
      "birnn_layers.3.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.0681, -0.0604,  0.0124,  ..., -0.1477, -0.0604, -0.0834])\n",
      "birnn_layers.4.BiGRU.weight_ih_l0 torch.Size([1536, 1024])\n",
      "tensor([[ 0.0900, -0.0802, -0.0680,  ..., -0.0797, -0.0852, -0.0435],\n",
      "        [-0.0189, -0.0436, -0.0020,  ...,  0.0251,  0.0227, -0.0071],\n",
      "        [ 0.0079, -0.0355,  0.0211,  ..., -0.0263, -0.0132,  0.0112],\n",
      "        ...,\n",
      "        [-0.0417, -0.0360,  0.0030,  ...,  0.0653, -0.0164, -0.0568],\n",
      "        [-0.0392,  0.0003, -0.0217,  ..., -0.0343,  0.0024,  0.0199],\n",
      "        [ 0.0501, -0.0479, -0.0886,  ..., -0.0519, -0.0230, -0.0543]])\n",
      "birnn_layers.4.BiGRU.weight_hh_l0 torch.Size([1536, 512])\n",
      "tensor([[ 0.0746,  0.0194, -0.0599,  ...,  0.0388, -0.0888,  0.0088],\n",
      "        [ 0.0142,  0.0019, -0.0327,  ..., -0.0349,  0.0180,  0.0375],\n",
      "        [-0.0137,  0.0170,  0.0249,  ...,  0.0345,  0.0576,  0.0057],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0440, -0.0034,  ...,  0.0350, -0.0308,  0.0144],\n",
      "        [-0.0225, -0.0872, -0.0169,  ...,  0.0069,  0.0068, -0.0361],\n",
      "        [ 0.0203,  0.0354,  0.0389,  ...,  0.0319,  0.0689, -0.0888]])\n",
      "birnn_layers.4.BiGRU.bias_ih_l0 torch.Size([1536])\n",
      "tensor([-0.0612,  0.0204,  0.0048,  ..., -0.0091, -0.0118, -0.0268])\n",
      "birnn_layers.4.BiGRU.bias_hh_l0 torch.Size([1536])\n",
      "tensor([-0.0460, -0.0236, -0.0044,  ...,  0.0003,  0.0227,  0.0232])\n",
      "birnn_layers.4.BiGRU.weight_ih_l0_reverse torch.Size([1536, 1024])\n",
      "tensor([[-0.0824, -0.1633,  0.0063,  ...,  0.0559, -0.0423, -0.1143],\n",
      "        [ 0.1176, -0.0872,  0.0148,  ..., -0.0755,  0.0051,  0.0804],\n",
      "        [ 0.0301, -0.0099, -0.0458,  ..., -0.0675,  0.0087, -0.0357],\n",
      "        ...,\n",
      "        [-0.0345, -0.0112,  0.0893,  ...,  0.0568,  0.0724,  0.0520],\n",
      "        [-0.0395, -0.0171, -0.0299,  ..., -0.0496, -0.0350,  0.0142],\n",
      "        [-0.0285, -0.0133, -0.0854,  ..., -0.0049, -0.1000, -0.0373]])\n",
      "birnn_layers.4.BiGRU.weight_hh_l0_reverse torch.Size([1536, 512])\n",
      "tensor([[ 0.0579, -0.0812,  0.1168,  ..., -0.0680, -0.0216,  0.0231],\n",
      "        [ 0.0051, -0.1419, -0.0353,  ...,  0.0372,  0.0122,  0.0803],\n",
      "        [-0.1306, -0.0338, -0.1962,  ...,  0.0522,  0.0222, -0.0335],\n",
      "        ...,\n",
      "        [-0.0985,  0.0978,  0.0221,  ...,  0.0401,  0.0003,  0.0456],\n",
      "        [-0.0066, -0.0143,  0.0313,  ..., -0.0273, -0.0300, -0.0039],\n",
      "        [-0.0285,  0.0329,  0.0339,  ..., -0.0605, -0.0532, -0.0445]])\n",
      "birnn_layers.4.BiGRU.bias_ih_l0_reverse torch.Size([1536])\n",
      "tensor([0.0003, 0.0689, 0.0098,  ..., 0.1109, 0.0236, 0.0180])\n",
      "birnn_layers.4.BiGRU.bias_hh_l0_reverse torch.Size([1536])\n",
      "tensor([-0.0376,  0.0794,  0.0086,  ...,  0.0013, -0.0325, -0.0449])\n",
      "birnn_layers.4.layer_norm.weight torch.Size([1024])\n",
      "tensor([0.9453, 1.0154, 0.8411,  ..., 0.9289, 0.9415, 1.0805])\n",
      "birnn_layers.4.layer_norm.bias torch.Size([1024])\n",
      "tensor([-0.1184,  0.0188, -0.1610,  ..., -0.1537, -0.0686, -0.1491])\n",
      "classifier.0.weight torch.Size([512, 1024])\n",
      "tensor([[ 0.0253, -0.0013,  0.0156,  ..., -0.0284,  0.0294, -0.0086],\n",
      "        [ 0.0598, -0.0060, -0.0225,  ...,  0.0075,  0.0461, -0.0010],\n",
      "        [ 0.0347,  0.0089, -0.0455,  ...,  0.0188,  0.0101,  0.0130],\n",
      "        ...,\n",
      "        [ 0.0660, -0.0314, -0.0152,  ...,  0.0216, -0.0243, -0.0248],\n",
      "        [ 0.0469, -0.0137, -0.0011,  ...,  0.0471,  0.0360, -0.0058],\n",
      "        [ 0.0285,  0.0112,  0.0189,  ...,  0.0047, -0.0084, -0.0073]])\n",
      "classifier.0.bias torch.Size([512])\n",
      "tensor([-0.0946, -0.1050, -0.1129, -0.0970, -0.0987, -0.1217, -0.0328, -0.1329,\n",
      "        -0.0087, -0.1007, -0.0866, -0.1086, -0.0930, -0.1021, -0.0983, -0.1097,\n",
      "        -0.0704, -0.1266, -0.0771, -0.0916, -0.1201,  0.0038, -0.0823, -0.0321,\n",
      "        -0.1071, -0.0986, -0.1040, -0.0163,  0.0281, -0.1330, -0.1431, -0.1072,\n",
      "        -0.1273, -0.0979, -0.1346, -0.1428, -0.1062, -0.0067, -0.0970, -0.1323,\n",
      "        -0.0591, -0.1117, -0.0522, -0.1109, -0.0727, -0.1040, -0.1343, -0.1322,\n",
      "        -0.1158, -0.1171, -0.1062, -0.0704, -0.1163, -0.1075, -0.1484, -0.1323,\n",
      "        -0.0998, -0.0981, -0.0995, -0.1289, -0.1118, -0.0878, -0.0804, -0.1267,\n",
      "        -0.0969, -0.1134, -0.0703, -0.0743, -0.1149, -0.1074, -0.0993, -0.1094,\n",
      "        -0.1225, -0.1147, -0.0960, -0.0947, -0.0468, -0.0905, -0.1362, -0.1462,\n",
      "        -0.0917, -0.1041, -0.0977,  0.0252, -0.1306, -0.1373, -0.0930, -0.1056,\n",
      "        -0.1388, -0.0125, -0.1040, -0.1420, -0.1179, -0.1119,  0.0743, -0.0361,\n",
      "        -0.0422, -0.1132, -0.0633, -0.1125, -0.1451, -0.1178, -0.1010, -0.1333,\n",
      "        -0.1076, -0.0941, -0.0815,  0.0124, -0.0840, -0.1189, -0.0988, -0.1007,\n",
      "        -0.1386, -0.1135, -0.0917, -0.1007, -0.0956, -0.0985, -0.1127, -0.0337,\n",
      "        -0.0655, -0.0567, -0.1230,  0.0077, -0.1054, -0.1109, -0.0291, -0.1028,\n",
      "        -0.0315, -0.1062, -0.1030, -0.0960, -0.0877, -0.0831, -0.0696, -0.0916,\n",
      "        -0.1306, -0.0921, -0.1227, -0.1122,  0.0353, -0.1080, -0.1336, -0.1352,\n",
      "        -0.1449, -0.0611, -0.0926, -0.0665, -0.1233, -0.0864, -0.0979, -0.1117,\n",
      "        -0.1344, -0.1292, -0.0541, -0.1312, -0.1207, -0.1078, -0.1377, -0.1338,\n",
      "        -0.1108, -0.0868, -0.1316, -0.1024, -0.0966, -0.0769, -0.1438, -0.0776,\n",
      "        -0.1209, -0.1177, -0.1270, -0.1178, -0.1155, -0.1090, -0.1184, -0.1488,\n",
      "        -0.1424, -0.0975, -0.0678, -0.1356, -0.1021, -0.1179, -0.1071, -0.1470,\n",
      "        -0.1285, -0.1149, -0.0807, -0.1208, -0.0992, -0.1039, -0.1249, -0.0949,\n",
      "        -0.1189, -0.0579, -0.1025, -0.1487, -0.1210, -0.0942, -0.0798, -0.0947,\n",
      "        -0.1312, -0.1131, -0.0887, -0.0890, -0.0620,  0.0141, -0.0201, -0.0785,\n",
      "        -0.1392, -0.0866, -0.1379, -0.1106, -0.1132, -0.0890, -0.1133, -0.1110,\n",
      "        -0.0979, -0.1245, -0.0836, -0.1268, -0.1174, -0.0943, -0.1231, -0.1334,\n",
      "        -0.0708, -0.1008, -0.0884, -0.1162, -0.0841, -0.1144, -0.1205, -0.1133,\n",
      "        -0.1293, -0.1055, -0.0734, -0.1032, -0.1156, -0.0665, -0.1136, -0.1401,\n",
      "        -0.0897, -0.1233, -0.0775,  0.0011, -0.0875, -0.0974, -0.1137, -0.1086,\n",
      "        -0.0926, -0.1050, -0.1462, -0.1100, -0.1190,  0.0449, -0.1463, -0.0677,\n",
      "        -0.1012, -0.0949, -0.1417, -0.1224, -0.0932, -0.0925, -0.1071, -0.1114,\n",
      "        -0.1328, -0.1057, -0.0761, -0.1412, -0.1254, -0.1083, -0.1344, -0.0870,\n",
      "        -0.0864, -0.1129, -0.0815, -0.1215, -0.1008, -0.1501, -0.0876, -0.0971,\n",
      "        -0.0361, -0.0853, -0.0717, -0.1326, -0.1236, -0.1319, -0.0770, -0.1394,\n",
      "        -0.1278, -0.0885, -0.1073, -0.1579, -0.1068,  0.0156, -0.0856, -0.1402,\n",
      "        -0.0327, -0.1131, -0.1341, -0.1428, -0.0992, -0.0452, -0.1453, -0.1433,\n",
      "        -0.1162, -0.0942, -0.1358, -0.0856, -0.1090, -0.1065, -0.1439, -0.1372,\n",
      "        -0.1188, -0.0964, -0.1071, -0.0891, -0.0906, -0.0879, -0.0937, -0.1426,\n",
      "        -0.1137, -0.0764, -0.1069, -0.0619, -0.1011, -0.1017, -0.0792, -0.1327,\n",
      "        -0.0837, -0.1489, -0.0894, -0.0865, -0.0585, -0.0949, -0.1480, -0.1300,\n",
      "        -0.1090, -0.1281, -0.1060, -0.1507, -0.1174, -0.0869, -0.0954, -0.1108,\n",
      "        -0.1486, -0.1383, -0.1042, -0.1046, -0.0860, -0.0989, -0.1254, -0.1017,\n",
      "        -0.0866, -0.0633, -0.0092, -0.0829, -0.1207, -0.0911, -0.0894, -0.1201,\n",
      "        -0.1402, -0.1105, -0.1028, -0.1311, -0.0546, -0.0981, -0.0478, -0.1074,\n",
      "        -0.0918, -0.0831, -0.0971, -0.1468, -0.0979, -0.0844, -0.1129, -0.1352,\n",
      "        -0.0974, -0.1311, -0.1175, -0.1225, -0.1045, -0.1057, -0.1013, -0.1268,\n",
      "        -0.1336, -0.0977, -0.1232, -0.1297, -0.0953, -0.0946, -0.0802, -0.0755,\n",
      "        -0.1042, -0.1137, -0.1003, -0.1380,  0.0392, -0.1039, -0.1331, -0.0924,\n",
      "        -0.1320, -0.1293, -0.1497, -0.0821, -0.1374, -0.1408, -0.0967, -0.1069,\n",
      "        -0.0483,  0.0015, -0.0489, -0.1095, -0.1375, -0.0362, -0.1365, -0.1394,\n",
      "        -0.1289, -0.0961, -0.0911, -0.1259, -0.1421, -0.1260, -0.0629, -0.1052,\n",
      "        -0.0739, -0.1175, -0.1364, -0.0287, -0.1005, -0.1002, -0.0938, -0.0318,\n",
      "        -0.1420, -0.1060, -0.1238, -0.0926, -0.1160, -0.0655, -0.0763,  0.0695,\n",
      "        -0.0951, -0.0785, -0.0467, -0.1124, -0.0872,  0.0124, -0.0972, -0.1381,\n",
      "        -0.1073, -0.1237, -0.1435, -0.0547, -0.1075, -0.1162, -0.1375, -0.1426,\n",
      "        -0.1075, -0.1490, -0.1232, -0.1377, -0.1243, -0.0937, -0.0937, -0.0865,\n",
      "        -0.0826, -0.1132, -0.1024, -0.0783, -0.0116, -0.0901, -0.0617, -0.1110,\n",
      "        -0.0940, -0.0796, -0.1423, -0.0967, -0.1274, -0.1026,  0.0440, -0.0922,\n",
      "        -0.1141, -0.0217, -0.1066, -0.0872,  0.0139, -0.1404, -0.0983, -0.1054,\n",
      "        -0.0514, -0.0599, -0.1096, -0.0885, -0.1283, -0.1031, -0.1246, -0.1248,\n",
      "        -0.1013, -0.1164, -0.1046, -0.0862, -0.0801, -0.0795, -0.0836, -0.1154,\n",
      "        -0.1050, -0.1021, -0.0732, -0.1189, -0.0947, -0.1061, -0.1355, -0.1109])\n",
      "classifier.3.weight torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0390, -0.0180, -0.0041,  ..., -0.0037,  0.0099,  0.0460],\n",
      "        [ 0.0344, -0.0040, -0.0207,  ..., -0.0316,  0.0018,  0.0096],\n",
      "        [-0.0154,  0.0266,  0.0404,  ...,  0.0055,  0.0274,  0.0553],\n",
      "        [-0.0044, -0.0151,  0.0124,  ...,  0.0031,  0.0157,  0.0511]])\n",
      "classifier.3.bias torch.Size([4])\n",
      "tensor([ 0.3474, -0.1841, -0.2395, -0.0883])\n"
     ]
    }
   ],
   "source": [
    "for name, param in client1_model.state_dict().items():\n",
    "    print(name, param.size())\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/90 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------EPOCH: 1-----------------\n",
      "tensor([[-1.7061e-07, -4.2971e-08, -1.8999e-08,  ..., -5.1188e-09,\n",
      "         -6.5060e-09, -2.7314e-07],\n",
      "        [ 1.8045e-07,  1.4972e-09,  2.6546e-08,  ...,  6.8954e-09,\n",
      "          7.8316e-09,  2.6940e-07],\n",
      "        [-3.1275e-08, -9.4515e-10, -1.0075e-08,  ..., -9.0712e-09,\n",
      "         -1.7137e-08, -1.2328e-08],\n",
      "        [ 2.1434e-08,  4.2419e-08,  2.5278e-09,  ...,  7.2947e-09,\n",
      "          1.5811e-08,  1.6067e-08]])\n",
      "------------------ITER------------------\n",
      "['sssss', 'ssss', 'ssssss', 'ssssss'] ['sstteeettttttttttttsssssstttttts', 'ssttettttetttttttttttttts', 'sssstettttttttttttstttttttttttttttttttttttttss', 'ssssttttttttteeeeeeeeeettssssseeettsettttttts']\n",
      "preds:  sssssssssssssssssssss\n",
      "Train Epoch: 1 [0/450 (0%)]\tLoss: 0.389539\n",
      "Train Accuracy: 0.23580754260267445, Train loss: 0\n",
      "------------------ITER------------------\n",
      "['ssss', 'sstss', 'ssss', 'ssss'] ['ssstttttttttttttssttteetttttts', 'sstttttttttteetttss', 'ssstttttssssssssttttttttetttss', 'ssttttttttttttssseeeetttssttttttttttttts']\n",
      "preds:  sssssstssssssssss\n",
      "------------------ITER------------------\n",
      "['ssss', 'sss', 'ssss', 'ss'] ['sstttetttttttttttttttttttts', 'ssttttttttttttttttseetttttttttts', 'ssttttteetttttttttttttttts', 'ssseettttsssssttttttss']\n",
      "preds:  sssssssssssss\n",
      "------------------ITER------------------\n",
      "['sss', 'ssss', 'sss', 'ssss'] ['ssseettteetttttsttteettttttttts', 'ssstttttttteetttttttttss', 'sssttttttttttttttttttttttteeetttttttss', 'sstttttttttttttttttttttttttttss']\n",
      "preds:  ssssssssssssss\n",
      "------------------ITER------------------\n",
      "['sssss', 'ss', 'ss', 'ss'] ['ssssstttttteeettttttttttttsssttttttttttss', 'ssttttttetttttttttts', 'ssttttttttttttttteeteetteteetttttttttts', 'ssttetttttttttttttttttttttttss']\n",
      "preds:  sssssssssss\n",
      "------------------ITER------------------\n",
      "['sssss', 'ssss', 'ssts', 'sss'] ['ssssttttttttttteeeeetttsttttttttttttttss', 'ssttttttttssstttttteeetttttttteettttss', 'sstttttseeeeettttttttss', 'sseetttttttttttttttttettttttttttts']\n",
      "preds:  ssssssssssstssss\n",
      "------------------ITER------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5e36ede88433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------EPOCH: {}-----------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclient1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter_client1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fed_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9312bdf61f59>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, epoch, iter_meter, writer, scheduler, ckpt_save_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f9fd71fd5132>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, time, feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbirnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f9fd71fd5132>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBiGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGELUs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \"\"\"\n\u001b[0;32m-> 1126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    print(\"-----------------EPOCH: {}-----------------\".format(epoch))\n",
    "    print(client1_model.classifier[3].weight.grad)\n",
    "    client1_model, client1_optimizer = train(client1_model, device, client1_train_loader, criterion, client1_optimizer, epoch, iter_meter_client1, writer, client1_scheduler, \"fed_averaging\")\n",
    "    print(client1_model.classifier[3].weight.grad)\n",
    "    test(client1_model, device, client1_test_loader, criterion, epoch, writer)\n",
    "\n",
    "    client2_model, client2_optimizer = train(client2_model, device, client2_train_loader, criterion, client2_optimizer, epoch, iter_meter_client2, writer, client2_scheduler, \"fed_averaging\")\n",
    "    test(client2_model, device, client2_test_loader, criterion, epoch, writer)\n",
    "\n",
    "    fed_model = federated_avg({'client1': client1_model,\n",
    "                              'client2': client2_model})\n",
    "    test(fed_model, device, client1_test_loader, criterion, epoch, writer)\n",
    "    \n",
    "fed_model.eval().cpu()\n",
    "save_model_filename = \"final_epoch_client1\" + str(epoch + 1)  + \".model\"\n",
    "save_model_path = os.path.join(\"fed_checkpoints\", save_model_filename)\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': fed_model.state_dict(),\n",
    "            }, save_model_path)\n",
    "\n",
    "print(\"\\nDone, trained model saved at\", save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch, iter_meter, writer, scheduler, ckpt_save_dir):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    total_loss=0\n",
    "    LR = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    avg_acc = 0\n",
    "    acc = []\n",
    "    wers = []\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (_data) in enumerate(train_loader):\n",
    "        print(\"------------------ITER------------------\")\n",
    "        #bi, wav, label = batch_idx, wav, label\n",
    "        for g in optimizer.param_groups:\n",
    "            LR=g['lr']\n",
    "        wav, labels, input_lengths, label_lengths = _data\n",
    "        # input_lengths, label_lengths = torch.IntTensor(input_lengths), torch.IntTensor(label_lengths)\n",
    "        wav = wav.to(device)\n",
    "        # wav = wav.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\n",
    "        output = model(wav)\n",
    "\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "\n",
    "\n",
    "        output = output.transpose(0,1)\n",
    "        \n",
    "        # print(labels, label_lengths)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        #print(loss)\n",
    "        total_loss+=loss\n",
    "\n",
    "        iter_meter.step()\n",
    "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "        decoded_preds, decoded_targets = list(map(str.strip, decoded_preds)), list(map(str.strip, decoded_targets))\n",
    "        print(decoded_preds, decoded_targets)\n",
    "        print(\"preds: \", \"\".join(decoded_preds))\n",
    "        for j in range(len(decoded_preds)):\n",
    "            s = SequenceMatcher(None, decoded_targets[j], decoded_preds[j])\n",
    "            wers.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "            acc.append(s.ratio())\n",
    "\n",
    "        avg_acc = sum(acc)/len(acc)\n",
    "        writer.add_scalar(\"accuracy/train_accuracy\", avg_acc, epoch)\n",
    "        writer.add_scalar('accuracy/train_loss', loss.item(), iter_meter.get())\n",
    "        writer.add_scalar('CTCLoss', loss, epoch*len(train_loader)+1)\n",
    "        writer.add_scalar('TLoss', total_loss, epoch*len(train_loader)+1)\n",
    "        writer.add_scalar(\"Learning Rate\", LR, epoch)\n",
    "\n",
    "        writer.add_scalar(\"WER\", wer(decoded_targets[j], decoded_preds[j]), iter_meter.get())\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(wav), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "            print(\"Train Accuracy: {}, Train loss: {}\".format(avg_acc, train_loss))\n",
    "        model.to(device).train()\n",
    "    return model, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------EPOCH-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7f213118b99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------EPOCH-----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(client1_model.classifier[3].weight.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter_client1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient1_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fed_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient2_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient2_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient2_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter_client2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient2_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fed_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-5e3e0557ce7e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, epoch, iter_meter, writer, scheduler, ckpt_save_dir)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# output = model(wav, input_lengths)   #(batch, time, n_class) [4, 911, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f9fd71fd5132>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, feature, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f9fd71fd5132>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (batch, channel, feature, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f9fd71fd5132>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# x (batch, channel, feature, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, channel, time, feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, channel, feature, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 153\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \"\"\"\n\u001b[1;32m   1695\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1696\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    print(\"-----------------EPOCH: {}-----------------\".format(epoch))\n",
    "    print(client1_model.classifier[3].weight.grad)\n",
    "    client1_model, client1_optimizer = train(client1_model, device, client1_train_loader, criterion, client1_optimizer, epoch, iter_meter_client1, writer, client1_scheduler, \"fed_averaging\")\n",
    "    print(client1_model.classifier[3].weight.grad)\n",
    "    test(client1_model, device, client1_test_loader, criterion, epoch, writer)\n",
    "\n",
    "    client2_model, client2_optimizer = train(client2_model, device, client2_train_loader, criterion, client2_optimizer, epoch, iter_meter_client2, writer, client2_scheduler, \"fed_averaging\")\n",
    "    test(client2_model, device, client2_test_loader, criterion, epoch, writer)\n",
    "\n",
    "    fed_model = federated_avg({'client1': client1_model,\n",
    "                              'client2': client2_model})\n",
    "    test(fed_model, device, client1_test_loader, criterion, epoch, writer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    _test_data = next(iter(test_loader))\n",
    "    print(_test_data)\n",
    "    for i in range(len(models)):\n",
    "        _train_data = next(iter(train_loaders[i]))\n",
    "        print(\"training: \", i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.4077e-04, 7.0382e-05, 1.9882e-05,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.2415e-04, 1.9087e-04, 5.3919e-05,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [9.5825e-08, 1.4270e-16, 1.1959e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.5467e-08, 1.2667e-16, 1.0774e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.6489e-08, 1.1667e-16, 7.9653e-17,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.2004e-05, 6.4693e-04, 9.3381e-04,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.2553e-05, 1.7544e-03, 2.5324e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [7.2002e-07, 1.6514e-15, 8.6660e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [7.1131e-07, 1.1774e-15, 7.6857e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [7.1530e-07, 1.4497e-15, 7.9708e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.4074e-03, 6.0813e-03, 1.0110e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.2406e-03, 1.6492e-02, 2.7418e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [6.5158e-06, 9.6895e-16, 3.7193e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.5206e-06, 7.4788e-16, 2.3647e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.6076e-06, 6.9808e-16, 3.0056e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.8762e-03, 3.6585e-04, 2.0394e-03,  ..., 1.1915e-02,\n",
       "            8.9514e-04, 1.2049e-04],\n",
       "           [7.8001e-03, 9.9217e-04, 5.5309e-03,  ..., 3.2313e-02,\n",
       "            2.4276e-03, 3.2676e-04],\n",
       "           ...,\n",
       "           [1.6173e-06, 1.7520e-15, 5.3062e-16,  ..., 7.9369e-16,\n",
       "            9.6503e-16, 7.7354e-07],\n",
       "           [1.6135e-06, 1.5640e-15, 5.0676e-16,  ..., 7.0079e-16,\n",
       "            6.7485e-16, 7.7023e-07],\n",
       "           [1.6320e-06, 1.4952e-15, 4.8510e-16,  ..., 9.5577e-16,\n",
       "            1.0911e-15, 7.7812e-07]]]]),\n",
       " tensor([[1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 1., 1., 1., 3., 3., 3., 3., 3.,\n",
       "          3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 3., 3., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 1., 1., 1., 3., 3., 3., 3., 3., 3., 1., 1., 2., 2., 2., 3., 3.,\n",
       "          3., 3., 3., 3., 3., 3., 1., 1., 1.]]),\n",
       " [205, 327, 247, 442],\n",
       " [21, 33, 25, 45])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.6102e-02, 2.5319e-03, 7.1354e-04,  ..., 3.8064e-03,\n",
       "            1.5619e-02, 1.0263e-02],\n",
       "           [4.3668e-02, 6.8663e-03, 1.9351e-03,  ..., 1.0323e-02,\n",
       "            4.2357e-02, 2.7834e-02],\n",
       "           ...,\n",
       "           [4.2098e-06, 3.6487e-15, 9.8787e-15,  ..., 2.3212e-14,\n",
       "            1.9503e-14, 1.3838e-07],\n",
       "           [4.1987e-06, 1.8435e-15, 6.9616e-15,  ..., 1.9385e-14,\n",
       "            1.5223e-14, 1.4079e-07],\n",
       "           [4.2461e-06, 1.4643e-15, 7.0396e-15,  ..., 1.4656e-14,\n",
       "            1.4816e-14, 1.4411e-07]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.3314e-05, 4.7871e-05, 1.8838e-04,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.3227e-05, 1.2982e-04, 5.1088e-04,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.7445e-07, 1.4782e-15, 2.1381e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.7971e-07, 1.4847e-15, 1.9984e-16,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.2631e-03, 4.1326e-04, 1.9945e-04,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.1375e-03, 1.1207e-03, 5.4088e-04,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [5.7575e-06, 8.3573e-15, 7.3665e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.7199e-06, 6.5779e-15, 5.2852e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.7706e-06, 5.6377e-15, 4.6717e-15,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.4336e-01, 3.5076e-02, 3.1847e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.5998e-01, 9.5124e-02, 8.6368e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [6.3739e-05, 2.3575e-14, 3.8806e-14,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.3948e-05, 1.3761e-14, 2.0835e-14,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.4900e-05, 9.3366e-15, 1.6607e-14,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]]]),\n",
       " tensor([[1., 1., 3., 3., 3., 3., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 2., 2.,\n",
       "          3., 3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1.],\n",
       "         [1., 1., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2.,\n",
       "          3., 3., 3., 3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 3., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3.,\n",
       "          3., 3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 3., 2., 2., 2., 3., 3.,\n",
       "          3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " [318, 246, 236, 222],\n",
       " [32, 25, 24, 23])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "majorProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
