{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTfYifImtoSJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/Desktop/MSR challenge/hparam.py:11: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import csv\n",
    "from data_load import TextTransform\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from decoder import GreedyDecoder\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "from librosa.core import stft, magphase\n",
    "from glob import glob\n",
    "from torch import autograd\n",
    "import csv\n",
    "from data_load import CodeSwitchDataset\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pad(wav, trans, lang):\n",
    "    if lang == \"Gujarati\":\n",
    "        max_len = 0\n",
    "    elif lang == \"Telugu\":\n",
    "        max_len = 529862\n",
    "    elif lang == 'Tamil':\n",
    "        max_len = 0\n",
    "    else:\n",
    "        raise Exception(\"Check Language\")\n",
    "\n",
    "    while len(wav) < max_len:\n",
    "        diff = max_len - len(wav)\n",
    "        ext = wav[:diff]\n",
    "        wav = np.append(wav, wav[:diff])\n",
    "        ratio = int(len(trans)*diff/len(wav))\n",
    "        trans +=trans[:ratio]\n",
    "    return wav, trans\n",
    "\n",
    "def preprocess(data):\n",
    "    #print(data)\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    \n",
    "    for (wav, sr, trans, lang) in data:\n",
    "        wav, trans  = pad(wav, trans, lang)\n",
    "        out = stft(wav, win_length=int(sr*0.02), hop_length=int(sr*0.01))\n",
    "        out = np.transpose(out, axes=(1, 0))\n",
    "\n",
    "        text_transform = TextTransform()\n",
    "        trans = torch.Tensor(text_transform.text_to_int(trans.lower()))\n",
    "\n",
    "        out = magphase(out)[0]\n",
    "        out = torch.from_numpy(np.array([np.log(1 + x) for x in out]))\n",
    "        #print(out.shape)\n",
    "        inputs.append(out)\n",
    "        labels.append(trans)\n",
    "        input_lengths.append(out.shape[0])\n",
    "        label_lengths.append(len(trans))\n",
    "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    #spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    return inputs, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=False):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    text_transform = TextTransform()\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CodeSwitchDataset(lang = 'Telugu', mode = \"train\")\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = train_sampler,\n",
    "                         collate_fn = lambda x: preprocess(x))\n",
    "test_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 6,\n",
    "                          sampler = valid_sampler,\n",
    "                         collate_fn = lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim = 29, num_layers = 4):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "        #self.drop = nn.Dropout(0.25)\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(type(self.lstm))\n",
    "        #print(x.shape)\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        #lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.linear(lstm_out)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data_len = len(train_loader.dataset)\n",
    "pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "for batch_idx, (_data) in pbar:\n",
    "    #bi, wav, label = batch_idx, wav, label\n",
    "    wav, labels, input_lengths, label_lengths = _data\n",
    "    print(wav.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, writer):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    total_loss=0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (_data) in pbar:\n",
    "        #bi, wav, label = batch_idx, wav, label\n",
    "        wav, labels, input_lengths, label_lengths = _data\n",
    "        wav = wav.to(device)\n",
    "        wav = wav.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "        output, _ = model(wav)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        output = output.transpose(0,1)\n",
    "        #print(output.shape)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        #print(loss)\n",
    "        total_loss+=loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        \n",
    "        writer.add_scalar('Loss', loss, epoch*len(train_loader)+1)\n",
    "        writer.add_scalar('TLoss', total_loss, epoch*len(train_loader)+1)\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(wav), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    if (epoch+1)%2 == 0:\n",
    "        model.eval().cpu()\n",
    "        ckpt_model_filename = \"ckpt_epoch_\" + str(epoch+1) + \"_batch_id_\" + str(batch_idx+1) + \".pth\"\n",
    "        ckpt_model_path = os.path.join(\"checkpoints/\", ckpt_model_filename)\n",
    "        torch.save(model.state_dict(), ckpt_model_path)\n",
    "        model.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    training_loss, train_acc = 0, 0\n",
    "    eer, total_eer = 0, 0\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, _data in enumerate(test_loader):\n",
    "            frr_far, eer = 0, 0\n",
    "            inputs, labels, input_lengths, label_lengths = _data \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, _ = model(inputs)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=1)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                if len(set(decoded_preds[j])) != len(set(decoded_targets[j])):\n",
    "                    frr_far+=1\n",
    "            eer = frr_far/len(decoded_preds)\n",
    "            total_eer+=eer\n",
    "            writer.add_scalar('TLoss', total_eer, epoch*len(test_loader)+1)\n",
    "            print(\"EER: \",eer)\n",
    "            print(\"Total EER: \", total_eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=1025,\n",
    "              hidden_dim=512,\n",
    "              batch_size=8,\n",
    "              output_dim=29,\n",
    "              num_layers=4)\n",
    "#model.half()\n",
    "model = model.to(device)\n",
    "criterion = nn.CTCLoss().to(device)\n",
    "epochs = 40\n",
    "optimizer = optim.Adam(model.parameters(), 5e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-4, \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=40,\n",
    "                                            anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load('checkpoints/ckpt_epoch_38_batch_id_1699.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels, input_lengths, label_lengths = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21., 21.,  1.,  ...,  0.,  0.,  0.],\n",
       "        [21., 21., 21.,  ...,  0.,  0.,  0.],\n",
       "        [ 6.,  6.,  6.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [21., 21., 21.,  ..., 21., 21., 21.],\n",
       "        [21., 21., 21.,  ...,  0.,  0.,  0.],\n",
       "        [21., 21., 21.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[183, 184, 184, 236, 239, 388, 178, 306]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2409, 2409, 2409, 2409, 2409, 2409, 2409, 2409]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1025, 512, num_layers=4)\n",
       "  (linear): Linear(in_features=512, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = model(inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2835,  1.3164, -0.1522,  ..., -0.1437, -0.1188, -0.1535],\n",
       "         [ 3.2497,  0.4497,  0.3604,  ...,  0.3275,  0.3461,  0.3395],\n",
       "         [ 3.3058,  1.5583, -0.3964,  ..., -0.3932, -0.3615, -0.3753],\n",
       "         ...,\n",
       "         [ 3.4495,  1.8411, -0.9489,  ..., -0.9906, -0.8959, -0.9429],\n",
       "         [ 3.2477,  2.5675, -1.3726,  ..., -1.4047, -1.3332, -1.3775],\n",
       "         [ 3.2150,  2.4898, -0.9548,  ..., -0.9558, -0.9080, -0.9752]],\n",
       "\n",
       "        [[ 3.5076,  2.3428, -1.1568,  ..., -1.0859, -1.0337, -1.0074],\n",
       "         [ 3.7234,  1.8242, -1.2044,  ..., -1.1536, -1.0829, -1.0382],\n",
       "         [ 3.7028,  2.3307, -1.9615,  ..., -1.8326, -1.7163, -1.7376],\n",
       "         ...,\n",
       "         [ 2.1062,  2.3658, -4.3977,  ..., -4.3685, -4.3655, -4.2692],\n",
       "         [ 1.7889,  3.0045, -4.6873,  ..., -4.6058, -4.6580, -4.5415],\n",
       "         [ 2.3047,  2.1133, -3.0806,  ..., -3.0224, -3.0906, -2.9584]],\n",
       "\n",
       "        [[ 3.6262,  1.9262, -0.1249,  ..., -0.1116, -0.1179,  0.0651],\n",
       "         [ 3.6798,  2.2807, -0.7161,  ..., -0.6720, -0.7237, -0.5649],\n",
       "         [ 3.6924,  2.5838, -1.2231,  ..., -1.1066, -1.1382, -1.0450],\n",
       "         ...,\n",
       "         [ 2.8831,  0.5942, -2.0832,  ..., -2.2063, -2.0707, -2.1421],\n",
       "         [ 2.9465,  0.6754, -2.1017,  ..., -2.1956, -2.0817, -2.1479],\n",
       "         [ 2.9896,  0.2050, -1.4406,  ..., -1.4928, -1.4599, -1.4514]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.3830,  0.3923, -0.1099,  ..., -0.2432, -0.4191, -0.0427],\n",
       "         [ 3.5746,  1.9287, -0.9454,  ..., -0.9823, -1.1960, -0.9855],\n",
       "         [ 3.5563,  1.9340, -0.7307,  ..., -0.7975, -0.9847, -0.7508],\n",
       "         ...,\n",
       "         [ 0.5517,  1.1057, -4.6596,  ..., -4.6027, -4.7320, -4.5328],\n",
       "         [ 0.2569,  0.6871, -4.8187,  ..., -4.7614, -4.9073, -4.7084],\n",
       "         [ 3.2777,  3.0476, -2.1368,  ..., -2.2290, -2.4851, -2.0401]],\n",
       "\n",
       "        [[ 3.3576,  0.0700,  0.1108,  ..., -0.0584, -0.2235,  0.1736],\n",
       "         [ 3.5838,  1.6429, -0.9029,  ..., -0.9477, -1.1853, -0.9777],\n",
       "         [ 3.5779,  1.7515, -0.8085,  ..., -0.8784, -1.0864, -0.8654],\n",
       "         ...,\n",
       "         [ 0.5301,  0.9996, -4.7547,  ..., -4.6673, -4.8307, -4.7543],\n",
       "         [ 0.2113,  0.3580, -4.8860,  ..., -4.7836, -4.9649, -4.9414],\n",
       "         [ 3.1422,  3.5028, -2.5667,  ..., -2.6379, -2.8941, -2.4666]],\n",
       "\n",
       "        [[ 3.3412, -0.3477,  0.2118,  ...,  0.0566, -0.0861,  0.3011],\n",
       "         [ 3.6109,  2.0103, -1.0310,  ..., -1.0595, -1.3181, -1.0902],\n",
       "         [ 3.5983,  1.9976, -0.8397,  ..., -0.8972, -1.1400, -0.8881],\n",
       "         ...,\n",
       "         [ 0.8364,  1.2270, -5.2594,  ..., -5.2065, -5.3320, -5.2238],\n",
       "         [ 0.6128,  0.8608, -5.3188,  ..., -5.2446, -5.4019, -5.3350],\n",
       "         [ 3.0353,  3.7773, -2.7204,  ..., -2.7766, -3.0360, -2.6327]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = GreedyDecoder(out, labels, label_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"eeee 'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'eee''eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee''                         e '        '        '''                                                   '   ''''   '  e tt              ttttt''''''ttttttttttttttttttttt  tt'  ''                 ttttttttttttt                      ttt'''''''''ttttttttttttt'''''      ''''''''                                                     ''ttttttttt''''t''''tt     ' e                 t                              ttttttttttttttttttttttttttttttttt''''''eee'                    ttttt ttttttttt'tttttt tt'''''''''''             tt     ttttttt'''e 'eeeeee'''tttt'ttttttttttttttttttt'''''             ee'    tttttttttt                  t                                    t         ttt'tttttttttttttt'ttt''''eeee'''''''''''t'ttttttttttttttttttttttte'''''''''''''''''''''''''''''''eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee 'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'eee''eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee''                         e '        '        '''                                                   ' ' ''''   '  e tt              ttttt''''''ttttttttttttttttttttt  tt'  ''                 ttttttttttttt                      ttt'''''''''ttttttttttttt'''''      ''''''''                                                     ''ttttttttt''''t''''tt     ' e                 t                              ttttttttttttttttttttttttttttttttt''''''eee'                    ttttt 'tttttttt'tttttt tt'''''''''''             tt     ttttttt'''e 'eeeeee'''tttt'ttttttttttttttttttt'''''             ee'    tttttttttt                  t                                    t         ttt'tttttttttttttt'ttt''''eeee'''''''''''t'ttttttttttttttttttttttt''''''''''''''''''''''''''''''''eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee 'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'eee''eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'                         e '        '        '''                                                   ' ' ''''   '  e tt              ttttt''''''ttttttttttttttttttttt  tt'' ''                 ttttttttttttt                      ttt'''''''''ttttttttttttt'''''      ''''''''                                                     ''ttttttttt''''t''''tt     ' e                 t                              ttttttttttttttttttttttttttttttttt''''''eee'                    ttttt 'tttttttt'tttttt tt'''''''''''             tt     ttttttt'''ee\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt tttt ttt tttttt tttttttt tttttt ttttttttttttttt ttttt tttttttt ttttttttttttttt tttt ttt tttttt tttttttt tttttt ttttttttttttttt ttttt tttttttt ttt tttt ttt tttttt tttttttt tttttt tt'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2409"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', \"'\", 'e', 't'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ans[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MSIR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
